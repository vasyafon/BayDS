{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:09:34.818294Z",
     "start_time": "2019-09-06T20:09:29.780175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.layers import Concatenate, Input, Dense, Embedding, Flatten, Dropout, BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "import keras.backend as k\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# pd.options.display.precision = 15\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import time\n",
    "# import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "# from sklearn import metrics\n",
    "# from sklearn import linear_model\n",
    "import gc\n",
    "import pickle\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import eli5\n",
    "# import shap\n",
    "# from IPython.display import HTML\n",
    "# import json\n",
    "# import altair as alt\n",
    "\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:09:55.244722Z",
     "start_time": "2019-09-06T20:09:55.014716Z"
    }
   },
   "outputs": [],
   "source": [
    "main_path = r'../..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:09:57.018765Z",
     "start_time": "2019-09-06T20:09:56.187734Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:09:58.576779Z",
     "start_time": "2019-09-06T20:09:58.319771Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = '31.08'\n",
    "main_learning_folder = main_path+'/Snapshots/'+experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:39.354469Z",
     "start_time": "2019-09-06T20:10:25.484238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start here\n",
    "data_folder = main_path+'/Data'\n",
    "y = pd.read_pickle(f'{data_folder}/y.pkl')\n",
    "X = pd.read_pickle(f'{data_folder}/X_encoded_scaled.pkl').astype(np.float32)\n",
    "test = pd.read_pickle(f'{data_folder}/test_encoded_scaled.pkl').astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:42.845525Z",
     "start_time": "2019-09-06T20:10:42.580518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting model_folder\n",
    "model_name = 'keras-4'\n",
    "model_folder = f'{main_learning_folder}/{model_name}'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:43.998545Z",
     "start_time": "2019-09-06T20:10:43.737539Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=n_fold)\n",
    "# folds = GroupKFold(n_splits=5)\n",
    "# groups = pd.read_pickle('./groups.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:45.075587Z",
     "start_time": "2019-09-06T20:10:44.802558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569877\n",
       "1     20663\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:46.129614Z",
     "start_time": "2019-09-06T20:10:45.860576Z"
    }
   },
   "outputs": [],
   "source": [
    "def NNModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[X.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "    x = Dense(400, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(400, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(200, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 8192,\n",
    "    'epochs': 60,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:50.666653Z",
     "start_time": "2019-09-06T20:10:50.378678Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:10:58.992828Z",
     "start_time": "2019-09-06T20:10:52.643723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "NNModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:11:00.148828Z",
     "start_time": "2019-09-06T20:10:59.787806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9394828649611977625, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1452988825\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4512666971317458215\n",
       " physical_device_desc: \"device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:11:01.225846Z",
     "start_time": "2019-09-06T20:11:00.971823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:11:04.860892Z",
     "start_time": "2019-09-06T20:11:04.505889Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:11:17.838140Z",
     "start_time": "2019-09-06T20:11:17.479104Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':8},log_device_placement=True) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:28.215022Z",
     "start_time": "2019-09-06T20:11:19.374135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Sep  6 23:11:20 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.6667 - val_loss: 0.8111\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.4309 - val_loss: 0.5337\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.2878 - val_loss: 0.4075\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.2118 - val_loss: 0.3171\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1689 - val_loss: 0.2644\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1469 - val_loss: 0.2036\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1335 - val_loss: 0.1681\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1249 - val_loss: 0.1480\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1176 - val_loss: 0.1114\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1127 - val_loss: 0.1074\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1092 - val_loss: 0.0963\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1042 - val_loss: 0.0881\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1014 - val_loss: 0.0795\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0988 - val_loss: 0.0792\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0959 - val_loss: 0.0790\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0944 - val_loss: 0.0784\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0916 - val_loss: 0.0798\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0907 - val_loss: 0.0726\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0897 - val_loss: 0.0751\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0875 - val_loss: 0.0703\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0865 - val_loss: 0.0750\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0854 - val_loss: 0.0731\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 20s 41us/step - loss: 0.0842 - val_loss: 0.0700\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0840 - val_loss: 0.0711\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0831 - val_loss: 0.0730\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0822 - val_loss: 0.0742\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0822 - val_loss: 0.0697\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0808 - val_loss: 0.0682\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0800 - val_loss: 0.0704\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0794 - val_loss: 0.0684\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0792 - val_loss: 0.0726\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0782 - val_loss: 0.0675\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0775 - val_loss: 0.0666\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0766 - val_loss: 0.0682\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0764 - val_loss: 0.0695\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0761 - val_loss: 0.0653\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0749 - val_loss: 0.0671\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0748 - val_loss: 0.0679\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0751 - val_loss: 0.0660\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0748 - val_loss: 0.0660\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 23s 50us/step - loss: 0.0745 - val_loss: 0.0645\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0731 - val_loss: 0.0654\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0729 - val_loss: 0.0664\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0724 - val_loss: 0.0636\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0722 - val_loss: 0.0667\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0714 - val_loss: 0.0642\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0716 - val_loss: 0.0635\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0712 - val_loss: 0.0641\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0711 - val_loss: 0.0651\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0701 - val_loss: 0.0631\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0705 - val_loss: 0.0661\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0697 - val_loss: 0.0638\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0692 - val_loss: 0.0622\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0688 - val_loss: 0.0648\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0689 - val_loss: 0.0620\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0689 - val_loss: 0.0656\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0678 - val_loss: 0.0627\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0673 - val_loss: 0.0624\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0672 - val_loss: 0.0614\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0671 - val_loss: 0.0627\n",
      "118108/118108 [==============================] - 1s 7us/step\n",
      "Fold 0. auc: 0.9290.\n",
      "Fold 2 started at Fri Sep  6 23:31:06 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.6824 - val_loss: 0.5246\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.4641 - val_loss: 0.3973\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.3044 - val_loss: 0.2762\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.2184 - val_loss: 0.2211\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1708 - val_loss: 0.1755\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.1437 - val_loss: 0.1500\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1289 - val_loss: 0.1317\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1184 - val_loss: 0.1229\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1120 - val_loss: 0.1161\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1066 - val_loss: 0.1097\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1026 - val_loss: 0.1081\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0983 - val_loss: 0.1024\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0957 - val_loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0930 - val_loss: 0.0963\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0903 - val_loss: 0.0948\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0878 - val_loss: 0.0904\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0866 - val_loss: 0.0916\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0848 - val_loss: 0.0909\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0833 - val_loss: 0.0897\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0820 - val_loss: 0.0900\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0810 - val_loss: 0.0869\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0796 - val_loss: 0.0869\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0788 - val_loss: 0.0860\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0780 - val_loss: 0.0853\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0775 - val_loss: 0.0840\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0767 - val_loss: 0.0834\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0764 - val_loss: 0.0850\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0756 - val_loss: 0.0827\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0748 - val_loss: 0.0826\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0741 - val_loss: 0.0821\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0737 - val_loss: 0.0821\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0732 - val_loss: 0.0821\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0724 - val_loss: 0.0812\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0726 - val_loss: 0.0798\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0720 - val_loss: 0.0806\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0711 - val_loss: 0.0819\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0707 - val_loss: 0.0805\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0707 - val_loss: 0.0806\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0702 - val_loss: 0.0808\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0692 - val_loss: 0.0786\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0690 - val_loss: 0.0802\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0686 - val_loss: 0.0806\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0682 - val_loss: 0.0797\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0678 - val_loss: 0.0804\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0677 - val_loss: 0.0788\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0679 - val_loss: 0.0795\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0671 - val_loss: 0.0774\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0666 - val_loss: 0.0783\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0664 - val_loss: 0.0795\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0659 - val_loss: 0.0790\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0652 - val_loss: 0.0787\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0657 - val_loss: 0.0780\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0651 - val_loss: 0.0777\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 20s 41us/step - loss: 0.0646 - val_loss: 0.0777\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0645 - val_loss: 0.0777\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0642 - val_loss: 0.0775\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0640 - val_loss: 0.0790\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0637 - val_loss: 0.0778\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0631 - val_loss: 0.0784\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0634 - val_loss: 0.0777\n",
      "118108/118108 [==============================] - 1s 7us/step\n",
      "Fold 1. auc: 0.9433.\n",
      "Fold 3 started at Fri Sep  6 23:49:54 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.6893 - val_loss: 0.5761\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.4754 - val_loss: 0.4109\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.3052 - val_loss: 0.2812\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.2157 - val_loss: 0.2081\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1691 - val_loss: 0.1644\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1429 - val_loss: 0.1415\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1280 - val_loss: 0.1269\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1192 - val_loss: 0.1167\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1122 - val_loss: 0.1110\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1075 - val_loss: 0.1061\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1029 - val_loss: 0.1026\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0997 - val_loss: 0.0991\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0964 - val_loss: 0.0964\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0934 - val_loss: 0.0964\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0909 - val_loss: 0.0937\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0884 - val_loss: 0.0894\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0873 - val_loss: 0.0898\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0858 - val_loss: 0.0876\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0846 - val_loss: 0.0888\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0841 - val_loss: 0.0863\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0820 - val_loss: 0.0866\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0812 - val_loss: 0.0854\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0803 - val_loss: 0.0852\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0797 - val_loss: 0.0835\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0782 - val_loss: 0.0817\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0780 - val_loss: 0.0836\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0768 - val_loss: 0.0825\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0766 - val_loss: 0.0809\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0760 - val_loss: 0.0818\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0747 - val_loss: 0.0820\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0745 - val_loss: 0.0800\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0741 - val_loss: 0.0819\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0741 - val_loss: 0.0790\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0730 - val_loss: 0.0805\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0732 - val_loss: 0.0804\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0719 - val_loss: 0.0785\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0712 - val_loss: 0.0802\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0712 - val_loss: 0.0785\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0715 - val_loss: 0.0791\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0707 - val_loss: 0.0787\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0701 - val_loss: 0.0789\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0696 - val_loss: 0.0773\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0692 - val_loss: 0.0768\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0690 - val_loss: 0.0769\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0684 - val_loss: 0.0770\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0680 - val_loss: 0.0770\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0681 - val_loss: 0.0783\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0675 - val_loss: 0.0770\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0672 - val_loss: 0.0763\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0671 - val_loss: 0.0770\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0669 - val_loss: 0.0769\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0668 - val_loss: 0.0757\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0665 - val_loss: 0.0771\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0660 - val_loss: 0.0768\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0649 - val_loss: 0.0756\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0652 - val_loss: 0.0760\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0648 - val_loss: 0.0758\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0647 - val_loss: 0.0756\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0647 - val_loss: 0.0761\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0640 - val_loss: 0.0749\n",
      "118108/118108 [==============================] - 1s 7us/step\n",
      "Fold 2. auc: 0.9388.\n",
      "Fold 4 started at Sat Sep  7 00:09:31 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.6807 - val_loss: 0.5270\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.4693 - val_loss: 0.3625\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.3036 - val_loss: 0.2652\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.2134 - val_loss: 0.2106\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1675 - val_loss: 0.1711\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1411 - val_loss: 0.1419\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1261 - val_loss: 0.1298\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1171 - val_loss: 0.1207\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1109 - val_loss: 0.1158\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1056 - val_loss: 0.1111\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.1015 - val_loss: 0.1069\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0974 - val_loss: 0.1058\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0950 - val_loss: 0.1010\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0922 - val_loss: 0.0993\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0899 - val_loss: 0.0988\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0880 - val_loss: 0.0974\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0860 - val_loss: 0.0941\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0847 - val_loss: 0.0926\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0834 - val_loss: 0.0930\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0823 - val_loss: 0.0913\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0815 - val_loss: 0.0900\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0808 - val_loss: 0.0894\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0796 - val_loss: 0.0870\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0792 - val_loss: 0.0883\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0779 - val_loss: 0.0872\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0773 - val_loss: 0.0885\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0767 - val_loss: 0.0844\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0762 - val_loss: 0.0872\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0757 - val_loss: 0.0861\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0749 - val_loss: 0.0851\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0745 - val_loss: 0.0819\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0744 - val_loss: 0.0820\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0737 - val_loss: 0.0824\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0728 - val_loss: 0.0840\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 22s 48us/step - loss: 0.0724 - val_loss: 0.0809\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.0716 - val_loss: 0.0827\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0712 - val_loss: 0.0827\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0712 - val_loss: 0.0820\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0708 - val_loss: 0.0822\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 20s 41us/step - loss: 0.0703 - val_loss: 0.0816\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0698 - val_loss: 0.0804\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0698 - val_loss: 0.0824\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0694 - val_loss: 0.0812\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0691 - val_loss: 0.0814\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0681 - val_loss: 0.0806\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0680 - val_loss: 0.0806\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0674 - val_loss: 0.0795\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0678 - val_loss: 0.0816\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0670 - val_loss: 0.0815\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0672 - val_loss: 0.0795\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0664 - val_loss: 0.0804\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0666 - val_loss: 0.0791\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0661 - val_loss: 0.0798\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0655 - val_loss: 0.0781\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0656 - val_loss: 0.0800\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0648 - val_loss: 0.0784\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0647 - val_loss: 0.0770\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0645 - val_loss: 0.0793\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0643 - val_loss: 0.0786\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0642 - val_loss: 0.0768\n",
      "118108/118108 [==============================] - 1s 7us/step\n",
      "Fold 3. auc: 0.9513.\n",
      "Fold 5 started at Sat Sep  7 00:29:44 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.6890 - val_loss: 0.6514\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.4773 - val_loss: 0.5314\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.3137 - val_loss: 0.3054\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.2225 - val_loss: 0.2314\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1745 - val_loss: 0.1838\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1477 - val_loss: 0.1534\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.1303 - val_loss: 0.1377\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1201 - val_loss: 0.1258\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1126 - val_loss: 0.1186\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1073 - val_loss: 0.1155\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.1031 - val_loss: 0.1077\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0991 - val_loss: 0.1058\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0961 - val_loss: 0.1015\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0934 - val_loss: 0.0993\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0904 - val_loss: 0.0985\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0889 - val_loss: 0.0965\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0882 - val_loss: 0.0947\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0859 - val_loss: 0.0936\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0847 - val_loss: 0.0909\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0839 - val_loss: 0.0913\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0829 - val_loss: 0.0900\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0819 - val_loss: 0.1001\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0809 - val_loss: 0.0916\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0803 - val_loss: 0.0906\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0791 - val_loss: 0.0868\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0785 - val_loss: 0.0889\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0777 - val_loss: 0.0857\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0770 - val_loss: 0.0857\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0765 - val_loss: 0.0839\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0759 - val_loss: 0.0847\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0752 - val_loss: 0.0886\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0747 - val_loss: 0.0849\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0748 - val_loss: 0.0870\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0739 - val_loss: 0.0823\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0731 - val_loss: 0.0851\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0727 - val_loss: 0.0832\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0725 - val_loss: 0.0854\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0718 - val_loss: 0.0816\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0715 - val_loss: 0.0878\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0707 - val_loss: 0.0885\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0701 - val_loss: 0.0816\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0701 - val_loss: 0.0817\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0699 - val_loss: 0.0814\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0697 - val_loss: 0.0808\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0693 - val_loss: 0.0801\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0689 - val_loss: 0.0807\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0685 - val_loss: 0.0816\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0684 - val_loss: 0.0809\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0679 - val_loss: 0.0810\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0676 - val_loss: 0.0802\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0676 - val_loss: 0.0808\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0670 - val_loss: 0.0815\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0663 - val_loss: 0.0801\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0662 - val_loss: 0.0804\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0665 - val_loss: 0.0798\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0658 - val_loss: 0.0802\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0653 - val_loss: 0.0798\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0650 - val_loss: 0.0800\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0648 - val_loss: 0.0793\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0648 - val_loss: 0.0794\n",
      "118108/118108 [==============================] - 1s 7us/step\n",
      "Fold 4. auc: 0.9298.\n",
      "CV mean score: 0.9384, std: 0.0084.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=NNModel_maker, \n",
    "                                             X=X,\n",
    "                                             X_test=test,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:29.479061Z",
     "start_time": "2019-09-06T21:48:29.120043Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:32.468093Z",
     "start_time": "2019-09-06T21:48:30.233043Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv(f'{model_folder}/ieee_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:33.507076Z",
     "start_time": "2019-09-06T21:48:33.238084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_keras['prediction'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:34.527086Z",
     "start_time": "2019-09-06T21:48:34.271084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 789)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:48:35.565101Z",
     "start_time": "2019-09-06T21:48:35.289097Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "754px",
    "left": "1526px",
    "right": "20px",
    "top": "96px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
