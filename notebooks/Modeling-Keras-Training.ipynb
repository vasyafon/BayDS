{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:34:46.524114Z",
     "start_time": "2019-09-06T17:34:46.318103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.layers import Concatenate, Input, Dense, Embedding, Flatten, Dropout, BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "import keras.backend as k\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# pd.options.display.precision = 15\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import time\n",
    "# import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "# from sklearn import metrics\n",
    "# from sklearn import linear_model\n",
    "import gc\n",
    "import pickle\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import eli5\n",
    "# import shap\n",
    "# from IPython.display import HTML\n",
    "# import json\n",
    "# import altair as alt\n",
    "\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:35:07.830102Z",
     "start_time": "2019-09-06T17:35:07.693102Z"
    }
   },
   "outputs": [],
   "source": [
    "main_path = r'f:\\my\\Prog\\kaggle\\Baydin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:35:12.383240Z",
     "start_time": "2019-09-06T17:35:09.293866Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:35:12.843276Z",
     "start_time": "2019-09-06T17:35:12.694275Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = '31.08'\n",
    "main_learning_folder = main_path+'/Snapshots/'+experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:28.150659Z",
     "start_time": "2019-09-06T17:37:09.342685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start here\n",
    "data_folder = main_path+'/Data'\n",
    "y = pd.read_pickle(f'{data_folder}/y.pkl')\n",
    "X = pd.read_pickle(f'{data_folder}/X_encoded_scaled.pkl').astype(np.float32)\n",
    "test = pd.read_pickle(f'{data_folder}/test_encoded_scaled.pkl').astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:29.060598Z",
     "start_time": "2019-09-06T17:37:28.742644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting model_folder\n",
    "model_name = 'keras-4'\n",
    "model_folder = f'{main_learning_folder}/{model_name}'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:29.710584Z",
     "start_time": "2019-09-06T17:37:29.560584Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=n_fold)\n",
    "# folds = GroupKFold(n_splits=5)\n",
    "# groups = pd.read_pickle('./groups.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:30.380569Z",
     "start_time": "2019-09-06T17:37:30.210572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569877\n",
       "1     20663\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:31.051569Z",
     "start_time": "2019-09-06T17:37:30.888570Z"
    }
   },
   "outputs": [],
   "source": [
    "def NNModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[X.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "\n",
    "    x = Dense(400, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(200, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 8192,\n",
    "    'epochs': 60,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:31.728584Z",
     "start_time": "2019-09-06T17:37:31.569583Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:37:35.595120Z",
     "start_time": "2019-09-06T17:37:32.231569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 20:37:32.378583 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0906 20:37:32.379570 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0906 20:37:32.432199 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0906 20:37:32.433181 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0906 20:37:32.441186 13944 deprecation.py:506] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0906 20:37:32.457175 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0906 20:37:32.589662 13944 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0906 20:37:32.595660 13944 deprecation.py:323] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "NNModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:43:08.972721Z",
     "start_time": "2019-09-06T17:43:08.774721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2422684412784766773, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6696213545\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10341058718385918652\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:07:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:42:59.877301Z",
     "start_time": "2019-09-06T17:42:59.670300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:44:33.421022Z",
     "start_time": "2019-09-06T17:44:33.213679Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:44:39.033996Z",
     "start_time": "2019-09-06T17:44:38.838012Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:05.302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Sep  6 21:23:07 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.6592 - val_loss: 0.6178\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.4463 - val_loss: 0.4971\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.3049 - val_loss: 0.3780\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.2237 - val_loss: 0.2995\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1780 - val_loss: 0.2453\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1515 - val_loss: 0.1896\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1354 - val_loss: 0.1763\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1259 - val_loss: 0.1446\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1183 - val_loss: 0.1331\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1129 - val_loss: 0.1062\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1082 - val_loss: 0.1027\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1044 - val_loss: 0.0931\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.1012 - val_loss: 0.0914\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0991 - val_loss: 0.0894\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0960 - val_loss: 0.0890\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0939 - val_loss: 0.0827\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0920 - val_loss: 0.0854\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0905 - val_loss: 0.0817\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0891 - val_loss: 0.0841\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0876 - val_loss: 0.0825\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0868 - val_loss: 0.0797\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0852 - val_loss: 0.0807\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0848 - val_loss: 0.0772\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0836 - val_loss: 0.0782\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0827 - val_loss: 0.0769\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0821 - val_loss: 0.0771\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0812 - val_loss: 0.0774\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0809 - val_loss: 0.0747\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0801 - val_loss: 0.0718\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0792 - val_loss: 0.0748\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0793 - val_loss: 0.0712\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0783 - val_loss: 0.0704\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0779 - val_loss: 0.0721\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0774 - val_loss: 0.0656\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0768 - val_loss: 0.0671\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0766 - val_loss: 0.0655\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0758 - val_loss: 0.0629\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0755 - val_loss: 0.0635\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0754 - val_loss: 0.0627\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0745 - val_loss: 0.0635\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0743 - val_loss: 0.0643\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0737 - val_loss: 0.0631\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0735 - val_loss: 0.0653\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0724 - val_loss: 0.0637\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0729 - val_loss: 0.0616\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0720 - val_loss: 0.0633\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0722 - val_loss: 0.0659\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0719 - val_loss: 0.0642\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0716 - val_loss: 0.0640\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0712 - val_loss: 0.0625\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0710 - val_loss: 0.0621\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0701 - val_loss: 0.0620\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0701 - val_loss: 0.0621\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0694 - val_loss: 0.0634\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0694 - val_loss: 0.0638\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0693 - val_loss: 0.0611\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0682 - val_loss: 0.0643\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0686 - val_loss: 0.0625\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0684 - val_loss: 0.0616\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0679 - val_loss: 0.0630\n",
      "118108/118108 [==============================] - 1s 11us/step\n",
      "Fold 0. auc: 0.9290.\n",
      "Fold 2 started at Fri Sep  6 21:45:12 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.6826 - val_loss: 0.5863\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.4944 - val_loss: 0.3855\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.3416 - val_loss: 0.2569\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.2412 - val_loss: 0.1949\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1857 - val_loss: 0.1632\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1533 - val_loss: 0.1431\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1351 - val_loss: 0.1309\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1237 - val_loss: 0.1217\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.1152 - val_loss: 0.1173\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.1084 - val_loss: 0.1111\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1033 - val_loss: 0.1073\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0994 - val_loss: 0.1021\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0964 - val_loss: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0935 - val_loss: 0.0964\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0909 - val_loss: 0.0952\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0887 - val_loss: 0.0940\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0867 - val_loss: 0.0898\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0854 - val_loss: 0.0885\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0836 - val_loss: 0.0864\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0828 - val_loss: 0.0871\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0811 - val_loss: 0.0858\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0801 - val_loss: 0.0863\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0794 - val_loss: 0.0853\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0784 - val_loss: 0.0836\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0774 - val_loss: 0.0840\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0773 - val_loss: 0.0825\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0768 - val_loss: 0.0826\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0758 - val_loss: 0.0826\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0754 - val_loss: 0.0823\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0753 - val_loss: 0.0806\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0743 - val_loss: 0.0816\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0742 - val_loss: 0.0807\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0735 - val_loss: 0.0810\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0728 - val_loss: 0.0799\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0724 - val_loss: 0.0819\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0719 - val_loss: 0.0800\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 20s 41us/step - loss: 0.0714 - val_loss: 0.0789\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0712 - val_loss: 0.0790\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0702 - val_loss: 0.0799\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0701 - val_loss: 0.0785\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0701 - val_loss: 0.0787\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0693 - val_loss: 0.0785\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0688 - val_loss: 0.0775\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0689 - val_loss: 0.0788\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0682 - val_loss: 0.0774\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0678 - val_loss: 0.0777\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0679 - val_loss: 0.0775\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0669 - val_loss: 0.0784\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 26s 54us/step - loss: 0.0668 - val_loss: 0.0770\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0668 - val_loss: 0.0765\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0662 - val_loss: 0.0770\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0659 - val_loss: 0.0772\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0661 - val_loss: 0.0767\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0652 - val_loss: 0.0760\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0650 - val_loss: 0.0767\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0648 - val_loss: 0.0766\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0649 - val_loss: 0.0769\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0642 - val_loss: 0.0759\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0641 - val_loss: 0.0773\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0637 - val_loss: 0.0766\n",
      "118108/118108 [==============================] - 1s 10us/step\n",
      "Fold 1. auc: 0.9438.\n",
      "Fold 3 started at Fri Sep  6 22:07:34 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.6829 - val_loss: 0.5593\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.4832 - val_loss: 0.3635\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.3260 - val_loss: 0.2323\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.2294 - val_loss: 0.1807\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1769 - val_loss: 0.1548\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1475 - val_loss: 0.1366\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.1306 - val_loss: 0.1231\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.1208 - val_loss: 0.1155\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1133 - val_loss: 0.1102\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.1078 - val_loss: 0.1058\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.1038 - val_loss: 0.1019\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1000 - val_loss: 0.0986\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0971 - val_loss: 0.0954\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0942 - val_loss: 0.0938\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0916 - val_loss: 0.0914\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0899 - val_loss: 0.0890\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0877 - val_loss: 0.0882\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0861 - val_loss: 0.0869\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0847 - val_loss: 0.0859\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0836 - val_loss: 0.0848\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0823 - val_loss: 0.0834\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0808 - val_loss: 0.0826\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0801 - val_loss: 0.0822\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0791 - val_loss: 0.0823\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0789 - val_loss: 0.0831\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0780 - val_loss: 0.0805\n",
      "Epoch 27/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0772 - val_loss: 0.0810\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0765 - val_loss: 0.0801\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0756 - val_loss: 0.0797\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0741 - val_loss: 0.0787\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0744 - val_loss: 0.0784\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0731 - val_loss: 0.0778\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0729 - val_loss: 0.0782\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0724 - val_loss: 0.0776\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0729 - val_loss: 0.0771\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0719 - val_loss: 0.0772\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0715 - val_loss: 0.0771\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0708 - val_loss: 0.0774\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0707 - val_loss: 0.0769\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0707 - val_loss: 0.0761\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0702 - val_loss: 0.0757\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0693 - val_loss: 0.0761\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0697 - val_loss: 0.0756\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0691 - val_loss: 0.0754\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0685 - val_loss: 0.0756\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0682 - val_loss: 0.0751\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0679 - val_loss: 0.0754\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0679 - val_loss: 0.0751\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0677 - val_loss: 0.0751\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0672 - val_loss: 0.0752\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0665 - val_loss: 0.0750\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0669 - val_loss: 0.0744\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0665 - val_loss: 0.0748\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0657 - val_loss: 0.0742\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0657 - val_loss: 0.0746\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0652 - val_loss: 0.0740\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0647 - val_loss: 0.0745\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0656 - val_loss: 0.0740\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0645 - val_loss: 0.0743\n",
      "118108/118108 [==============================] - 1s 9us/step\n",
      "Fold 2. auc: 0.9398.\n",
      "Fold 4 started at Fri Sep  6 22:25:35 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.6899 - val_loss: 0.6790\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.5030 - val_loss: 0.4536\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.3540 - val_loss: 0.2916\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.2510 - val_loss: 0.2080\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1904 - val_loss: 0.1706\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1568 - val_loss: 0.1472\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1364 - val_loss: 0.1341\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.1237 - val_loss: 0.1252\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1152 - val_loss: 0.1177\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1079 - val_loss: 0.1124\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.1035 - val_loss: 0.1078\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0993 - val_loss: 0.1038\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0965 - val_loss: 0.1017\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0934 - val_loss: 0.0991\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0908 - val_loss: 0.0966\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0891 - val_loss: 0.0944\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0865 - val_loss: 0.0940\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0856 - val_loss: 0.0886\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0839 - val_loss: 0.0894\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0827 - val_loss: 0.0887\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0819 - val_loss: 0.0896\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0816 - val_loss: 0.0865\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0797 - val_loss: 0.0843\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0793 - val_loss: 0.0851\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0789 - val_loss: 0.0843\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 26s 54us/step - loss: 0.0780 - val_loss: 0.0841\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0771 - val_loss: 0.0837\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0766 - val_loss: 0.0824\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0758 - val_loss: 0.0819\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.0760 - val_loss: 0.0824\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0751 - val_loss: 0.0815\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0744 - val_loss: 0.0813\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0734 - val_loss: 0.0805\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0734 - val_loss: 0.0804\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0729 - val_loss: 0.0794\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0728 - val_loss: 0.0787\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0729 - val_loss: 0.0802\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0716 - val_loss: 0.0784\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0716 - val_loss: 0.0791\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0712 - val_loss: 0.0792\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0703 - val_loss: 0.0798\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0707 - val_loss: 0.0788\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0700 - val_loss: 0.0782\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0696 - val_loss: 0.0783\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0689 - val_loss: 0.0781\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 113s 240us/step - loss: 0.0686 - val_loss: 0.0771\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 196s 415us/step - loss: 0.0681 - val_loss: 0.0767\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 203s 430us/step - loss: 0.0681 - val_loss: 0.0776\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 195s 413us/step - loss: 0.0678 - val_loss: 0.0773\n",
      "Epoch 50/60\n",
      "311296/472432 [==================>...........] - ETA: 1:03 - loss: 0.0671"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=NNModel_maker, \n",
    "                                             X=X,\n",
    "                                             X_test=test,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:06.851Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:07.327Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv(f'{model_folder}/ieee_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:07.831Z"
    }
   },
   "outputs": [],
   "source": [
    "result_dict_keras['prediction'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:08.809Z"
    }
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T18:23:10.378Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "754px",
    "left": "1526px",
    "right": "20px",
    "top": "96px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
