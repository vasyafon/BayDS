{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:25.507819Z",
     "start_time": "2019-09-06T21:30:21.096822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.layers import Concatenate, Input, Dense, Embedding, Flatten, Dropout, BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "import keras.backend as k\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# pd.options.display.precision = 15\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import time\n",
    "# import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "# from sklearn import metrics\n",
    "# from sklearn import linear_model\n",
    "import gc\n",
    "import pickle\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import eli5\n",
    "# import shap\n",
    "# from IPython.display import HTML\n",
    "# import json\n",
    "# import altair as alt\n",
    "\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:25.664824Z",
     "start_time": "2019-09-06T21:30:25.509821Z"
    }
   },
   "outputs": [],
   "source": [
    "main_path = r'f:\\my\\Prog\\kaggle\\Baydin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:26.864834Z",
     "start_time": "2019-09-06T21:30:25.666820Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:27.019821Z",
     "start_time": "2019-09-06T21:30:26.865819Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = '31.08'\n",
    "main_learning_folder = main_path+'/Snapshots/'+experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:44.540086Z",
     "start_time": "2019-09-06T21:30:27.020820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start here\n",
    "data_folder = main_path+'/Data'\n",
    "y = pd.read_pickle(f'{data_folder}/y.pkl')\n",
    "X = pd.read_pickle(f'{data_folder}/X_encoded_scaled.pkl').astype(np.float32)\n",
    "test = pd.read_pickle(f'{data_folder}/test_encoded_scaled.pkl').astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:19:10.787215Z",
     "start_time": "2019-09-07T06:19:10.165434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting model_folder\n",
    "model_name = 'keras-4Layer'\n",
    "model_folder = f'{main_learning_folder}/{model_name}'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:44.913100Z",
     "start_time": "2019-09-06T21:30:44.760086Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=n_fold)\n",
    "# folds = GroupKFold(n_splits=5)\n",
    "# groups = pd.read_pickle('./groups.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:45.095090Z",
     "start_time": "2019-09-06T21:30:44.914086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569877\n",
       "1     20663\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:55:54.305544Z",
     "start_time": "2019-09-07T06:55:54.149543Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l1,l2\n",
    "\n",
    "def NNModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[X.shape[1]], name = 'all')\n",
    "    x = numerical_inputs\n",
    "    x = Dense(400, activation = 'relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(400, activation = 'relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(200, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(100, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)     \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 100,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:55:46.167255Z",
     "start_time": "2019-09-07T06:55:46.014245Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:56:00.190591Z",
     "start_time": "2019-09-07T06:55:58.668787Z"
    }
   },
   "outputs": [],
   "source": [
    "NNModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:19:45.936140Z",
     "start_time": "2019-09-07T06:19:45.740140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2295671409795812128, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6696213545\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 943391395817768365\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:07:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T06:19:48.676283Z",
     "start_time": "2019-09-07T06:19:48.524282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:48.727542Z",
     "start_time": "2019-09-06T21:30:48.529971Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T21:30:48.918816Z",
     "start_time": "2019-09-06T21:30:48.728538Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T10:11:42.699873Z",
     "start_time": "2019-09-07T06:56:02.669274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sat Sep  7 09:56:03 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.9473 - val_loss: 0.5850\n",
      "Epoch 2/100\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.3459 - val_loss: 0.2370\n",
      "Epoch 3/100\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.1950 - val_loss: 0.1525\n",
      "Epoch 4/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1387 - val_loss: 0.1360\n",
      "Epoch 5/100\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.1155 - val_loss: 0.0943\n",
      "Epoch 6/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.1024 - val_loss: 0.0869\n",
      "Epoch 7/100\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0961 - val_loss: 0.0926\n",
      "Epoch 8/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0925 - val_loss: 0.0866\n",
      "Epoch 9/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0900 - val_loss: 0.0871\n",
      "Epoch 10/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0873 - val_loss: 0.0810\n",
      "Epoch 11/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0868 - val_loss: 0.0781\n",
      "Epoch 12/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0857 - val_loss: 0.0781\n",
      "Epoch 13/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0845 - val_loss: 0.0893\n",
      "Epoch 14/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0834 - val_loss: 0.0846\n",
      "Epoch 15/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0829 - val_loss: 0.0808\n",
      "Epoch 16/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0823 - val_loss: 0.0746\n",
      "Epoch 17/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0819 - val_loss: 0.0820\n",
      "Epoch 18/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0814 - val_loss: 0.0793\n",
      "Epoch 19/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0809 - val_loss: 0.0747\n",
      "Epoch 20/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0806 - val_loss: 0.0787\n",
      "Epoch 21/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0803 - val_loss: 0.0797\n",
      "Epoch 22/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0796 - val_loss: 0.0799\n",
      "Epoch 23/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0792 - val_loss: 0.0776\n",
      "Epoch 24/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0790 - val_loss: 0.0756\n",
      "Epoch 25/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0787 - val_loss: 0.0787\n",
      "Epoch 26/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0783 - val_loss: 0.0765\n",
      "Epoch 27/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0785 - val_loss: 0.0747\n",
      "Epoch 28/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0787 - val_loss: 0.0750\n",
      "Epoch 29/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0781 - val_loss: 0.0751\n",
      "Epoch 30/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0784 - val_loss: 0.0763\n",
      "Epoch 31/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0776 - val_loss: 0.0779\n",
      "Epoch 32/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0780 - val_loss: 0.0769\n",
      "Epoch 33/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0775 - val_loss: 0.0794\n",
      "Epoch 34/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0777 - val_loss: 0.0734\n",
      "Epoch 35/100\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0773 - val_loss: 0.0812\n",
      "Epoch 36/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0774 - val_loss: 0.0774\n",
      "Epoch 37/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0774 - val_loss: 0.0761\n",
      "Epoch 38/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 39/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0766 - val_loss: 0.0832\n",
      "Epoch 40/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0767 - val_loss: 0.0868\n",
      "Epoch 41/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0770 - val_loss: 0.0755\n",
      "Epoch 42/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0767 - val_loss: 0.0766\n",
      "Epoch 43/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0764 - val_loss: 0.0787\n",
      "Epoch 44/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0762 - val_loss: 0.0768\n",
      "Epoch 45/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0761 - val_loss: 0.0778\n",
      "Epoch 46/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0760 - val_loss: 0.0777\n",
      "Epoch 47/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0764 - val_loss: 0.0775\n",
      "Epoch 48/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0758 - val_loss: 0.0786\n",
      "Epoch 49/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0760 - val_loss: 0.0821\n",
      "Epoch 50/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0761 - val_loss: 0.0769\n",
      "Epoch 51/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0755 - val_loss: 0.0761\n",
      "Epoch 52/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0760 - val_loss: 0.0772\n",
      "Epoch 53/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0756 - val_loss: 0.0785\n",
      "Epoch 54/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0757 - val_loss: 0.0771\n",
      "Epoch 55/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0758 - val_loss: 0.0773\n",
      "Epoch 56/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0755 - val_loss: 0.0799\n",
      "Epoch 57/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0756 - val_loss: 0.0753\n",
      "Epoch 58/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0756 - val_loss: 0.0756\n",
      "Epoch 59/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0750 - val_loss: 0.0743\n",
      "Epoch 60/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 61/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0759 - val_loss: 0.0770\n",
      "Epoch 62/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0751 - val_loss: 0.0752\n",
      "Epoch 63/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0754 - val_loss: 0.0748\n",
      "Epoch 64/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0748 - val_loss: 0.0715\n",
      "Epoch 65/100\n",
      "472432/472432 [==============================] - 22s 48us/step - loss: 0.0754 - val_loss: 0.0744\n",
      "Epoch 66/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0752 - val_loss: 0.0745\n",
      "Epoch 67/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0751 - val_loss: 0.0753\n",
      "Epoch 68/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0752 - val_loss: 0.0862\n",
      "Epoch 69/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0748 - val_loss: 0.0779\n",
      "Epoch 70/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0746 - val_loss: 0.0790\n",
      "Epoch 71/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0743 - val_loss: 0.0790\n",
      "Epoch 72/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0747 - val_loss: 0.0777\n",
      "Epoch 73/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0749 - val_loss: 0.0758\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0745 - val_loss: 0.0775\n",
      "Epoch 75/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0746 - val_loss: 0.0800\n",
      "Epoch 76/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0774\n",
      "Epoch 77/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0749 - val_loss: 0.0776\n",
      "Epoch 78/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0774\n",
      "Epoch 79/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0765\n",
      "Epoch 80/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0745 - val_loss: 0.0763\n",
      "Epoch 81/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0745 - val_loss: 0.0780\n",
      "Epoch 82/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0747 - val_loss: 0.0800\n",
      "Epoch 83/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0744 - val_loss: 0.0804\n",
      "Epoch 84/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0739\n",
      "Epoch 85/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0748 - val_loss: 0.0744\n",
      "Epoch 86/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0742 - val_loss: 0.0787\n",
      "Epoch 87/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0745 - val_loss: 0.0858\n",
      "Epoch 88/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0775\n",
      "Epoch 89/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0743 - val_loss: 0.0754\n",
      "Epoch 90/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0746 - val_loss: 0.0761\n",
      "Epoch 91/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0745 - val_loss: 0.0753\n",
      "Epoch 92/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0745 - val_loss: 0.0773\n",
      "Epoch 93/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0746 - val_loss: 0.0780\n",
      "Epoch 94/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0740 - val_loss: 0.0804\n",
      "Epoch 95/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0744 - val_loss: 0.0740\n",
      "Epoch 96/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0741 - val_loss: 0.0739\n",
      "Epoch 97/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0743 - val_loss: 0.0760\n",
      "Epoch 98/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0746 - val_loss: 0.0730\n",
      "Epoch 99/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0741 - val_loss: 0.0800\n",
      "Epoch 100/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0743 - val_loss: 0.0772\n",
      "118108/118108 [==============================] - 1s 12us/step\n",
      "Fold 0. auc: 0.9205.\n",
      "Fold 2 started at Sat Sep  7 10:32:31 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.9666 - val_loss: 0.5096\n",
      "Epoch 2/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.3560 - val_loss: 0.2642\n",
      "Epoch 3/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.2015 - val_loss: 0.1690\n",
      "Epoch 4/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1419 - val_loss: 0.1364\n",
      "Epoch 5/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1139 - val_loss: 0.1170\n",
      "Epoch 6/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0994 - val_loss: 0.1082\n",
      "Epoch 7/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0928 - val_loss: 0.1070\n",
      "Epoch 8/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0880 - val_loss: 0.0997\n",
      "Epoch 9/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0849 - val_loss: 0.0947\n",
      "Epoch 10/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0838 - val_loss: 0.0955\n",
      "Epoch 11/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0817 - val_loss: 0.0964\n",
      "Epoch 12/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0812 - val_loss: 0.0977\n",
      "Epoch 13/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0800 - val_loss: 0.0982\n",
      "Epoch 14/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0791 - val_loss: 0.0962\n",
      "Epoch 15/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0787 - val_loss: 0.0918\n",
      "Epoch 16/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0782 - val_loss: 0.0934\n",
      "Epoch 17/100\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.0778 - val_loss: 0.0953\n",
      "Epoch 18/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0775 - val_loss: 0.0939\n",
      "Epoch 19/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0768 - val_loss: 0.0914\n",
      "Epoch 20/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0760 - val_loss: 0.0930\n",
      "Epoch 21/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0758 - val_loss: 0.0921\n",
      "Epoch 22/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0753 - val_loss: 0.0974\n",
      "Epoch 23/100\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0760 - val_loss: 0.0934\n",
      "Epoch 24/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0749 - val_loss: 0.0937\n",
      "Epoch 25/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0750 - val_loss: 0.0919\n",
      "Epoch 26/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0748 - val_loss: 0.0955\n",
      "Epoch 27/100\n",
      "472432/472432 [==============================] - 25s 54us/step - loss: 0.0743 - val_loss: 0.0945\n",
      "Epoch 28/100\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0741 - val_loss: 0.0912\n",
      "Epoch 29/100\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0740 - val_loss: 0.0902\n",
      "Epoch 30/100\n",
      "472432/472432 [==============================] - 22s 48us/step - loss: 0.0742 - val_loss: 0.0891\n",
      "Epoch 31/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 32/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0737 - val_loss: 0.0941\n",
      "Epoch 33/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0732 - val_loss: 0.0928\n",
      "Epoch 34/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0733 - val_loss: 0.0928\n",
      "Epoch 35/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0737 - val_loss: 0.0919\n",
      "Epoch 36/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0726 - val_loss: 0.0919\n",
      "Epoch 37/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0729 - val_loss: 0.0915\n",
      "Epoch 38/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0729 - val_loss: 0.0890\n",
      "Epoch 39/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0724 - val_loss: 0.0918\n",
      "Epoch 40/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0724 - val_loss: 0.0925\n",
      "Epoch 41/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0726 - val_loss: 0.0946\n",
      "Epoch 42/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0728 - val_loss: 0.0947\n",
      "Epoch 43/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0726 - val_loss: 0.0946\n",
      "Epoch 44/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0719 - val_loss: 0.0923\n",
      "Epoch 45/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0721 - val_loss: 0.0970\n",
      "Epoch 46/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0725 - val_loss: 0.0920\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0724 - val_loss: 0.0938\n",
      "Epoch 48/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0721 - val_loss: 0.0962\n",
      "Epoch 49/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0716 - val_loss: 0.0907\n",
      "Epoch 50/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0717 - val_loss: 0.0915\n",
      "Epoch 51/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0721 - val_loss: 0.0907\n",
      "Epoch 52/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0718 - val_loss: 0.0916\n",
      "Epoch 53/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0714 - val_loss: 0.0901\n",
      "Epoch 54/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0720 - val_loss: 0.0924\n",
      "Epoch 55/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0712 - val_loss: 0.0936\n",
      "Epoch 56/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0716 - val_loss: 0.0943\n",
      "Epoch 57/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0717 - val_loss: 0.0900\n",
      "Epoch 58/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0717 - val_loss: 0.0913\n",
      "Epoch 59/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0717 - val_loss: 0.0921\n",
      "Epoch 60/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0715 - val_loss: 0.0928\n",
      "Epoch 61/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0715 - val_loss: 0.0921\n",
      "Epoch 62/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0711 - val_loss: 0.0915\n",
      "Epoch 63/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0710 - val_loss: 0.0931\n",
      "Epoch 64/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0709 - val_loss: 0.0904\n",
      "Epoch 65/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0712 - val_loss: 0.0912\n",
      "Epoch 66/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0714 - val_loss: 0.0918\n",
      "Epoch 67/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0709 - val_loss: 0.0894\n",
      "Epoch 68/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0711 - val_loss: 0.0942\n",
      "Epoch 69/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0709 - val_loss: 0.0907\n",
      "Epoch 70/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0707 - val_loss: 0.0920\n",
      "Epoch 71/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0707 - val_loss: 0.0967\n",
      "Epoch 72/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0707 - val_loss: 0.0916\n",
      "Epoch 73/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0706 - val_loss: 0.0911\n",
      "Epoch 74/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0704 - val_loss: 0.0930\n",
      "Epoch 75/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0708 - val_loss: 0.0923\n",
      "Epoch 76/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0705 - val_loss: 0.0961\n",
      "Epoch 77/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0705 - val_loss: 0.0945\n",
      "Epoch 78/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0703 - val_loss: 0.0913\n",
      "Epoch 79/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0709 - val_loss: 0.0911\n",
      "Epoch 80/100\n",
      "472432/472432 [==============================] - 30s 64us/step - loss: 0.0707 - val_loss: 0.0923\n",
      "Epoch 81/100\n",
      "472432/472432 [==============================] - 29s 62us/step - loss: 0.0703 - val_loss: 0.0983\n",
      "Epoch 82/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0708 - val_loss: 0.0937\n",
      "Epoch 83/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0704 - val_loss: 0.0918\n",
      "Epoch 84/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0703 - val_loss: 0.0895\n",
      "Epoch 85/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0708 - val_loss: 0.0886\n",
      "Epoch 86/100\n",
      "472432/472432 [==============================] - 25s 54us/step - loss: 0.0701 - val_loss: 0.0909\n",
      "Epoch 87/100\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0703 - val_loss: 0.0904\n",
      "Epoch 88/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0702 - val_loss: 0.0920\n",
      "Epoch 89/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0699 - val_loss: 0.0937\n",
      "Epoch 90/100\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0700 - val_loss: 0.0920\n",
      "Epoch 91/100\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 92/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0703 - val_loss: 0.0912\n",
      "Epoch 93/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0697 - val_loss: 0.0929\n",
      "Epoch 94/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0713 - val_loss: 0.0936\n",
      "Epoch 95/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0704 - val_loss: 0.0946\n",
      "Epoch 96/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0698 - val_loss: 0.0934\n",
      "Epoch 97/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0697 - val_loss: 0.0900\n",
      "Epoch 98/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 99/100\n",
      "472432/472432 [==============================] - 25s 54us/step - loss: 0.0707 - val_loss: 0.0892\n",
      "Epoch 100/100\n",
      "472432/472432 [==============================] - 29s 60us/step - loss: 0.0700 - val_loss: 0.0943\n",
      "118108/118108 [==============================] - 1s 12us/step\n",
      "Fold 1. auc: 0.9400.\n",
      "Fold 3 started at Sat Sep  7 11:10:03 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/100\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.9760 - val_loss: 0.5110\n",
      "Epoch 2/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.3538 - val_loss: 0.2543\n",
      "Epoch 3/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.1998 - val_loss: 0.1679\n",
      "Epoch 4/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.1384 - val_loss: 0.1288\n",
      "Epoch 5/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.1117 - val_loss: 0.1125\n",
      "Epoch 6/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0985 - val_loss: 0.1018\n",
      "Epoch 7/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0915 - val_loss: 0.0994\n",
      "Epoch 8/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0875 - val_loss: 0.0967\n",
      "Epoch 9/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0850 - val_loss: 0.0980\n",
      "Epoch 10/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0839 - val_loss: 0.0959\n",
      "Epoch 11/100\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0822 - val_loss: 0.0962\n",
      "Epoch 12/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0804 - val_loss: 0.1037\n",
      "Epoch 13/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0801 - val_loss: 0.0933\n",
      "Epoch 14/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0789 - val_loss: 0.0944\n",
      "Epoch 15/100\n",
      "472432/472432 [==============================] - 20s 42us/step - loss: 0.0787 - val_loss: 0.0917\n",
      "Epoch 16/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0778 - val_loss: 0.0960\n",
      "Epoch 17/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0773 - val_loss: 0.0946\n",
      "Epoch 18/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0768 - val_loss: 0.0912\n",
      "Epoch 19/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0761 - val_loss: 0.0918\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0758 - val_loss: 0.0917\n",
      "Epoch 21/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0759 - val_loss: 0.0929\n",
      "Epoch 22/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0753 - val_loss: 0.0941\n",
      "Epoch 23/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0751 - val_loss: 0.0991\n",
      "Epoch 24/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0749 - val_loss: 0.0916\n",
      "Epoch 25/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0748 - val_loss: 0.0904\n",
      "Epoch 26/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0748 - val_loss: 0.0926\n",
      "Epoch 27/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0747 - val_loss: 0.0927\n",
      "Epoch 28/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0742 - val_loss: 0.0947\n",
      "Epoch 29/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0741 - val_loss: 0.0910\n",
      "Epoch 30/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0741 - val_loss: 0.0921\n",
      "Epoch 31/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0737 - val_loss: 0.0912\n",
      "Epoch 32/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0739 - val_loss: 0.0901\n",
      "Epoch 33/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0736 - val_loss: 0.0910\n",
      "Epoch 34/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0733 - val_loss: 0.0893\n",
      "Epoch 35/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0734 - val_loss: 0.0938\n",
      "Epoch 36/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0729 - val_loss: 0.0917\n",
      "Epoch 37/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0735 - val_loss: 0.0926\n",
      "Epoch 38/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0730 - val_loss: 0.0907\n",
      "Epoch 39/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0726 - val_loss: 0.0935\n",
      "Epoch 40/100\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0728 - val_loss: 0.0923\n",
      "Epoch 41/100\n",
      "472432/472432 [==============================] - 31s 66us/step - loss: 0.0724 - val_loss: 0.0938\n",
      "Epoch 42/100\n",
      "472432/472432 [==============================] - 31s 66us/step - loss: 0.0724 - val_loss: 0.0912\n",
      "Epoch 43/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0726 - val_loss: 0.0914\n",
      "Epoch 44/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0721 - val_loss: 0.0924\n",
      "Epoch 45/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0723 - val_loss: 0.0908\n",
      "Epoch 46/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0717 - val_loss: 0.0955\n",
      "Epoch 47/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0723 - val_loss: 0.0921\n",
      "Epoch 48/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0721 - val_loss: 0.0923\n",
      "Epoch 49/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0723 - val_loss: 0.0918\n",
      "Epoch 50/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0720 - val_loss: 0.0918\n",
      "Epoch 51/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0721 - val_loss: 0.0904\n",
      "Epoch 52/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0720 - val_loss: 0.0935\n",
      "Epoch 53/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0715 - val_loss: 0.0888\n",
      "Epoch 54/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 55/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0718 - val_loss: 0.0963\n",
      "Epoch 56/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0715 - val_loss: 0.0909\n",
      "Epoch 57/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0718 - val_loss: 0.0906\n",
      "Epoch 58/100\n",
      "472432/472432 [==============================] - 29s 61us/step - loss: 0.0715 - val_loss: 0.0910\n",
      "Epoch 59/100\n",
      "472432/472432 [==============================] - 31s 65us/step - loss: 0.0719 - val_loss: 0.0925\n",
      "Epoch 60/100\n",
      "472432/472432 [==============================] - 31s 66us/step - loss: 0.0717 - val_loss: 0.0950\n",
      "Epoch 61/100\n",
      "472432/472432 [==============================] - 29s 61us/step - loss: 0.0712 - val_loss: 0.0925\n",
      "Epoch 62/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0714 - val_loss: 0.0925\n",
      "Epoch 63/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0712 - val_loss: 0.0913\n",
      "Epoch 64/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0709 - val_loss: 0.0914\n",
      "Epoch 65/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0710 - val_loss: 0.0919\n",
      "Epoch 66/100\n",
      "472432/472432 [==============================] - 31s 66us/step - loss: 0.0715 - val_loss: 0.0966\n",
      "Epoch 67/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0719 - val_loss: 0.0909\n",
      "Epoch 68/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0706 - val_loss: 0.0898\n",
      "Epoch 69/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0713 - val_loss: 0.0939\n",
      "Epoch 70/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0713 - val_loss: 0.0929\n",
      "Epoch 71/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0714 - val_loss: 0.0906\n",
      "Epoch 72/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0712 - val_loss: 0.0936\n",
      "Epoch 73/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0712 - val_loss: 0.0911\n",
      "Epoch 74/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0709 - val_loss: 0.0936\n",
      "Epoch 75/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0710 - val_loss: 0.0919\n",
      "Epoch 76/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0711 - val_loss: 0.0904\n",
      "Epoch 77/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0711 - val_loss: 0.0921\n",
      "Epoch 78/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0711 - val_loss: 0.0957\n",
      "Epoch 79/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 80/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 81/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0708 - val_loss: 0.0906\n",
      "Epoch 82/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0711 - val_loss: 0.0949\n",
      "Epoch 83/100\n",
      "472432/472432 [==============================] - 31s 65us/step - loss: 0.0709 - val_loss: 0.0911\n",
      "Epoch 84/100\n",
      "472432/472432 [==============================] - 32s 67us/step - loss: 0.0711 - val_loss: 0.0973\n",
      "Epoch 85/100\n",
      "472432/472432 [==============================] - 31s 66us/step - loss: 0.0705 - val_loss: 0.0946\n",
      "Epoch 86/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0711 - val_loss: 0.0945\n",
      "Epoch 87/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0705 - val_loss: 0.0930\n",
      "Epoch 88/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0706 - val_loss: 0.0926\n",
      "Epoch 89/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0711 - val_loss: 0.0925\n",
      "Epoch 90/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0699 - val_loss: 0.0913\n",
      "Epoch 91/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0708 - val_loss: 0.0982\n",
      "Epoch 92/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0707 - val_loss: 0.0947\n",
      "Epoch 93/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0714 - val_loss: 0.0944\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0711 - val_loss: 0.0936\n",
      "Epoch 95/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0708 - val_loss: 0.0941\n",
      "Epoch 96/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0704 - val_loss: 0.0909\n",
      "Epoch 97/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0703 - val_loss: 0.0925\n",
      "Epoch 98/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0704 - val_loss: 0.0964\n",
      "Epoch 99/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0708 - val_loss: 0.0937\n",
      "Epoch 100/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0704 - val_loss: 0.0916\n",
      "118108/118108 [==============================] - 1s 11us/step\n",
      "Fold 2. auc: 0.9266.\n",
      "Fold 4 started at Sat Sep  7 11:50:30 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.9400 - val_loss: 0.4810\n",
      "Epoch 2/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.3219 - val_loss: 0.2394\n",
      "Epoch 3/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1825 - val_loss: 0.1601\n",
      "Epoch 4/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1301 - val_loss: 0.1226\n",
      "Epoch 5/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1074 - val_loss: 0.1103\n",
      "Epoch 6/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0970 - val_loss: 0.1048\n",
      "Epoch 7/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0910 - val_loss: 0.1028\n",
      "Epoch 8/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0873 - val_loss: 0.0984\n",
      "Epoch 9/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0846 - val_loss: 0.0996\n",
      "Epoch 10/100\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0829 - val_loss: 0.0975\n",
      "Epoch 11/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0818 - val_loss: 0.0972\n",
      "Epoch 12/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0803 - val_loss: 0.0942\n",
      "Epoch 13/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0805 - val_loss: 0.0935\n",
      "Epoch 14/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0795 - val_loss: 0.0926\n",
      "Epoch 15/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0792 - val_loss: 0.0906\n",
      "Epoch 16/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0782 - val_loss: 0.0942\n",
      "Epoch 17/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0774 - val_loss: 0.0924\n",
      "Epoch 18/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0775 - val_loss: 0.0916\n",
      "Epoch 19/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0767 - val_loss: 0.0911\n",
      "Epoch 20/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0761 - val_loss: 0.0902\n",
      "Epoch 21/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0764 - val_loss: 0.0915\n",
      "Epoch 22/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0757 - val_loss: 0.0930\n",
      "Epoch 23/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0752 - val_loss: 0.0913\n",
      "Epoch 24/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0755 - val_loss: 0.0930\n",
      "Epoch 25/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0747 - val_loss: 0.0897\n",
      "Epoch 26/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0747 - val_loss: 0.0907\n",
      "Epoch 27/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0743 - val_loss: 0.0939\n",
      "Epoch 28/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0749 - val_loss: 0.0940\n",
      "Epoch 29/100\n",
      "472432/472432 [==============================] - 30s 64us/step - loss: 0.0745 - val_loss: 0.0899\n",
      "Epoch 30/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0745 - val_loss: 0.0914\n",
      "Epoch 31/100\n",
      "472432/472432 [==============================] - 30s 64us/step - loss: 0.0744 - val_loss: 0.0918\n",
      "Epoch 32/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0735 - val_loss: 0.0879\n",
      "Epoch 33/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0738 - val_loss: 0.0880\n",
      "Epoch 34/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0738 - val_loss: 0.0888\n",
      "Epoch 35/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0736 - val_loss: 0.0894\n",
      "Epoch 36/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0735 - val_loss: 0.0905\n",
      "Epoch 37/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 38/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0735 - val_loss: 0.0873\n",
      "Epoch 39/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0734 - val_loss: 0.0901\n",
      "Epoch 40/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0725 - val_loss: 0.0891\n",
      "Epoch 41/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0731 - val_loss: 0.0882\n",
      "Epoch 42/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0730 - val_loss: 0.0886\n",
      "Epoch 43/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0728 - val_loss: 0.0889\n",
      "Epoch 44/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0726 - val_loss: 0.0904\n",
      "Epoch 45/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0722 - val_loss: 0.0894\n",
      "Epoch 46/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 47/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0725 - val_loss: 0.0877\n",
      "Epoch 48/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0727 - val_loss: 0.0894\n",
      "Epoch 49/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0728 - val_loss: 0.0886\n",
      "Epoch 50/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0723 - val_loss: 0.0887\n",
      "Epoch 51/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0720 - val_loss: 0.0897\n",
      "Epoch 52/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0723 - val_loss: 0.0891\n",
      "Epoch 53/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0729 - val_loss: 0.0915\n",
      "Epoch 54/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0724 - val_loss: 0.0926\n",
      "Epoch 55/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0723 - val_loss: 0.0954\n",
      "Epoch 56/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0726 - val_loss: 0.0918\n",
      "Epoch 57/100\n",
      "472432/472432 [==============================] - 30s 63us/step - loss: 0.0721 - val_loss: 0.0891\n",
      "Epoch 58/100\n",
      "472432/472432 [==============================] - 30s 64us/step - loss: 0.0723 - val_loss: 0.0903\n",
      "Epoch 59/100\n",
      "472432/472432 [==============================] - 29s 62us/step - loss: 0.0720 - val_loss: 0.0940\n",
      "Epoch 60/100\n",
      "472432/472432 [==============================] - 29s 62us/step - loss: 0.0720 - val_loss: 0.0930\n",
      "Epoch 61/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0722 - val_loss: 0.0902\n",
      "Epoch 62/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0720 - val_loss: 0.0928\n",
      "Epoch 63/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0715 - val_loss: 0.0892\n",
      "Epoch 64/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0720 - val_loss: 0.0877\n",
      "Epoch 65/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0716 - val_loss: 0.0897\n",
      "Epoch 66/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0716 - val_loss: 0.0890\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0713 - val_loss: 0.0920\n",
      "Epoch 68/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0716 - val_loss: 0.0884\n",
      "Epoch 69/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0714 - val_loss: 0.0887\n",
      "Epoch 70/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0715 - val_loss: 0.0916\n",
      "Epoch 71/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0718 - val_loss: 0.0908\n",
      "Epoch 72/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0714 - val_loss: 0.0896\n",
      "Epoch 73/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0717 - val_loss: 0.0894\n",
      "Epoch 74/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0714 - val_loss: 0.0880\n",
      "Epoch 75/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0716 - val_loss: 0.0894\n",
      "Epoch 76/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0713 - val_loss: 0.0903\n",
      "Epoch 77/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0717 - val_loss: 0.0883\n",
      "Epoch 78/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0713 - val_loss: 0.0906\n",
      "Epoch 79/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0714 - val_loss: 0.0881\n",
      "Epoch 80/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0713 - val_loss: 0.0899\n",
      "Epoch 81/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0712 - val_loss: 0.0887\n",
      "Epoch 82/100\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0713 - val_loss: 0.0898\n",
      "Epoch 83/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0715 - val_loss: 0.0885\n",
      "Epoch 84/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0710 - val_loss: 0.0892\n",
      "Epoch 85/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0715 - val_loss: 0.0895\n",
      "Epoch 86/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0707 - val_loss: 0.0888\n",
      "Epoch 87/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0707 - val_loss: 0.0936\n",
      "Epoch 88/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0711 - val_loss: 0.0905\n",
      "Epoch 89/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0712 - val_loss: 0.0898\n",
      "Epoch 90/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0711 - val_loss: 0.0908\n",
      "Epoch 91/100\n",
      "472432/472432 [==============================] - 27s 56us/step - loss: 0.0709 - val_loss: 0.0925\n",
      "Epoch 92/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0712 - val_loss: 0.0884\n",
      "Epoch 93/100\n",
      "472432/472432 [==============================] - 26s 56us/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 94/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0710 - val_loss: 0.0881\n",
      "Epoch 95/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0706 - val_loss: 0.0899\n",
      "Epoch 96/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0713 - val_loss: 0.0858\n",
      "Epoch 97/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0706 - val_loss: 0.0925\n",
      "Epoch 98/100\n",
      "472432/472432 [==============================] - 29s 62us/step - loss: 0.0713 - val_loss: 0.0881\n",
      "Epoch 99/100\n",
      "472432/472432 [==============================] - 31s 65us/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 100/100\n",
      "472432/472432 [==============================] - 31s 65us/step - loss: 0.0708 - val_loss: 0.0879\n",
      "118108/118108 [==============================] - 1s 12us/step\n",
      "Fold 3. auc: 0.9463.\n",
      "Fold 5 started at Sat Sep  7 12:32:41 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/100\n",
      "472432/472432 [==============================] - 32s 67us/step - loss: 0.9464 - val_loss: 0.5016\n",
      "Epoch 2/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.3463 - val_loss: 0.2547\n",
      "Epoch 3/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1956 - val_loss: 0.1725\n",
      "Epoch 4/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1388 - val_loss: 0.1413\n",
      "Epoch 5/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.1138 - val_loss: 0.1144\n",
      "Epoch 6/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.1003 - val_loss: 0.1067\n",
      "Epoch 7/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0929 - val_loss: 0.1308\n",
      "Epoch 8/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0888 - val_loss: 0.1025\n",
      "Epoch 9/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0861 - val_loss: 0.0991\n",
      "Epoch 10/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0841 - val_loss: 0.0976\n",
      "Epoch 11/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0826 - val_loss: 0.0989\n",
      "Epoch 12/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0815 - val_loss: 0.1015\n",
      "Epoch 13/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0803 - val_loss: 0.0987\n",
      "Epoch 14/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0797 - val_loss: 0.0988\n",
      "Epoch 15/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0795 - val_loss: 0.1061\n",
      "Epoch 16/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0778 - val_loss: 0.1010\n",
      "Epoch 17/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0777 - val_loss: 0.1025\n",
      "Epoch 18/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0769 - val_loss: 0.0956\n",
      "Epoch 19/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0771 - val_loss: 0.0986\n",
      "Epoch 20/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0766 - val_loss: 0.0961\n",
      "Epoch 21/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0758 - val_loss: 0.0963\n",
      "Epoch 22/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0759 - val_loss: 0.0965\n",
      "Epoch 23/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0755 - val_loss: 0.1001\n",
      "Epoch 24/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0758 - val_loss: 0.0973\n",
      "Epoch 25/100\n",
      "472432/472432 [==============================] - 21s 44us/step - loss: 0.0753 - val_loss: 0.0964\n",
      "Epoch 26/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0749 - val_loss: 0.1001\n",
      "Epoch 27/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0750 - val_loss: 0.0989\n",
      "Epoch 28/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0749 - val_loss: 0.0965\n",
      "Epoch 29/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0743 - val_loss: 0.0964\n",
      "Epoch 30/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0744 - val_loss: 0.0974\n",
      "Epoch 31/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0743 - val_loss: 0.0981\n",
      "Epoch 32/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0741 - val_loss: 0.0999\n",
      "Epoch 33/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0738 - val_loss: 0.0986\n",
      "Epoch 34/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0739 - val_loss: 0.1004\n",
      "Epoch 35/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0733 - val_loss: 0.0991\n",
      "Epoch 36/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0732 - val_loss: 0.1026\n",
      "Epoch 37/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0731 - val_loss: 0.0993\n",
      "Epoch 38/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0735 - val_loss: 0.0974\n",
      "Epoch 39/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0731 - val_loss: 0.0969\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0730 - val_loss: 0.0955\n",
      "Epoch 41/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0731 - val_loss: 0.1033\n",
      "Epoch 42/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0730 - val_loss: 0.0974\n",
      "Epoch 43/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0729 - val_loss: 0.0956\n",
      "Epoch 44/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0729 - val_loss: 0.0969\n",
      "Epoch 45/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0732 - val_loss: 0.0978\n",
      "Epoch 46/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0732 - val_loss: 0.0963\n",
      "Epoch 47/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0727 - val_loss: 0.0963\n",
      "Epoch 48/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0721 - val_loss: 0.0966\n",
      "Epoch 49/100\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0727 - val_loss: 0.0975\n",
      "Epoch 50/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0723 - val_loss: 0.1027\n",
      "Epoch 51/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0726 - val_loss: 0.0962\n",
      "Epoch 52/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0725 - val_loss: 0.0986\n",
      "Epoch 53/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0724 - val_loss: 0.0984\n",
      "Epoch 54/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0722 - val_loss: 0.0992\n",
      "Epoch 55/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0725 - val_loss: 0.0998\n",
      "Epoch 56/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0721 - val_loss: 0.0964\n",
      "Epoch 57/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0722 - val_loss: 0.0956\n",
      "Epoch 58/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0723 - val_loss: 0.0977\n",
      "Epoch 59/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0721 - val_loss: 0.0990\n",
      "Epoch 60/100\n",
      "472432/472432 [==============================] - 27s 57us/step - loss: 0.0725 - val_loss: 0.0988\n",
      "Epoch 61/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0719 - val_loss: 0.0968\n",
      "Epoch 62/100\n",
      "472432/472432 [==============================] - 28s 60us/step - loss: 0.0719 - val_loss: 0.0982\n",
      "Epoch 63/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0719 - val_loss: 0.0970\n",
      "Epoch 64/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0714 - val_loss: 0.0996\n",
      "Epoch 65/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0718 - val_loss: 0.1008\n",
      "Epoch 66/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0717 - val_loss: 0.0973\n",
      "Epoch 67/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0717 - val_loss: 0.0994\n",
      "Epoch 68/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0719 - val_loss: 0.0977\n",
      "Epoch 69/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0717 - val_loss: 0.1037\n",
      "Epoch 70/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0716 - val_loss: 0.1022\n",
      "Epoch 71/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0719 - val_loss: 0.0948\n",
      "Epoch 72/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0714 - val_loss: 0.0976\n",
      "Epoch 73/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0721 - val_loss: 0.0981\n",
      "Epoch 74/100\n",
      "472432/472432 [==============================] - 28s 58us/step - loss: 0.0716 - val_loss: 0.0981\n",
      "Epoch 75/100\n",
      "472432/472432 [==============================] - 28s 59us/step - loss: 0.0718 - val_loss: 0.0985\n",
      "Epoch 76/100\n",
      "472432/472432 [==============================] - 32s 67us/step - loss: 0.0718 - val_loss: 0.0998\n",
      "Epoch 77/100\n",
      "472432/472432 [==============================] - 32s 69us/step - loss: 0.0718 - val_loss: 0.0947\n",
      "Epoch 78/100\n",
      "472432/472432 [==============================] - 32s 68us/step - loss: 0.0711 - val_loss: 0.1052\n",
      "Epoch 79/100\n",
      "472432/472432 [==============================] - 32s 69us/step - loss: 0.0711 - val_loss: 0.0991\n",
      "Epoch 80/100\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0717 - val_loss: 0.0974\n",
      "Epoch 81/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0714 - val_loss: 0.0971\n",
      "Epoch 82/100\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0711 - val_loss: 0.1005\n",
      "Epoch 83/100\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0714 - val_loss: 0.0946\n",
      "Epoch 84/100\n",
      "472432/472432 [==============================] - 27s 58us/step - loss: 0.0710 - val_loss: 0.0943\n",
      "Epoch 85/100\n",
      "472432/472432 [==============================] - 29s 61us/step - loss: 0.0715 - val_loss: 0.0946\n",
      "Epoch 86/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0712 - val_loss: 0.0956\n",
      "Epoch 87/100\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0712 - val_loss: 0.1005\n",
      "Epoch 88/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0715 - val_loss: 0.1003\n",
      "Epoch 89/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0715 - val_loss: 0.0996\n",
      "Epoch 90/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0715 - val_loss: 0.1001\n",
      "Epoch 91/100\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.0708 - val_loss: 0.0987\n",
      "Epoch 92/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0712 - val_loss: 0.0954\n",
      "Epoch 93/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0709 - val_loss: 0.0972\n",
      "Epoch 94/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0712 - val_loss: 0.1014\n",
      "Epoch 95/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0711 - val_loss: 0.1005\n",
      "Epoch 96/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0710 - val_loss: 0.0962\n",
      "Epoch 97/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0712 - val_loss: 0.0953\n",
      "Epoch 98/100\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0713 - val_loss: 0.0953\n",
      "Epoch 99/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0712 - val_loss: 0.0949\n",
      "Epoch 100/100\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0714 - val_loss: 0.0954\n",
      "118108/118108 [==============================] - 1s 11us/step\n",
      "Fold 4. auc: 0.9257.\n",
      "CV mean score: 0.9318, std: 0.0097.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=NNModel_maker, \n",
    "                                             X=X,\n",
    "                                             X_test=test,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T12:09:11.222750Z",
     "start_time": "2019-09-07T12:09:09.407973Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T12:09:14.028767Z",
     "start_time": "2019-09-07T12:09:12.274751Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv(f'{model_folder}/ieee_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T12:09:15.226753Z",
     "start_time": "2019-09-07T12:09:15.063755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_keras['prediction'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T12:09:16.466751Z",
     "start_time": "2019-09-07T12:09:16.315755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 789)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T12:09:17.687766Z",
     "start_time": "2019-09-07T12:09:17.510753Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "754px",
    "left": "1526px",
    "right": "20px",
    "top": "96px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
