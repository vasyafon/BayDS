{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:17:53.172707Z",
     "start_time": "2019-09-03T16:17:47.678234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.layers import Concatenate, Input, Dense, Embedding, Flatten, Dropout, BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "import keras.backend as k\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# pd.options.display.precision = 15\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import time\n",
    "# import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "# from sklearn import metrics\n",
    "# from sklearn import linear_model\n",
    "import gc\n",
    "import pickle\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import eli5\n",
    "# import shap\n",
    "# from IPython.display import HTML\n",
    "# import json\n",
    "# import altair as alt\n",
    "\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:17:53.380715Z",
     "start_time": "2019-09-03T16:17:53.174696Z"
    }
   },
   "outputs": [],
   "source": [
    "main_path = r'd:\\Documents\\Private\\Kaggle\\IEEEFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:17:54.340464Z",
     "start_time": "2019-09-03T16:17:53.383700Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:17:54.587399Z",
     "start_time": "2019-09-03T16:17:54.341453Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = '31.08'\n",
    "main_learning_folder = main_path+'/Snapshots/'+experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:06.425962Z",
     "start_time": "2019-09-03T16:17:54.589398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start here\n",
    "y = pd.read_pickle(f'{main_learning_folder}/y.pkl')\n",
    "X = pd.read_pickle(f'{main_learning_folder}/X_encoded_scaled.pkl').astype(np.float32)\n",
    "test = pd.read_pickle(f'{main_learning_folder}/test_encoded_scaled.pkl').astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:06.691968Z",
     "start_time": "2019-09-03T16:18:06.427932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting model_folder\n",
    "model_name = 'keras-3'\n",
    "model_folder = f'{main_learning_folder}/{model_name}'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:06.938952Z",
     "start_time": "2019-09-03T16:18:06.694936Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=n_fold)\n",
    "# folds = GroupKFold(n_splits=5)\n",
    "# groups = pd.read_pickle('./groups.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:07.207980Z",
     "start_time": "2019-09-03T16:18:06.941960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569877\n",
       "1     20663\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:07.454963Z",
     "start_time": "2019-09-03T16:18:07.209975Z"
    }
   },
   "outputs": [],
   "source": [
    "def NNModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[X.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "\n",
    "    x = Dense(200, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(100, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 8000,\n",
    "    'epochs': 60,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:07.715959Z",
     "start_time": "2019-09-03T16:18:07.457949Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:18:10.298825Z",
     "start_time": "2019-09-03T16:18:07.717958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "NNModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T20:17:05.242898Z",
     "start_time": "2019-09-02T20:17:04.964846Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:17.572470Z",
     "start_time": "2019-09-03T16:18:10.300780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Tue Sep  3 19:18:11 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.7004 - val_loss: 0.7936\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.5431 - val_loss: 0.6032\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.4225 - val_loss: 0.4820\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.3242 - val_loss: 0.3987\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.2539 - val_loss: 0.3143\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.2074 - val_loss: 0.2579\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.1754 - val_loss: 0.2498\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.1550 - val_loss: 0.1974\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1416 - val_loss: 0.1786\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1324 - val_loss: 0.1596\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1255 - val_loss: 0.1415\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1201 - val_loss: 0.1327\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1165 - val_loss: 0.1233\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1122 - val_loss: 0.1162\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1107 - val_loss: 0.1090\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1073 - val_loss: 0.1062\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1052 - val_loss: 0.1028\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1033 - val_loss: 0.1003\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1009 - val_loss: 0.0969\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0997 - val_loss: 0.0918\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0979 - val_loss: 0.0905\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0971 - val_loss: 0.0888\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0955 - val_loss: 0.0903\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0941 - val_loss: 0.0849\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0935 - val_loss: 0.0864\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0926 - val_loss: 0.0871\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0918 - val_loss: 0.0831\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0905 - val_loss: 0.0831\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0897 - val_loss: 0.0841\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0894 - val_loss: 0.0821\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0884 - val_loss: 0.0801\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0881 - val_loss: 0.0785\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0879 - val_loss: 0.0808\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0870 - val_loss: 0.0800\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0868 - val_loss: 0.0776\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0861 - val_loss: 0.0753\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0856 - val_loss: 0.0766\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0848 - val_loss: 0.0738\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0847 - val_loss: 0.0753\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0841 - val_loss: 0.0719\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0835 - val_loss: 0.0707\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0833 - val_loss: 0.0691\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0830 - val_loss: 0.0705\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0823 - val_loss: 0.0707\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0820 - val_loss: 0.0686\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0815 - val_loss: 0.0699\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0814 - val_loss: 0.0698\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0817 - val_loss: 0.0668\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0811 - val_loss: 0.0656\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0808 - val_loss: 0.0667\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0805 - val_loss: 0.0665\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0804 - val_loss: 0.0660\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0796 - val_loss: 0.0676\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0793 - val_loss: 0.0678\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0789 - val_loss: 0.0669\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0789 - val_loss: 0.0678\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0784 - val_loss: 0.0633\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0787 - val_loss: 0.0651\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0781 - val_loss: 0.0689\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0784 - val_loss: 0.0691\n",
      "118108/118108 [==============================] - 1s 6us/step\n",
      "Fold 0. auc: 0.9255.\n",
      "Fold 2 started at Tue Sep  3 19:34:14 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.7027 - val_loss: 0.5291\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.5524 - val_loss: 0.4273\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.4309 - val_loss: 0.3314\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.3290 - val_loss: 0.2620\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.2545 - val_loss: 0.2110\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.2041 - val_loss: 0.1818\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1722 - val_loss: 0.1596\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1514 - val_loss: 0.1418\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1378 - val_loss: 0.1326\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1285 - val_loss: 0.1256\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1225 - val_loss: 0.1209\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.1172 - val_loss: 0.1170\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1123 - val_loss: 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.1096 - val_loss: 0.1113\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1071 - val_loss: 0.1087\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1042 - val_loss: 0.1067\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.1021 - val_loss: 0.1050\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0993 - val_loss: 0.1031\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0968 - val_loss: 0.1019\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0950 - val_loss: 0.1013\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0926 - val_loss: 0.0976\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0920 - val_loss: 0.0963\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0906 - val_loss: 0.0946\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0901 - val_loss: 0.0945\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0887 - val_loss: 0.0921\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0878 - val_loss: 0.0920\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0877 - val_loss: 0.0910\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0873 - val_loss: 0.0914\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0857 - val_loss: 0.0918\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0855 - val_loss: 0.0916\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0846 - val_loss: 0.0892\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0843 - val_loss: 0.0884\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0839 - val_loss: 0.0875\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0826 - val_loss: 0.0864\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0823 - val_loss: 0.0866\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0825 - val_loss: 0.0870\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0819 - val_loss: 0.0872\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0818 - val_loss: 0.0871\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0809 - val_loss: 0.0855\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0805 - val_loss: 0.0851\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0797 - val_loss: 0.0846\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0799 - val_loss: 0.0847\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0793 - val_loss: 0.0850\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0796 - val_loss: 0.0857\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0784 - val_loss: 0.0842\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0783 - val_loss: 0.0834\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0777 - val_loss: 0.0835\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0773 - val_loss: 0.0831\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0776 - val_loss: 0.0839\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0770 - val_loss: 0.0823\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0765 - val_loss: 0.0820\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0766 - val_loss: 0.0831\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0766 - val_loss: 0.0824\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0761 - val_loss: 0.0829\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0760 - val_loss: 0.0815\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0758 - val_loss: 0.0811\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0752 - val_loss: 0.0816\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0748 - val_loss: 0.0811\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0752 - val_loss: 0.0811\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0741 - val_loss: 0.0810\n",
      "118108/118108 [==============================] - 1s 6us/step\n",
      "Fold 1. auc: 0.9369.\n",
      "Fold 3 started at Tue Sep  3 19:50:08 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.7302 - val_loss: 0.7055\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.5656 - val_loss: 0.5103\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.4391 - val_loss: 0.3691\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.3351 - val_loss: 0.2791\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.2582 - val_loss: 0.2250\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.2063 - val_loss: 0.1837\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1745 - val_loss: 0.1622\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1529 - val_loss: 0.1448\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1394 - val_loss: 0.1337\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1289 - val_loss: 0.1257\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1218 - val_loss: 0.1195\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1168 - val_loss: 0.1147\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1127 - val_loss: 0.1119\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1099 - val_loss: 0.1082\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1070 - val_loss: 0.1069\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1046 - val_loss: 0.1051\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1022 - val_loss: 0.1028\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.1010 - val_loss: 0.1002\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0992 - val_loss: 0.0989\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0972 - val_loss: 0.0976\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0958 - val_loss: 0.0954\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0946 - val_loss: 0.0946\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0938 - val_loss: 0.0942\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0924 - val_loss: 0.0931\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0915 - val_loss: 0.0926\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0906 - val_loss: 0.0911\n",
      "Epoch 27/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0890 - val_loss: 0.0908\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0886 - val_loss: 0.0900\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0874 - val_loss: 0.0887\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0868 - val_loss: 0.0878\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0865 - val_loss: 0.0876\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0857 - val_loss: 0.0865\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 19s 41us/step - loss: 0.0851 - val_loss: 0.0863\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0845 - val_loss: 0.0867\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0848 - val_loss: 0.0859\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0835 - val_loss: 0.0853\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0830 - val_loss: 0.0840\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0836 - val_loss: 0.0844\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0827 - val_loss: 0.0855\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0822 - val_loss: 0.0841\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0816 - val_loss: 0.0831\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0812 - val_loss: 0.0832\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0809 - val_loss: 0.0835\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0801 - val_loss: 0.0824\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0798 - val_loss: 0.0822\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0796 - val_loss: 0.0820\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0799 - val_loss: 0.0818\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0796 - val_loss: 0.0819\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0785 - val_loss: 0.0816\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0788 - val_loss: 0.0818\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 20s 43us/step - loss: 0.0787 - val_loss: 0.0811\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0777 - val_loss: 0.0809\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0770 - val_loss: 0.0805\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0771 - val_loss: 0.0802\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.0773 - val_loss: 0.0803\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0763 - val_loss: 0.0801\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0764 - val_loss: 0.0804\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0769 - val_loss: 0.0804\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0758 - val_loss: 0.0807\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0756 - val_loss: 0.0799\n",
      "118108/118108 [==============================] - 1s 6us/step\n",
      "Fold 2. auc: 0.9294.\n",
      "Fold 4 started at Tue Sep  3 20:06:49 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.7113 - val_loss: 0.7085\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.5704 - val_loss: 0.5461\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.4565 - val_loss: 0.4021\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.3519 - val_loss: 0.3073\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.2685 - val_loss: 0.2482\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.2119 - val_loss: 0.2049\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1760 - val_loss: 0.1788\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1521 - val_loss: 0.1560\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1369 - val_loss: 0.1430\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1272 - val_loss: 0.1323\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1200 - val_loss: 0.1275\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1140 - val_loss: 0.1202\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.1101 - val_loss: 0.1171\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.1072 - val_loss: 0.1142\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1050 - val_loss: 0.1116\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.1025 - val_loss: 0.1098\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0998 - val_loss: 0.1079\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0979 - val_loss: 0.1049\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0968 - val_loss: 0.1022\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0948 - val_loss: 0.1012\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0931 - val_loss: 0.0989\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0919 - val_loss: 0.0975\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0903 - val_loss: 0.0981\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0898 - val_loss: 0.0967\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0884 - val_loss: 0.0955\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0877 - val_loss: 0.0943\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0871 - val_loss: 0.0932\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0865 - val_loss: 0.0924\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0861 - val_loss: 0.0918\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0853 - val_loss: 0.0898\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0844 - val_loss: 0.0906\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0847 - val_loss: 0.0907\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0843 - val_loss: 0.0886\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0833 - val_loss: 0.0875\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0826 - val_loss: 0.0863\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0827 - val_loss: 0.0873\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0818 - val_loss: 0.0862\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0816 - val_loss: 0.0862\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0809 - val_loss: 0.0850\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0806 - val_loss: 0.0855\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0800 - val_loss: 0.0852\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0800 - val_loss: 0.0846\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 16s 35us/step - loss: 0.0794 - val_loss: 0.0842\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0789 - val_loss: 0.0840\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0786 - val_loss: 0.0842\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0782 - val_loss: 0.0838\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0783 - val_loss: 0.0832\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0778 - val_loss: 0.0836\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0777 - val_loss: 0.0824\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0772 - val_loss: 0.0821\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0765 - val_loss: 0.0821\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0766 - val_loss: 0.0808\n",
      "Epoch 53/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0756 - val_loss: 0.0819\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0758 - val_loss: 0.0812\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0757 - val_loss: 0.0805\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0754 - val_loss: 0.0811\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0752 - val_loss: 0.0809\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0757 - val_loss: 0.0808\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0747 - val_loss: 0.0796\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.0746 - val_loss: 0.0798\n",
      "118108/118108 [==============================] - 1s 6us/step\n",
      "Fold 3. auc: 0.9464.\n",
      "Fold 5 started at Tue Sep  3 20:23:45 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.7059 - val_loss: 0.5420\n",
      "Epoch 2/60\n",
      "472432/472432 [==============================] - 17s 35us/step - loss: 0.5521 - val_loss: 0.4371\n",
      "Epoch 3/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.4273 - val_loss: 0.3292\n",
      "Epoch 4/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.3278 - val_loss: 0.2740\n",
      "Epoch 5/60\n",
      "472432/472432 [==============================] - 18s 38us/step - loss: 0.2564 - val_loss: 0.2337\n",
      "Epoch 6/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.2073 - val_loss: 0.1953\n",
      "Epoch 7/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1743 - val_loss: 0.1741\n",
      "Epoch 8/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1529 - val_loss: 0.1571\n",
      "Epoch 9/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1390 - val_loss: 0.1437\n",
      "Epoch 10/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1291 - val_loss: 0.1320\n",
      "Epoch 11/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1221 - val_loss: 0.1249\n",
      "Epoch 12/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1166 - val_loss: 0.1220\n",
      "Epoch 13/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1128 - val_loss: 0.1162\n",
      "Epoch 14/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1095 - val_loss: 0.1130\n",
      "Epoch 15/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1072 - val_loss: 0.1097\n",
      "Epoch 16/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1050 - val_loss: 0.1079\n",
      "Epoch 17/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1034 - val_loss: 0.1043\n",
      "Epoch 18/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.1007 - val_loss: 0.1021\n",
      "Epoch 19/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0990 - val_loss: 0.1013\n",
      "Epoch 20/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0974 - val_loss: 0.0988\n",
      "Epoch 21/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0960 - val_loss: 0.0975\n",
      "Epoch 22/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0948 - val_loss: 0.0962\n",
      "Epoch 23/60\n",
      "472432/472432 [==============================] - 19s 39us/step - loss: 0.0935 - val_loss: 0.0951\n",
      "Epoch 24/60\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0929 - val_loss: 0.0943\n",
      "Epoch 25/60\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0913 - val_loss: 0.0927\n",
      "Epoch 26/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0904 - val_loss: 0.0919\n",
      "Epoch 27/60\n",
      "472432/472432 [==============================] - 21s 43us/step - loss: 0.0900 - val_loss: 0.0907\n",
      "Epoch 28/60\n",
      "472432/472432 [==============================] - 20s 41us/step - loss: 0.0884 - val_loss: 0.0899\n",
      "Epoch 29/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0879 - val_loss: 0.0898\n",
      "Epoch 30/60\n",
      "472432/472432 [==============================] - 19s 40us/step - loss: 0.0876 - val_loss: 0.0884\n",
      "Epoch 31/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0865 - val_loss: 0.0883\n",
      "Epoch 32/60\n",
      "472432/472432 [==============================] - 18s 37us/step - loss: 0.0857 - val_loss: 0.0875\n",
      "Epoch 33/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0858 - val_loss: 0.0869\n",
      "Epoch 34/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0859 - val_loss: 0.0866\n",
      "Epoch 35/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0852 - val_loss: 0.0863\n",
      "Epoch 36/60\n",
      "472432/472432 [==============================] - 18s 39us/step - loss: 0.0842 - val_loss: 0.0858\n",
      "Epoch 37/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0832 - val_loss: 0.0852\n",
      "Epoch 38/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0833 - val_loss: 0.0849\n",
      "Epoch 39/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0828 - val_loss: 0.0846\n",
      "Epoch 40/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0821 - val_loss: 0.0843\n",
      "Epoch 41/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0817 - val_loss: 0.0840\n",
      "Epoch 42/60\n",
      "472432/472432 [==============================] - 17s 36us/step - loss: 0.0813 - val_loss: 0.0838\n",
      "Epoch 43/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0814 - val_loss: 0.0833\n",
      "Epoch 44/60\n",
      "472432/472432 [==============================] - 17s 37us/step - loss: 0.0807 - val_loss: 0.0831\n",
      "Epoch 45/60\n",
      "472432/472432 [==============================] - 16s 34us/step - loss: 0.0800 - val_loss: 0.0825\n",
      "Epoch 46/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0802 - val_loss: 0.0831\n",
      "Epoch 47/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0801 - val_loss: 0.0822\n",
      "Epoch 48/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0790 - val_loss: 0.0828\n",
      "Epoch 49/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0788 - val_loss: 0.0821\n",
      "Epoch 50/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0787 - val_loss: 0.0822\n",
      "Epoch 51/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0783 - val_loss: 0.0819\n",
      "Epoch 52/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0778 - val_loss: 0.0814\n",
      "Epoch 53/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0775 - val_loss: 0.0809\n",
      "Epoch 54/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0770 - val_loss: 0.0812\n",
      "Epoch 55/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0772 - val_loss: 0.0812\n",
      "Epoch 56/60\n",
      "472432/472432 [==============================] - 15s 33us/step - loss: 0.0765 - val_loss: 0.0808\n",
      "Epoch 57/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0761 - val_loss: 0.0809\n",
      "Epoch 58/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0758 - val_loss: 0.0801\n",
      "Epoch 59/60\n",
      "472432/472432 [==============================] - 15s 32us/step - loss: 0.0758 - val_loss: 0.0803\n",
      "Epoch 60/60\n",
      "472432/472432 [==============================] - 16s 33us/step - loss: 0.0756 - val_loss: 0.0802\n",
      "118108/118108 [==============================] - 1s 6us/step\n",
      "Fold 4. auc: 0.9297.\n",
      "CV mean score: 0.9336, std: 0.0074.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=NNModel_maker, \n",
    "                                             X=X,\n",
    "                                             X_test=test,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:17.939526Z",
     "start_time": "2019-09-03T17:41:17.574457Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:20.103532Z",
     "start_time": "2019-09-03T17:41:17.941446Z"
    }
   },
   "outputs": [],
   "source": [
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv('ieee_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:20.350218Z",
     "start_time": "2019-09-03T17:41:20.105469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_keras['prediction'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:20.593194Z",
     "start_time": "2019-09-03T17:41:20.352194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 789)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:41:20.857195Z",
     "start_time": "2019-09-03T17:41:20.595191Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "754px",
    "left": "1526px",
    "right": "20px",
    "top": "96px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
