{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:08.816586Z",
     "start_time": "2019-09-06T20:34:08.655585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import sys\n",
    "main_path = r'../..'\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:08.971599Z",
     "start_time": "2019-09-06T20:34:08.818602Z"
    }
   },
   "outputs": [],
   "source": [
    "main_folder = r'f:\\my\\Prog\\kaggle\\Stacking_data'\n",
    "model_folder = r'f:\\my\\Prog\\kaggle\\Snapshots\\Stacking\\06.09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:28.159193Z",
     "start_time": "2019-09-06T20:34:08.972585Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(f'../../Data/train_09457_with_additions.pkl')\n",
    "test = pd.read_pickle(f'../../Data/test_09457_with_additions.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:28.323176Z",
     "start_time": "2019-09-06T20:34:28.160165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2987000, 2987001, 2987002, 2987003, 2987004, 2987005, 2987006,\n",
       "            2987007, 2987008, 2987009,\n",
       "            ...\n",
       "            3577530, 3577531, 3577532, 3577533, 3577534, 3577535, 3577536,\n",
       "            3577537, 3577538, 3577539],\n",
       "           dtype='int64', name='TransactionID', length=590540)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:29.989649Z",
     "start_time": "2019-09-06T20:34:28.324164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras-1 0.9424890970079728\n",
      "keras-3 0.9335847806217249\n",
      "lightgbm-0000 0.9214079716576545\n",
      "lightgbm-0001 0.9307534121273541\n",
      "lightgbm-0002 0.9057393914936828\n",
      "lightgbm-0003 0.9094343223387966\n",
      "lightgbm-0004 0.922207412827418\n",
      "lightgbm-0005 0.9326247096098855\n",
      "lightgbm-0006 0.919660639645335\n",
      "lightgbm-0007 0.9193543696157349\n",
      "lightgbm-0008 0.9343375118661627\n",
      "lightgbm-0009 0.9195492820489312\n",
      "lightgbm-0010 0.930241049291918\n",
      "lightgbm-0011 0.9320579425282656\n",
      "lightgbm-0012 0.9088114853323285\n",
      "logreg-0000 0.7427794669324287\n",
      "logreg-0001 0.7427636540388207\n",
      "logreg-0002 0.7214276072415384\n",
      "logreg-0003 0.7413343210679839\n",
      "logreg-0004 0.7233102020108867\n",
      "logreg-0005 0.7211794219810611\n"
     ]
    }
   ],
   "source": [
    "L = os.listdir(main_folder)\n",
    "oof = pd.DataFrame(index=train.index)\n",
    "prediction = pd.DataFrame(index=test.index)\n",
    "for experiment_name in L:\n",
    "    experiment_folder = os.path.join(main_folder,experiment_name)\n",
    "    if not os.path.exists(f'{experiment_folder}/results_dict.pkl'):\n",
    "        continue\n",
    "    results_dict = pd.read_pickle(f'{experiment_folder}/results_dict.pkl')\n",
    "    print(experiment_name, sum(results_dict['scores'])/len(results_dict['scores']))\n",
    "    oof[experiment_name] = results_dict['oof'][:,0]\n",
    "    prediction[experiment_name] = results_dict['prediction'][:,0]\n",
    "y = train.isFraud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:39.195647Z",
     "start_time": "2019-09-06T20:34:38.839648Z"
    }
   },
   "outputs": [],
   "source": [
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:53.755235Z",
     "start_time": "2019-09-06T20:34:53.607244Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:34:50.687848Z",
     "start_time": "2019-09-06T19:34:50.524837Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## LightGBM Stacking (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:34:27.632832Z",
     "start_time": "2019-09-06T19:32:10.594834Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Sep  6 22:32:11 2019\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.109891\ttraining's auc: 0.906504\tvalid_1's binary_logloss: 0.0839437\tvalid_1's auc: 0.899767\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's binary_logloss: 0.139285\ttraining's auc: 0.906217\tvalid_1's binary_logloss: 0.102694\tvalid_1's auc: 0.899856\n",
      "Fold 2 started at Fri Sep  6 22:33:04 2019\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.101532\ttraining's auc: 0.903072\tvalid_1's binary_logloss: 0.1142\tvalid_1's auc: 0.898168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d60985114f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                                          \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                          \u001b[0maveraging\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'averaging'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                                          n_jobs=-1, groups=None)\n\u001b[0m",
      "\u001b[1;32mf:\\my\\Prog\\kaggle\\Baydin\\BayDS\\training\\third_party.py\u001b[0m in \u001b[0;36mtrain_model_classification\u001b[1;34m(X, X_test, y, params, folds, model_type, eval_metric, columns, plot_feature_importance, model, verbose, early_stopping_rounds, n_estimators, splits, averaging, n_jobs, groups)\u001b[0m\n\u001b[0;32m    146\u001b[0m                       \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                       \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lgb_metric_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                       verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0my_pred_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \"\"\"\n\u001b[1;32m-> 1958\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2373\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2375\u001b[1;33m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(preds, dataset)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0margc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margc_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\my\\Prog\\kaggle\\Baydin\\BayDS\\training\\third_party.py\u001b[0m in \u001b[0;36meval_auc\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mFast\u001b[0m \u001b[0mauc\u001b[0m \u001b[0meval\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 1,\n",
    "    'min_child_weight': 10,\n",
    "    'lambda_l1':2,\n",
    "    'lambda_l2':3,\n",
    "    'min_data_in_leaf' :10,\n",
    "    'min_sum_hessian_in_leaf' : 0.0001,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'max_bin': 12,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_freq' : 100,\n",
    "    'min_gain_to_split': 0.1 }\n",
    "\n",
    "train_options = {\n",
    "    \"model_type\":'lgb',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'early_stopping_rounds': 500,\n",
    "    'n_estimators': 5000,\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "}\n",
    "\n",
    "\n",
    "result_dict_lgb = train_model_classification(X=oof, X_test=prediction, y=y, params=params, folds=folds,\n",
    "                                         model_type=train_options['model_type'], \n",
    "                                         eval_metric=train_options['eval_metric'],\n",
    "                                         plot_feature_importance=True,\n",
    "                                         verbose=500, early_stopping_rounds=train_options['early_stopping_rounds'],\n",
    "                                         n_estimators=train_options['n_estimators'], \n",
    "                                         averaging=train_options['averaging'],\n",
    "                                         n_jobs=-1, groups=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:35:20.278847Z",
     "start_time": "2019-09-06T19:35:20.115833Z"
    }
   },
   "source": [
    "## Keras Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:36:42.071411Z",
     "start_time": "2019-09-06T20:36:41.912426Z"
    }
   },
   "outputs": [],
   "source": [
    "def StackModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[oof.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "\n",
    "    x = Dense(50, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(10, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 16384,\n",
    "    'epochs': 120,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:36:43.981235Z",
     "start_time": "2019-09-06T20:36:43.825234Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n",
    "# StackModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:36:45.572804Z",
     "start_time": "2019-09-06T20:36:45.366807Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':4}, log_device_placement=False) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:44:59.345289Z",
     "start_time": "2019-09-06T20:36:47.870901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Sep  6 23:36:48 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/120\n",
      "472432/472432 [==============================] - ETA: 13s - loss: 0.76 - ETA: 3s - loss: 0.7664 - ETA: 1s - loss: 0.764 - ETA: 1s - loss: 0.759 - ETA: 0s - loss: 0.754 - ETA: 0s - loss: 0.750 - ETA: 0s - loss: 0.745 - ETA: 0s - loss: 0.742 - ETA: 0s - loss: 0.738 - ETA: 0s - loss: 0.734 - 1s 3us/step - loss: 0.7338 - val_loss: 0.6349\n",
      "Epoch 2/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.704 - ETA: 0s - loss: 0.696 - ETA: 0s - loss: 0.694 - ETA: 0s - loss: 0.691 - ETA: 0s - loss: 0.687 - ETA: 0s - loss: 0.684 - ETA: 0s - loss: 0.680 - ETA: 0s - loss: 0.677 - ETA: 0s - loss: 0.674 - ETA: 0s - loss: 0.672 - 1s 1us/step - loss: 0.6716 - val_loss: 0.6294\n",
      "Epoch 3/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.642 - ETA: 0s - loss: 0.642 - ETA: 0s - loss: 0.640 - ETA: 0s - loss: 0.638 - ETA: 0s - loss: 0.635 - ETA: 0s - loss: 0.632 - ETA: 0s - loss: 0.629 - ETA: 0s - loss: 0.627 - ETA: 0s - loss: 0.625 - ETA: 0s - loss: 0.623 - 1s 1us/step - loss: 0.6230 - val_loss: 0.6703\n",
      "Epoch 4/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.596 - ETA: 0s - loss: 0.598 - ETA: 0s - loss: 0.595 - ETA: 0s - loss: 0.595 - ETA: 0s - loss: 0.594 - ETA: 0s - loss: 0.593 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.588 - ETA: 0s - loss: 0.586 - 1s 1us/step - loss: 0.5857 - val_loss: 0.6514\n",
      "Epoch 5/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.574 - ETA: 0s - loss: 0.571 - ETA: 0s - loss: 0.569 - ETA: 0s - loss: 0.567 - ETA: 0s - loss: 0.566 - ETA: 0s - loss: 0.564 - ETA: 0s - loss: 0.563 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.560 - 1s 1us/step - loss: 0.5601 - val_loss: 0.6219\n",
      "Epoch 6/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.548 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.543 - ETA: 0s - loss: 0.541 - ETA: 0s - loss: 0.541 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.537 - 1s 1us/step - loss: 0.5374 - val_loss: 0.5998\n",
      "Epoch 7/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.523 - ETA: 0s - loss: 0.522 - ETA: 0s - loss: 0.521 - ETA: 0s - loss: 0.520 - ETA: 0s - loss: 0.519 - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.517 - ETA: 0s - loss: 0.517 - 1s 1us/step - loss: 0.5167 - val_loss: 0.5824\n",
      "Epoch 8/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.509 - ETA: 0s - loss: 0.505 - ETA: 0s - loss: 0.502 - ETA: 0s - loss: 0.503 - ETA: 0s - loss: 0.502 - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.500 - ETA: 0s - loss: 0.499 - ETA: 0s - loss: 0.498 - ETA: 0s - loss: 0.498 - 1s 1us/step - loss: 0.4977 - val_loss: 0.5653\n",
      "Epoch 9/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.487 - ETA: 0s - loss: 0.486 - ETA: 0s - loss: 0.486 - ETA: 0s - loss: 0.485 - ETA: 0s - loss: 0.484 - ETA: 0s - loss: 0.482 - ETA: 0s - loss: 0.481 - ETA: 0s - loss: 0.480 - ETA: 0s - loss: 0.479 - 1s 1us/step - loss: 0.4795 - val_loss: 0.5450\n",
      "Epoch 10/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.469 - ETA: 0s - loss: 0.468 - ETA: 0s - loss: 0.466 - ETA: 0s - loss: 0.467 - ETA: 0s - loss: 0.465 - ETA: 0s - loss: 0.465 - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.461 - 1s 1us/step - loss: 0.4607 - val_loss: 0.5196\n",
      "Epoch 11/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.446 - ETA: 0s - loss: 0.446 - ETA: 0s - loss: 0.445 - ETA: 0s - loss: 0.444 - ETA: 0s - loss: 0.443 - 1s 1us/step - loss: 0.4433 - val_loss: 0.4950\n",
      "Epoch 12/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.433 - ETA: 0s - loss: 0.431 - ETA: 0s - loss: 0.429 - ETA: 0s - loss: 0.427 - ETA: 0s - loss: 0.426 - ETA: 0s - loss: 0.425 - 1s 1us/step - loss: 0.4253 - val_loss: 0.4702\n",
      "Epoch 13/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.417 - ETA: 0s - loss: 0.415 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.413 - ETA: 0s - loss: 0.412 - ETA: 0s - loss: 0.412 - ETA: 0s - loss: 0.411 - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.409 - 1s 1us/step - loss: 0.4094 - val_loss: 0.4454\n",
      "Epoch 14/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.397 - ETA: 0s - loss: 0.396 - ETA: 0s - loss: 0.396 - ETA: 0s - loss: 0.395 - ETA: 0s - loss: 0.395 - ETA: 0s - loss: 0.395 - ETA: 0s - loss: 0.393 - ETA: 0s - loss: 0.392 - 1s 1us/step - loss: 0.3926 - val_loss: 0.4233\n",
      "Epoch 15/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.392 - ETA: 0s - loss: 0.386 - ETA: 0s - loss: 0.384 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.379 - ETA: 0s - loss: 0.379 - ETA: 0s - loss: 0.378 - ETA: 0s - loss: 0.377 - 1s 1us/step - loss: 0.3771 - val_loss: 0.4050\n",
      "Epoch 16/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.361 - 1s 1us/step - loss: 0.3616 - val_loss: 0.3853\n",
      "Epoch 17/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.353 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.346 - 1s 1us/step - loss: 0.3466 - val_loss: 0.3658\n",
      "Epoch 18/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.335 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.331 - 1s 1us/step - loss: 0.3317 - val_loss: 0.3499\n",
      "Epoch 19/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.321 - ETA: 0s - loss: 0.320 - ETA: 0s - loss: 0.319 - ETA: 0s - loss: 0.318 - ETA: 0s - loss: 0.318 - 1s 1us/step - loss: 0.3185 - val_loss: 0.3303\n",
      "Epoch 20/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.306 - ETA: 0s - loss: 0.305 - 1s 1us/step - loss: 0.3052 - val_loss: 0.3119\n",
      "Epoch 21/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.292 - 1s 1us/step - loss: 0.2919 - val_loss: 0.2978\n",
      "Epoch 22/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.286 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.280 - 1s 1us/step - loss: 0.2804 - val_loss: 0.2834\n",
      "Epoch 23/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.269 - 1s 1us/step - loss: 0.2689 - val_loss: 0.2675\n",
      "Epoch 24/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.258 - 1s 1us/step - loss: 0.2578 - val_loss: 0.2514\n",
      "Epoch 25/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - 1s 1us/step - loss: 0.2473 - val_loss: 0.2401\n",
      "Epoch 26/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.236 - 1s 1us/step - loss: 0.2367 - val_loss: 0.2307\n",
      "Epoch 27/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.234 - ETA: 0s - loss: 0.231 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.227 - 1s 1us/step - loss: 0.2280 - val_loss: 0.2180\n",
      "Epoch 28/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.219 - 1s 1us/step - loss: 0.2195 - val_loss: 0.2112\n",
      "Epoch 29/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - 1s 1us/step - loss: 0.2122 - val_loss: 0.2023\n",
      "Epoch 30/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - 1s 1us/step - loss: 0.2044 - val_loss: 0.1948\n",
      "Epoch 31/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - 1s 1us/step - loss: 0.1973 - val_loss: 0.1834\n",
      "Epoch 32/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.190 - 1s 1us/step - loss: 0.1900 - val_loss: 0.1750\n",
      "Epoch 33/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - 1s 1us/step - loss: 0.1844 - val_loss: 0.1716\n",
      "Epoch 34/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.178 - 1s 1us/step - loss: 0.1786 - val_loss: 0.1652\n",
      "Epoch 35/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - 1s 1us/step - loss: 0.1731 - val_loss: 0.1596\n",
      "Epoch 36/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - 1s 1us/step - loss: 0.1682 - val_loss: 0.1534\n",
      "Epoch 37/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - 1s 1us/step - loss: 0.1625 - val_loss: 0.1476\n",
      "Epoch 38/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.158 - 1s 1us/step - loss: 0.1587 - val_loss: 0.1422\n",
      "Epoch 39/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - 1s 1us/step - loss: 0.1546 - val_loss: 0.1374\n",
      "Epoch 40/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - 1s 1us/step - loss: 0.1511 - val_loss: 0.1292\n",
      "Epoch 41/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - 1s 1us/step - loss: 0.1473 - val_loss: 0.1265\n",
      "Epoch 42/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - 1s 1us/step - loss: 0.1429 - val_loss: 0.1242\n",
      "Epoch 43/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - 1s 1us/step - loss: 0.1401 - val_loss: 0.1198\n",
      "Epoch 44/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - 1s 1us/step - loss: 0.1374 - val_loss: 0.1177\n",
      "Epoch 45/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - 1s 1us/step - loss: 0.1341 - val_loss: 0.1142\n",
      "Epoch 46/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - 1s 2us/step - loss: 0.1319 - val_loss: 0.1139\n",
      "Epoch 47/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1293 - val_loss: 0.1091\n",
      "Epoch 48/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.127 - 1s 1us/step - loss: 0.1273 - val_loss: 0.1084\n",
      "Epoch 49/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 2us/step - loss: 0.1252 - val_loss: 0.1046\n",
      "Epoch 50/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - 1s 2us/step - loss: 0.1229 - val_loss: 0.1016\n",
      "Epoch 51/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - 1s 1us/step - loss: 0.1214 - val_loss: 0.1009\n",
      "Epoch 52/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1196 - val_loss: 0.0975\n",
      "Epoch 53/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1172 - val_loss: 0.0950\n",
      "Epoch 54/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1159 - val_loss: 0.0944\n",
      "Epoch 55/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 1us/step - loss: 0.1147 - val_loss: 0.0915\n",
      "Epoch 56/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1140 - val_loss: 0.0905\n",
      "Epoch 57/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1119 - val_loss: 0.0885\n",
      "Epoch 58/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1107 - val_loss: 0.0872\n",
      "Epoch 59/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1095 - val_loss: 0.0878\n",
      "Epoch 60/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1083 - val_loss: 0.0845\n",
      "Epoch 61/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1076 - val_loss: 0.0832\n",
      "Epoch 62/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1066 - val_loss: 0.0824\n",
      "Epoch 63/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1055 - val_loss: 0.0820\n",
      "Epoch 64/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1049 - val_loss: 0.0812\n",
      "Epoch 65/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1035 - val_loss: 0.0801\n",
      "Epoch 66/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1031 - val_loss: 0.0777\n",
      "Epoch 67/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1023 - val_loss: 0.0782\n",
      "Epoch 68/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1011 - val_loss: 0.0765\n",
      "Epoch 69/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1014 - val_loss: 0.0761\n",
      "Epoch 70/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1001 - val_loss: 0.0747\n",
      "Epoch 71/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0997 - val_loss: 0.0733\n",
      "Epoch 72/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0991 - val_loss: 0.0718\n",
      "Epoch 73/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0993 - val_loss: 0.0721\n",
      "Epoch 74/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0977 - val_loss: 0.0711\n",
      "Epoch 75/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0976 - val_loss: 0.0700\n",
      "Epoch 76/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0968 - val_loss: 0.0698\n",
      "Epoch 77/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0964 - val_loss: 0.0685\n",
      "Epoch 78/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0960 - val_loss: 0.0693\n",
      "Epoch 79/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0953 - val_loss: 0.0684\n",
      "Epoch 80/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0956 - val_loss: 0.0678\n",
      "Epoch 81/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0950 - val_loss: 0.0682\n",
      "Epoch 82/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0939 - val_loss: 0.0672\n",
      "Epoch 83/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0665\n",
      "Epoch 84/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0663\n",
      "Epoch 85/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0936 - val_loss: 0.0660\n",
      "Epoch 86/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0665\n",
      "Epoch 87/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0937 - val_loss: 0.0655\n",
      "Epoch 88/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0649\n",
      "Epoch 89/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0651\n",
      "Epoch 90/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0646\n",
      "Epoch 91/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0645\n",
      "Epoch 92/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0649\n",
      "Epoch 93/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0645\n",
      "Epoch 94/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0637\n",
      "Epoch 95/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0641\n",
      "Epoch 96/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0643\n",
      "Epoch 97/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0632\n",
      "Epoch 98/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0904 - val_loss: 0.0633\n",
      "Epoch 99/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0901 - val_loss: 0.0627\n",
      "Epoch 100/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0899 - val_loss: 0.0627\n",
      "Epoch 101/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0897 - val_loss: 0.0626\n",
      "Epoch 102/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0626\n",
      "Epoch 103/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0890 - val_loss: 0.0628\n",
      "Epoch 104/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0898 - val_loss: 0.0620\n",
      "Epoch 105/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0622\n",
      "Epoch 106/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0894 - val_loss: 0.0618\n",
      "Epoch 107/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0619\n",
      "Epoch 108/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0886 - val_loss: 0.0619\n",
      "Epoch 109/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0882 - val_loss: 0.0618\n",
      "Epoch 110/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0615\n",
      "Epoch 111/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0884 - val_loss: 0.0613\n",
      "Epoch 112/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0610\n",
      "Epoch 113/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0613\n",
      "Epoch 114/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0611\n",
      "Epoch 115/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0607\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0610\n",
      "Epoch 117/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0607\n",
      "Epoch 118/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0873 - val_loss: 0.0607\n",
      "Epoch 119/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0606\n",
      "Epoch 120/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0875 - val_loss: 0.0603\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 0. auc: 0.9338.\n",
      "Fold 2 started at Fri Sep  6 23:38:26 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/120\n",
      "472432/472432 [==============================] - ETA: 14s - loss: 0.72 - ETA: 3s - loss: 0.7340 - ETA: 1s - loss: 0.728 - ETA: 1s - loss: 0.726 - ETA: 0s - loss: 0.723 - ETA: 0s - loss: 0.720 - ETA: 0s - loss: 0.716 - ETA: 0s - loss: 0.713 - ETA: 0s - loss: 0.709 - ETA: 0s - loss: 0.706 - 1s 3us/step - loss: 0.7059 - val_loss: 0.6252\n",
      "Epoch 2/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.681 - ETA: 0s - loss: 0.675 - ETA: 0s - loss: 0.673 - ETA: 0s - loss: 0.670 - ETA: 0s - loss: 0.667 - ETA: 0s - loss: 0.665 - ETA: 0s - loss: 0.662 - ETA: 0s - loss: 0.660 - ETA: 0s - loss: 0.658 - ETA: 0s - loss: 0.656 - 1s 1us/step - loss: 0.6556 - val_loss: 0.6406\n",
      "Epoch 3/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.631 - ETA: 0s - loss: 0.634 - ETA: 0s - loss: 0.633 - ETA: 0s - loss: 0.631 - ETA: 0s - loss: 0.628 - ETA: 0s - loss: 0.627 - ETA: 0s - loss: 0.626 - ETA: 0s - loss: 0.624 - ETA: 0s - loss: 0.622 - ETA: 0s - loss: 0.621 - 1s 2us/step - loss: 0.6211 - val_loss: 0.6097\n",
      "Epoch 4/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.603 - ETA: 0s - loss: 0.604 - ETA: 0s - loss: 0.603 - ETA: 0s - loss: 0.602 - ETA: 0s - loss: 0.601 - ETA: 0s - loss: 0.600 - ETA: 0s - loss: 0.598 - ETA: 0s - loss: 0.597 - ETA: 0s - loss: 0.596 - ETA: 0s - loss: 0.595 - 1s 1us/step - loss: 0.5948 - val_loss: 0.5928\n",
      "Epoch 5/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.578 - ETA: 0s - loss: 0.580 - ETA: 0s - loss: 0.578 - ETA: 0s - loss: 0.576 - ETA: 0s - loss: 0.575 - ETA: 0s - loss: 0.574 - ETA: 0s - loss: 0.573 - ETA: 0s - loss: 0.572 - ETA: 0s - loss: 0.571 - 1s 2us/step - loss: 0.5705 - val_loss: 0.5739\n",
      "Epoch 6/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.557 - ETA: 0s - loss: 0.553 - ETA: 0s - loss: 0.554 - ETA: 0s - loss: 0.553 - ETA: 0s - loss: 0.551 - ETA: 0s - loss: 0.550 - ETA: 0s - loss: 0.549 - ETA: 0s - loss: 0.548 - ETA: 0s - loss: 0.548 - ETA: 0s - loss: 0.546 - 1s 2us/step - loss: 0.5462 - val_loss: 0.5569\n",
      "Epoch 7/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.524 - ETA: 0s - loss: 0.534 - ETA: 0s - loss: 0.534 - ETA: 0s - loss: 0.532 - ETA: 0s - loss: 0.531 - ETA: 0s - loss: 0.530 - ETA: 0s - loss: 0.530 - ETA: 0s - loss: 0.529 - ETA: 0s - loss: 0.528 - ETA: 0s - loss: 0.526 - 1s 1us/step - loss: 0.5262 - val_loss: 0.5386\n",
      "Epoch 8/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.520 - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.513 - ETA: 0s - loss: 0.510 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.510 - ETA: 0s - loss: 0.508 - ETA: 0s - loss: 0.508 - ETA: 0s - loss: 0.507 - ETA: 0s - loss: 0.506 - 1s 1us/step - loss: 0.5064 - val_loss: 0.5221\n",
      "Epoch 9/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.492 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.488 - ETA: 0s - loss: 0.488 - ETA: 0s - loss: 0.487 - ETA: 0s - loss: 0.487 - 1s 1us/step - loss: 0.4866 - val_loss: 0.5059\n",
      "Epoch 10/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.482 - ETA: 0s - loss: 0.476 - ETA: 0s - loss: 0.474 - ETA: 0s - loss: 0.474 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.471 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.469 - 1s 1us/step - loss: 0.4688 - val_loss: 0.4851\n",
      "Epoch 11/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.459 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.457 - ETA: 0s - loss: 0.456 - ETA: 0s - loss: 0.455 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.451 - 1s 2us/step - loss: 0.4509 - val_loss: 0.4666\n",
      "Epoch 12/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.440 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.442 - ETA: 0s - loss: 0.440 - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.433 - ETA: 0s - loss: 0.433 - 1s 1us/step - loss: 0.4331 - val_loss: 0.4451\n",
      "Epoch 13/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.426 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.420 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.417 - ETA: 0s - loss: 0.416 - 1s 2us/step - loss: 0.4159 - val_loss: 0.4212\n",
      "Epoch 14/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.407 - ETA: 0s - loss: 0.411 - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.407 - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.405 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.402 - ETA: 0s - loss: 0.400 - 1s 2us/step - loss: 0.3999 - val_loss: 0.3976\n",
      "Epoch 15/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.391 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.386 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.384 - ETA: 0s - loss: 0.384 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.383 - 1s 2us/step - loss: 0.3828 - val_loss: 0.3779\n",
      "Epoch 16/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.374 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.371 - ETA: 0s - loss: 0.370 - ETA: 0s - loss: 0.370 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.367 - 1s 2us/step - loss: 0.3668 - val_loss: 0.3562\n",
      "Epoch 17/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.353 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.351 - 1s 1us/step - loss: 0.3508 - val_loss: 0.3364\n",
      "Epoch 18/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.342 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.336 - 1s 1us/step - loss: 0.3361 - val_loss: 0.3193\n",
      "Epoch 19/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.322 - 1s 1us/step - loss: 0.3227 - val_loss: 0.3038\n",
      "Epoch 20/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.308 - 1s 1us/step - loss: 0.3082 - val_loss: 0.2875\n",
      "Epoch 21/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.303 - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.295 - 1s 1us/step - loss: 0.2954 - val_loss: 0.2761\n",
      "Epoch 22/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - 1s 1us/step - loss: 0.2825 - val_loss: 0.2622\n",
      "Epoch 23/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.271 - 1s 1us/step - loss: 0.2707 - val_loss: 0.2506\n",
      "Epoch 24/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.254 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.264 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.258 - 1s 1us/step - loss: 0.2587 - val_loss: 0.2415\n",
      "Epoch 25/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.253 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.253 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.249 - 1s 1us/step - loss: 0.2488 - val_loss: 0.2293\n",
      "Epoch 26/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.242 - ETA: 0s - loss: 0.242 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - 1s 1us/step - loss: 0.2385 - val_loss: 0.2202\n",
      "Epoch 27/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.233 - ETA: 0s - loss: 0.233 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.231 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.229 - 1s 1us/step - loss: 0.2293 - val_loss: 0.2103\n",
      "Epoch 28/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - 1s 1us/step - loss: 0.2204 - val_loss: 0.2019\n",
      "Epoch 29/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - 1s 1us/step - loss: 0.2118 - val_loss: 0.1960\n",
      "Epoch 30/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - 1s 1us/step - loss: 0.2044 - val_loss: 0.1903\n",
      "Epoch 31/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - 1s 1us/step - loss: 0.1963 - val_loss: 0.1828\n",
      "Epoch 32/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.189 - 1s 1us/step - loss: 0.1897 - val_loss: 0.1752\n",
      "Epoch 33/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.183 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.183 - 1s 1us/step - loss: 0.1833 - val_loss: 0.1687\n",
      "Epoch 34/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.178 - 1s 1us/step - loss: 0.1781 - val_loss: 0.1639\n",
      "Epoch 35/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.172 - 1s 2us/step - loss: 0.1718 - val_loss: 0.1607\n",
      "Epoch 36/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.176 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.171 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.166 - 1s 1us/step - loss: 0.1670 - val_loss: 0.1539\n",
      "Epoch 37/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - 1s 1us/step - loss: 0.1623 - val_loss: 0.1506\n",
      "Epoch 38/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.153 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.157 - 1s 1us/step - loss: 0.1574 - val_loss: 0.1466\n",
      "Epoch 39/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - 1s 1us/step - loss: 0.1541 - val_loss: 0.1417\n",
      "Epoch 40/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - 1s 1us/step - loss: 0.1487 - val_loss: 0.1404\n",
      "Epoch 41/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - 1s 1us/step - loss: 0.1457 - val_loss: 0.1352\n",
      "Epoch 42/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 1s - loss: 0.141 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - 1s 1us/step - loss: 0.1416 - val_loss: 0.1332\n",
      "Epoch 43/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1394 - val_loss: 0.1287\n",
      "Epoch 44/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - 1s 1us/step - loss: 0.1359 - val_loss: 0.1263\n",
      "Epoch 45/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.137 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - 1s 1us/step - loss: 0.1337 - val_loss: 0.1238\n",
      "Epoch 46/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.131 - 1s 1us/step - loss: 0.1309 - val_loss: 0.1211\n",
      "Epoch 47/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - 1s 1us/step - loss: 0.1286 - val_loss: 0.1190\n",
      "Epoch 48/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1252 - val_loss: 0.1171\n",
      "Epoch 49/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - 1s 1us/step - loss: 0.1238 - val_loss: 0.1152\n",
      "Epoch 50/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - 1s 1us/step - loss: 0.1216 - val_loss: 0.1142\n",
      "Epoch 51/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.116 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1194 - val_loss: 0.1124\n",
      "Epoch 52/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - 1s 1us/step - loss: 0.1184 - val_loss: 0.1092\n",
      "Epoch 53/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - 1s 1us/step - loss: 0.1169 - val_loss: 0.1086\n",
      "Epoch 54/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1150 - val_loss: 0.1073\n",
      "Epoch 55/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1132 - val_loss: 0.1041\n",
      "Epoch 56/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1118 - val_loss: 0.1041\n",
      "Epoch 57/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1108 - val_loss: 0.1036\n",
      "Epoch 58/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1098 - val_loss: 0.1016\n",
      "Epoch 59/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1084 - val_loss: 0.1006\n",
      "Epoch 60/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1067 - val_loss: 0.0992\n",
      "Epoch 61/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1061 - val_loss: 0.0972\n",
      "Epoch 62/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1051 - val_loss: 0.0971\n",
      "Epoch 63/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1042 - val_loss: 0.0969\n",
      "Epoch 64/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1029 - val_loss: 0.0958\n",
      "Epoch 65/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1027 - val_loss: 0.0953\n",
      "Epoch 66/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1011 - val_loss: 0.0937\n",
      "Epoch 67/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1005 - val_loss: 0.0928\n",
      "Epoch 68/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0996 - val_loss: 0.0924\n",
      "Epoch 69/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1000 - val_loss: 0.0908\n",
      "Epoch 70/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0900\n",
      "Epoch 71/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0976 - val_loss: 0.0894\n",
      "Epoch 72/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0897\n",
      "Epoch 73/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0964 - val_loss: 0.0887\n",
      "Epoch 74/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0960 - val_loss: 0.0885\n",
      "Epoch 75/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0957 - val_loss: 0.0883\n",
      "Epoch 76/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0949 - val_loss: 0.0876\n",
      "Epoch 77/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0951 - val_loss: 0.0864\n",
      "Epoch 78/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0869\n",
      "Epoch 79/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0863\n",
      "Epoch 80/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0939 - val_loss: 0.0858\n",
      "Epoch 81/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0931 - val_loss: 0.0853\n",
      "Epoch 82/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0921 - val_loss: 0.0858\n",
      "Epoch 83/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0847\n",
      "Epoch 84/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0842\n",
      "Epoch 85/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0837\n",
      "Epoch 86/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0911 - val_loss: 0.0837\n",
      "Epoch 87/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0835\n",
      "Epoch 88/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0898 - val_loss: 0.0832\n",
      "Epoch 89/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - 1s 2us/step - loss: 0.0901 - val_loss: 0.0830\n",
      "Epoch 90/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 2us/step - loss: 0.0897 - val_loss: 0.0829\n",
      "Epoch 91/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 2us/step - loss: 0.0894 - val_loss: 0.0826\n",
      "Epoch 92/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 2us/step - loss: 0.0893 - val_loss: 0.0822\n",
      "Epoch 93/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.086 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0886 - val_loss: 0.0822\n",
      "Epoch 94/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0883 - val_loss: 0.0823\n",
      "Epoch 95/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0883 - val_loss: 0.0820\n",
      "Epoch 96/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0882 - val_loss: 0.0818\n",
      "Epoch 97/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0883 - val_loss: 0.0818\n",
      "Epoch 98/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 2us/step - loss: 0.0877 - val_loss: 0.0820\n",
      "Epoch 99/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0878 - val_loss: 0.0817\n",
      "Epoch 100/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.084 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 101/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 102/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0870 - val_loss: 0.0817\n",
      "Epoch 103/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0874 - val_loss: 0.0816\n",
      "Epoch 104/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0866 - val_loss: 0.0817\n",
      "Epoch 105/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.080 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0863 - val_loss: 0.0813\n",
      "Epoch 106/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0865 - val_loss: 0.0810\n",
      "Epoch 107/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0866 - val_loss: 0.0811\n",
      "Epoch 108/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 2us/step - loss: 0.0862 - val_loss: 0.0811\n",
      "Epoch 109/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0812\n",
      "Epoch 110/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0809\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 1s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0811\n",
      "Epoch 112/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0812\n",
      "Epoch 113/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0814\n",
      "Epoch 114/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0857 - val_loss: 0.0814\n",
      "Epoch 115/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0813\n",
      "Epoch 116/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0852 - val_loss: 0.0813\n",
      "Epoch 117/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0814\n",
      "Epoch 118/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0850 - val_loss: 0.0816\n",
      "Epoch 119/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0849 - val_loss: 0.0816\n",
      "Epoch 120/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0850 - val_loss: 0.0814\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 1. auc: 0.9483.\n",
      "Fold 3 started at Fri Sep  6 23:40:05 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/120\n",
      "472432/472432 [==============================] - ETA: 13s - loss: 0.77 - ETA: 3s - loss: 0.7701 - ETA: 1s - loss: 0.768 - ETA: 1s - loss: 0.764 - ETA: 0s - loss: 0.761 - ETA: 0s - loss: 0.757 - ETA: 0s - loss: 0.754 - ETA: 0s - loss: 0.750 - ETA: 0s - loss: 0.747 - ETA: 0s - loss: 0.743 - 1s 2us/step - loss: 0.7425 - val_loss: 0.6563\n",
      "Epoch 2/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.702 - ETA: 0s - loss: 0.706 - ETA: 0s - loss: 0.703 - ETA: 0s - loss: 0.701 - ETA: 0s - loss: 0.698 - ETA: 0s - loss: 0.696 - ETA: 0s - loss: 0.693 - ETA: 0s - loss: 0.691 - ETA: 0s - loss: 0.688 - ETA: 0s - loss: 0.686 - 1s 1us/step - loss: 0.6853 - val_loss: 0.6258\n",
      "Epoch 3/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.667 - ETA: 0s - loss: 0.660 - ETA: 0s - loss: 0.657 - ETA: 0s - loss: 0.655 - ETA: 0s - loss: 0.653 - ETA: 0s - loss: 0.652 - ETA: 0s - loss: 0.650 - ETA: 0s - loss: 0.648 - ETA: 0s - loss: 0.646 - ETA: 0s - loss: 0.644 - 1s 1us/step - loss: 0.6434 - val_loss: 0.6201\n",
      "Epoch 4/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.623 - ETA: 0s - loss: 0.621 - ETA: 0s - loss: 0.619 - ETA: 0s - loss: 0.618 - ETA: 0s - loss: 0.617 - ETA: 0s - loss: 0.615 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.612 - ETA: 0s - loss: 0.610 - ETA: 0s - loss: 0.608 - 1s 1us/step - loss: 0.6084 - val_loss: 0.6232\n",
      "Epoch 5/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.593 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.587 - ETA: 0s - loss: 0.586 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.583 - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.580 - ETA: 0s - loss: 0.579 - 1s 1us/step - loss: 0.5791 - val_loss: 0.6038\n",
      "Epoch 6/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.564 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.560 - ETA: 0s - loss: 0.559 - ETA: 0s - loss: 0.558 - ETA: 0s - loss: 0.557 - ETA: 0s - loss: 0.555 - ETA: 0s - loss: 0.554 - 1s 1us/step - loss: 0.5544 - val_loss: 0.5936\n",
      "Epoch 7/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.538 - ETA: 0s - loss: 0.537 - ETA: 0s - loss: 0.536 - ETA: 0s - loss: 0.535 - ETA: 0s - loss: 0.533 - ETA: 0s - loss: 0.532 - ETA: 0s - loss: 0.530 - 1s 1us/step - loss: 0.5303 - val_loss: 0.5671\n",
      "Epoch 8/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.512 - ETA: 0s - loss: 0.515 - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.515 - ETA: 0s - loss: 0.514 - ETA: 0s - loss: 0.512 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.510 - ETA: 0s - loss: 0.508 - 1s 1us/step - loss: 0.5082 - val_loss: 0.5404\n",
      "Epoch 9/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.494 - ETA: 0s - loss: 0.494 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.492 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.488 - ETA: 0s - loss: 0.487 - 1s 1us/step - loss: 0.4873 - val_loss: 0.5106\n",
      "Epoch 10/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.477 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.473 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.469 - ETA: 0s - loss: 0.468 - ETA: 0s - loss: 0.467 - 1s 1us/step - loss: 0.4674 - val_loss: 0.4828\n",
      "Epoch 11/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.456 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.453 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.451 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.449 - 1s 1us/step - loss: 0.4498 - val_loss: 0.4595\n",
      "Epoch 12/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.434 - ETA: 0s - loss: 0.433 - ETA: 0s - loss: 0.432 - 1s 1us/step - loss: 0.4320 - val_loss: 0.4372\n",
      "Epoch 13/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.417 - ETA: 0s - loss: 0.416 - ETA: 0s - loss: 0.416 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.414 - 1s 1us/step - loss: 0.4140 - val_loss: 0.4193\n",
      "Epoch 14/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.402 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.399 - ETA: 0s - loss: 0.399 - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.397 - 1s 1us/step - loss: 0.3971 - val_loss: 0.3984\n",
      "Epoch 15/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.379 - 1s 1us/step - loss: 0.3798 - val_loss: 0.3783\n",
      "Epoch 16/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.371 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.363 - 1s 1us/step - loss: 0.3635 - val_loss: 0.3583\n",
      "Epoch 17/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.349 - 1s 1us/step - loss: 0.3490 - val_loss: 0.3401\n",
      "Epoch 18/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.335 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.333 - 1s 1us/step - loss: 0.3334 - val_loss: 0.3240\n",
      "Epoch 19/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.335 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.321 - ETA: 0s - loss: 0.320 - ETA: 0s - loss: 0.320 - 1s 1us/step - loss: 0.3199 - val_loss: 0.3076\n",
      "Epoch 20/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.306 - 1s 1us/step - loss: 0.3060 - val_loss: 0.2919\n",
      "Epoch 21/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.292 - 1s 1us/step - loss: 0.2922 - val_loss: 0.2784\n",
      "Epoch 22/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.279 - 1s 1us/step - loss: 0.2799 - val_loss: 0.2654\n",
      "Epoch 23/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.278 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.268 - 1s 1us/step - loss: 0.2690 - val_loss: 0.2506\n",
      "Epoch 24/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.256 - 1s 1us/step - loss: 0.2559 - val_loss: 0.2356\n",
      "Epoch 25/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.246 - 1s 1us/step - loss: 0.2455 - val_loss: 0.2263\n",
      "Epoch 26/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - 1s 1us/step - loss: 0.2360 - val_loss: 0.2171\n",
      "Epoch 27/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.224 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.226 - 1s 1us/step - loss: 0.2260 - val_loss: 0.2070\n",
      "Epoch 28/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.225 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.217 - 1s 1us/step - loss: 0.2170 - val_loss: 0.1980\n",
      "Epoch 29/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.209 - 1s 1us/step - loss: 0.2089 - val_loss: 0.1874\n",
      "Epoch 30/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.206 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.200 - 1s 1us/step - loss: 0.2005 - val_loss: 0.1822\n",
      "Epoch 31/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.193 - 1s 1us/step - loss: 0.1936 - val_loss: 0.1729\n",
      "Epoch 32/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - 1s 1us/step - loss: 0.1867 - val_loss: 0.1691\n",
      "Epoch 33/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - 1s 1us/step - loss: 0.1800 - val_loss: 0.1645\n",
      "Epoch 34/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - 1s 1us/step - loss: 0.1743 - val_loss: 0.1585\n",
      "Epoch 35/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.171 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.167 - 1s 1us/step - loss: 0.1678 - val_loss: 0.1538\n",
      "Epoch 36/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - 1s 1us/step - loss: 0.1639 - val_loss: 0.1514\n",
      "Epoch 37/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.158 - 1s 1us/step - loss: 0.1587 - val_loss: 0.1456\n",
      "Epoch 38/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - 1s 2us/step - loss: 0.1544 - val_loss: 0.1414\n",
      "Epoch 39/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.148 - ETA: 1s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.150 - 1s 2us/step - loss: 0.1507 - val_loss: 0.1385\n",
      "Epoch 40/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - 1s 1us/step - loss: 0.1465 - val_loss: 0.1337\n",
      "Epoch 41/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - 1s 1us/step - loss: 0.1425 - val_loss: 0.1298\n",
      "Epoch 42/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1395 - val_loss: 0.1275\n",
      "Epoch 43/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - 1s 1us/step - loss: 0.1362 - val_loss: 0.1258\n",
      "Epoch 44/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - 1s 1us/step - loss: 0.1333 - val_loss: 0.1236\n",
      "Epoch 45/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1300 - val_loss: 0.1170\n",
      "Epoch 46/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - 1s 1us/step - loss: 0.1280 - val_loss: 0.1165\n",
      "Epoch 47/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1251 - val_loss: 0.1160\n",
      "Epoch 48/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - 1s 1us/step - loss: 0.1228 - val_loss: 0.1131\n",
      "Epoch 49/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - 1s 1us/step - loss: 0.1208 - val_loss: 0.1102\n",
      "Epoch 50/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1195 - val_loss: 0.1095\n",
      "Epoch 51/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1177 - val_loss: 0.1067\n",
      "Epoch 52/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1157 - val_loss: 0.1039\n",
      "Epoch 53/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 1us/step - loss: 0.1140 - val_loss: 0.1023\n",
      "Epoch 54/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.110 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1120 - val_loss: 0.1014\n",
      "Epoch 55/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1108 - val_loss: 0.0999\n",
      "Epoch 56/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1103 - val_loss: 0.0988\n",
      "Epoch 57/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1091 - val_loss: 0.0988\n",
      "Epoch 58/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1074 - val_loss: 0.0953\n",
      "Epoch 59/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1061 - val_loss: 0.0956\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1050 - val_loss: 0.0942\n",
      "Epoch 61/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1039 - val_loss: 0.0933\n",
      "Epoch 62/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1028 - val_loss: 0.0924\n",
      "Epoch 63/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1023 - val_loss: 0.0912\n",
      "Epoch 64/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1016 - val_loss: 0.0912\n",
      "Epoch 65/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1008 - val_loss: 0.0899\n",
      "Epoch 66/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1001 - val_loss: 0.0886\n",
      "Epoch 67/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0996 - val_loss: 0.0887\n",
      "Epoch 68/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 2us/step - loss: 0.0983 - val_loss: 0.0875\n",
      "Epoch 69/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 2us/step - loss: 0.0978 - val_loss: 0.0877\n",
      "Epoch 70/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0976 - val_loss: 0.0882\n",
      "Epoch 71/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0861\n",
      "Epoch 72/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0964 - val_loss: 0.0850\n",
      "Epoch 73/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0958 - val_loss: 0.0831\n",
      "Epoch 74/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0954 - val_loss: 0.0826\n",
      "Epoch 75/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0825\n",
      "Epoch 76/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0810\n",
      "Epoch 77/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0816\n",
      "Epoch 78/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0934 - val_loss: 0.0814\n",
      "Epoch 79/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0804\n",
      "Epoch 80/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0922 - val_loss: 0.0804\n",
      "Epoch 81/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0799\n",
      "Epoch 82/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0793\n",
      "Epoch 83/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0792\n",
      "Epoch 84/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0908 - val_loss: 0.0788\n",
      "Epoch 85/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0900 - val_loss: 0.0789\n",
      "Epoch 86/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0786\n",
      "Epoch 87/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0899 - val_loss: 0.0787\n",
      "Epoch 88/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0782\n",
      "Epoch 89/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0780\n",
      "Epoch 90/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0778\n",
      "Epoch 91/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0777\n",
      "Epoch 92/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0883 - val_loss: 0.0775\n",
      "Epoch 93/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0773\n",
      "Epoch 94/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0770\n",
      "Epoch 95/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0877 - val_loss: 0.0767\n",
      "Epoch 96/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0869 - val_loss: 0.0766\n",
      "Epoch 97/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0871 - val_loss: 0.0765\n",
      "Epoch 98/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0870 - val_loss: 0.0762\n",
      "Epoch 99/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0864 - val_loss: 0.0761\n",
      "Epoch 100/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0759\n",
      "Epoch 101/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0761\n",
      "Epoch 102/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0761\n",
      "Epoch 103/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0865 - val_loss: 0.0760\n",
      "Epoch 104/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0861 - val_loss: 0.0758\n",
      "Epoch 105/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0757\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0852 - val_loss: 0.0756\n",
      "Epoch 107/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0853 - val_loss: 0.0755\n",
      "Epoch 108/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0755\n",
      "Epoch 109/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0755\n",
      "Epoch 110/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0753\n",
      "Epoch 111/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0851 - val_loss: 0.0754\n",
      "Epoch 112/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0752\n",
      "Epoch 113/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0753\n",
      "Epoch 114/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0753\n",
      "Epoch 115/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0752\n",
      "Epoch 116/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0752\n",
      "Epoch 117/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0752\n",
      "Epoch 118/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0749\n",
      "Epoch 119/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0749\n",
      "Epoch 120/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0750\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 2. auc: 0.9429.\n",
      "Fold 4 started at Fri Sep  6 23:41:42 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/120\n",
      "472432/472432 [==============================] - ETA: 13s - loss: 0.73 - ETA: 3s - loss: 0.7250 - ETA: 1s - loss: 0.720 - ETA: 1s - loss: 0.716 - ETA: 0s - loss: 0.711 - ETA: 0s - loss: 0.708 - ETA: 0s - loss: 0.704 - ETA: 0s - loss: 0.701 - ETA: 0s - loss: 0.697 - ETA: 0s - loss: 0.694 - 1s 3us/step - loss: 0.6930 - val_loss: 0.6115\n",
      "Epoch 2/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.661 - ETA: 0s - loss: 0.662 - ETA: 0s - loss: 0.658 - ETA: 0s - loss: 0.655 - ETA: 0s - loss: 0.652 - ETA: 0s - loss: 0.650 - ETA: 0s - loss: 0.647 - ETA: 0s - loss: 0.645 - ETA: 0s - loss: 0.643 - ETA: 0s - loss: 0.641 - 1s 1us/step - loss: 0.6404 - val_loss: 0.6514\n",
      "Epoch 3/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.621 - ETA: 0s - loss: 0.619 - ETA: 0s - loss: 0.617 - ETA: 0s - loss: 0.615 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.612 - ETA: 0s - loss: 0.611 - ETA: 0s - loss: 0.609 - ETA: 0s - loss: 0.608 - ETA: 0s - loss: 0.606 - 1s 1us/step - loss: 0.6060 - val_loss: 0.6487\n",
      "Epoch 4/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.586 - ETA: 0s - loss: 0.586 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.583 - ETA: 0s - loss: 0.582 - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.580 - ETA: 0s - loss: 0.578 - ETA: 0s - loss: 0.578 - 1s 1us/step - loss: 0.5777 - val_loss: 0.6181\n",
      "Epoch 5/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.563 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.560 - ETA: 0s - loss: 0.559 - ETA: 0s - loss: 0.558 - ETA: 0s - loss: 0.556 - ETA: 0s - loss: 0.555 - ETA: 0s - loss: 0.554 - ETA: 0s - loss: 0.553 - 1s 1us/step - loss: 0.5529 - val_loss: 0.5868\n",
      "Epoch 6/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.541 - ETA: 0s - loss: 0.538 - ETA: 0s - loss: 0.537 - ETA: 0s - loss: 0.536 - ETA: 0s - loss: 0.535 - ETA: 0s - loss: 0.534 - ETA: 0s - loss: 0.533 - ETA: 0s - loss: 0.532 - 1s 1us/step - loss: 0.5317 - val_loss: 0.5559\n",
      "Epoch 7/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.522 - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.517 - ETA: 0s - loss: 0.517 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.515 - ETA: 0s - loss: 0.514 - ETA: 0s - loss: 0.513 - ETA: 0s - loss: 0.513 - 1s 1us/step - loss: 0.5126 - val_loss: 0.5294\n",
      "Epoch 8/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.500 - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.500 - ETA: 0s - loss: 0.499 - ETA: 0s - loss: 0.498 - ETA: 0s - loss: 0.496 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.494 - ETA: 0s - loss: 0.493 - 1s 1us/step - loss: 0.4932 - val_loss: 0.5049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.480 - ETA: 0s - loss: 0.483 - ETA: 0s - loss: 0.480 - ETA: 0s - loss: 0.479 - ETA: 0s - loss: 0.479 - ETA: 0s - loss: 0.478 - ETA: 0s - loss: 0.477 - ETA: 0s - loss: 0.476 - ETA: 0s - loss: 0.475 - ETA: 0s - loss: 0.474 - 1s 1us/step - loss: 0.4746 - val_loss: 0.4816\n",
      "Epoch 10/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.463 - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.461 - ETA: 0s - loss: 0.461 - ETA: 0s - loss: 0.461 - ETA: 0s - loss: 0.459 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.457 - 1s 1us/step - loss: 0.4568 - val_loss: 0.4597\n",
      "Epoch 11/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.442 - ETA: 0s - loss: 0.442 - ETA: 0s - loss: 0.441 - ETA: 0s - loss: 0.441 - ETA: 0s - loss: 0.440 - ETA: 0s - loss: 0.439 - 1s 1us/step - loss: 0.4387 - val_loss: 0.4391\n",
      "Epoch 12/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.432 - ETA: 0s - loss: 0.429 - ETA: 0s - loss: 0.428 - ETA: 0s - loss: 0.426 - ETA: 0s - loss: 0.425 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.420 - 1s 1us/step - loss: 0.4204 - val_loss: 0.4189\n",
      "Epoch 13/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.407 - ETA: 0s - loss: 0.407 - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.405 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.403 - 1s 1us/step - loss: 0.4038 - val_loss: 0.4000\n",
      "Epoch 14/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.393 - ETA: 0s - loss: 0.392 - ETA: 0s - loss: 0.392 - ETA: 0s - loss: 0.390 - ETA: 0s - loss: 0.389 - ETA: 0s - loss: 0.388 - ETA: 0s - loss: 0.388 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.387 - 1s 1us/step - loss: 0.3869 - val_loss: 0.3819\n",
      "Epoch 15/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.376 - ETA: 0s - loss: 0.376 - ETA: 0s - loss: 0.374 - ETA: 0s - loss: 0.373 - ETA: 0s - loss: 0.373 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.371 - ETA: 0s - loss: 0.370 - 1s 1us/step - loss: 0.3702 - val_loss: 0.3644\n",
      "Epoch 16/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.361 - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.358 - ETA: 0s - loss: 0.358 - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.354 - 1s 1us/step - loss: 0.3548 - val_loss: 0.3479\n",
      "Epoch 17/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.341 - ETA: 0s - loss: 0.344 - ETA: 0s - loss: 0.344 - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.341 - ETA: 0s - loss: 0.341 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.339 - 1s 1us/step - loss: 0.3397 - val_loss: 0.3320\n",
      "Epoch 18/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.325 - 1s 1us/step - loss: 0.3250 - val_loss: 0.3171\n",
      "Epoch 19/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.310 - 1s 1us/step - loss: 0.3102 - val_loss: 0.3028\n",
      "Epoch 20/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.303 - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.296 - 1s 1us/step - loss: 0.2965 - val_loss: 0.2893\n",
      "Epoch 21/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.286 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.284 - 1s 1us/step - loss: 0.2839 - val_loss: 0.2770\n",
      "Epoch 22/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.278 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.271 - 1s 1us/step - loss: 0.2717 - val_loss: 0.2658\n",
      "Epoch 23/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.266 - ETA: 0s - loss: 0.265 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.260 - 1s 2us/step - loss: 0.2602 - val_loss: 0.2552\n",
      "Epoch 24/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.254 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.250 - 1s 1us/step - loss: 0.2501 - val_loss: 0.2455\n",
      "Epoch 25/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.244 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - 1s 1us/step - loss: 0.2389 - val_loss: 0.2362\n",
      "Epoch 26/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.233 - ETA: 0s - loss: 0.234 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.229 - 1s 1us/step - loss: 0.2295 - val_loss: 0.2274\n",
      "Epoch 27/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.221 - 1s 1us/step - loss: 0.2208 - val_loss: 0.2192\n",
      "Epoch 28/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.213 - ETA: 0s - loss: 0.212 - 1s 1us/step - loss: 0.2125 - val_loss: 0.2115\n",
      "Epoch 29/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.208 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.208 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.206 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.204 - 1s 1us/step - loss: 0.2047 - val_loss: 0.2044\n",
      "Epoch 30/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.199 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - 1s 1us/step - loss: 0.1976 - val_loss: 0.1978\n",
      "Epoch 31/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.190 - 1s 1us/step - loss: 0.1901 - val_loss: 0.1922\n",
      "Epoch 32/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - 1s 1us/step - loss: 0.1845 - val_loss: 0.1862\n",
      "Epoch 33/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - 1s 1us/step - loss: 0.1787 - val_loss: 0.1809\n",
      "Epoch 34/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.172 - 1s 1us/step - loss: 0.1726 - val_loss: 0.1760\n",
      "Epoch 35/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.167 - 1s 1us/step - loss: 0.1676 - val_loss: 0.1712\n",
      "Epoch 36/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - 1s 1us/step - loss: 0.1630 - val_loss: 0.1672\n",
      "Epoch 37/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - 1s 1us/step - loss: 0.1592 - val_loss: 0.1630\n",
      "Epoch 38/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - 1s 1us/step - loss: 0.1537 - val_loss: 0.1594\n",
      "Epoch 39/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - 1s 1us/step - loss: 0.1505 - val_loss: 0.1560\n",
      "Epoch 40/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - 1s 1us/step - loss: 0.1480 - val_loss: 0.1529\n",
      "Epoch 41/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - 1s 1us/step - loss: 0.1441 - val_loss: 0.1501\n",
      "Epoch 42/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - 1s 1us/step - loss: 0.1410 - val_loss: 0.1474\n",
      "Epoch 43/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - 1s 1us/step - loss: 0.1382 - val_loss: 0.1452\n",
      "Epoch 44/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.135 - 1s 2us/step - loss: 0.1350 - val_loss: 0.1431\n",
      "Epoch 45/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.135 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - 1s 2us/step - loss: 0.1323 - val_loss: 0.1408\n",
      "Epoch 46/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - 1s 1us/step - loss: 0.1304 - val_loss: 0.1386\n",
      "Epoch 47/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - 1s 2us/step - loss: 0.1280 - val_loss: 0.1370\n",
      "Epoch 48/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - 1s 2us/step - loss: 0.1262 - val_loss: 0.1349\n",
      "Epoch 49/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.123 - 1s 2us/step - loss: 0.1236 - val_loss: 0.1337\n",
      "Epoch 50/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.124 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.122 - 1s 2us/step - loss: 0.1223 - val_loss: 0.1317\n",
      "Epoch 51/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1202 - val_loss: 0.1301\n",
      "Epoch 52/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 2us/step - loss: 0.1196 - val_loss: 0.1277\n",
      "Epoch 53/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1178 - val_loss: 0.1265\n",
      "Epoch 54/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - 1s 2us/step - loss: 0.1165 - val_loss: 0.1257\n",
      "Epoch 55/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 2us/step - loss: 0.1144 - val_loss: 0.1240\n",
      "Epoch 56/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 1us/step - loss: 0.1144 - val_loss: 0.1236\n",
      "Epoch 57/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1126 - val_loss: 0.1217\n",
      "Epoch 58/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 2us/step - loss: 0.1119 - val_loss: 0.1194\n",
      "Epoch 59/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1101 - val_loss: 0.1183\n",
      "Epoch 60/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 2us/step - loss: 0.1106 - val_loss: 0.1167\n",
      "Epoch 61/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1085 - val_loss: 0.1073\n",
      "Epoch 62/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1071 - val_loss: 0.1085\n",
      "Epoch 63/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1069 - val_loss: 0.1088\n",
      "Epoch 64/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1053 - val_loss: 0.1081\n",
      "Epoch 65/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1045 - val_loss: 0.1067\n",
      "Epoch 66/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1038 - val_loss: 0.1073\n",
      "Epoch 67/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1040 - val_loss: 0.1066\n",
      "Epoch 68/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 2us/step - loss: 0.1027 - val_loss: 0.1049\n",
      "Epoch 69/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1025 - val_loss: 0.1043\n",
      "Epoch 70/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1019 - val_loss: 0.1041\n",
      "Epoch 71/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1002 - val_loss: 0.1030\n",
      "Epoch 72/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1005 - val_loss: 0.1012\n",
      "Epoch 73/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1004 - val_loss: 0.1001\n",
      "Epoch 74/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0997 - val_loss: 0.1000\n",
      "Epoch 75/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0988 - val_loss: 0.0999\n",
      "Epoch 76/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0980 - val_loss: 0.1002\n",
      "Epoch 77/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - 1s 2us/step - loss: 0.0984 - val_loss: 0.0989\n",
      "Epoch 78/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0980\n",
      "Epoch 79/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0973 - val_loss: 0.0979\n",
      "Epoch 80/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0972 - val_loss: 0.0980\n",
      "Epoch 81/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0963 - val_loss: 0.0970\n",
      "Epoch 82/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0966 - val_loss: 0.0956\n",
      "Epoch 83/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 84/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0951 - val_loss: 0.0955\n",
      "Epoch 85/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0954 - val_loss: 0.0949\n",
      "Epoch 86/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0939\n",
      "Epoch 87/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0950 - val_loss: 0.0921\n",
      "Epoch 88/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0918\n",
      "Epoch 89/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0949 - val_loss: 0.0924\n",
      "Epoch 90/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0919\n",
      "Epoch 91/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0897\n",
      "Epoch 92/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0936 - val_loss: 0.0904\n",
      "Epoch 93/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0909\n",
      "Epoch 94/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0895\n",
      "Epoch 95/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0859\n",
      "Epoch 96/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 2us/step - loss: 0.0917 - val_loss: 0.0852\n",
      "Epoch 97/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0922 - val_loss: 0.0865\n",
      "Epoch 98/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0921 - val_loss: 0.0862\n",
      "Epoch 99/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0913 - val_loss: 0.0864\n",
      "Epoch 100/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0854\n",
      "Epoch 101/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0904 - val_loss: 0.0847\n",
      "Epoch 102/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0841\n",
      "Epoch 103/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0832\n",
      "Epoch 104/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 2us/step - loss: 0.0904 - val_loss: 0.0810\n",
      "Epoch 105/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0900 - val_loss: 0.0809\n",
      "Epoch 106/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0808\n",
      "Epoch 107/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0900 - val_loss: 0.0804\n",
      "Epoch 108/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0891 - val_loss: 0.0805\n",
      "Epoch 109/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0893 - val_loss: 0.0800\n",
      "Epoch 110/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0798\n",
      "Epoch 111/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0798\n",
      "Epoch 112/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0891 - val_loss: 0.0794\n",
      "Epoch 113/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0890 - val_loss: 0.0795\n",
      "Epoch 114/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0880 - val_loss: 0.0789\n",
      "Epoch 115/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0884 - val_loss: 0.0787\n",
      "Epoch 116/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 2us/step - loss: 0.0887 - val_loss: 0.0791\n",
      "Epoch 117/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0885 - val_loss: 0.0786\n",
      "Epoch 118/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0882 - val_loss: 0.0788\n",
      "Epoch 119/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0785\n",
      "Epoch 120/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0779\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 3. auc: 0.9551.\n",
      "Fold 5 started at Fri Sep  6 23:43:21 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/120\n",
      "472432/472432 [==============================] - ETA: 13s - loss: 0.80 - ETA: 4s - loss: 0.8078 - ETA: 2s - loss: 0.804 - ETA: 1s - loss: 0.798 - ETA: 1s - loss: 0.791 - ETA: 0s - loss: 0.783 - ETA: 0s - loss: 0.777 - ETA: 0s - loss: 0.771 - ETA: 0s - loss: 0.766 - ETA: 0s - loss: 0.760 - 1s 2us/step - loss: 0.7572 - val_loss: 0.6729\n",
      "Epoch 2/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.701 - ETA: 0s - loss: 0.696 - ETA: 0s - loss: 0.691 - ETA: 0s - loss: 0.686 - ETA: 0s - loss: 0.682 - ETA: 0s - loss: 0.678 - ETA: 0s - loss: 0.674 - ETA: 0s - loss: 0.670 - ETA: 0s - loss: 0.667 - ETA: 0s - loss: 0.664 - 1s 1us/step - loss: 0.6636 - val_loss: 0.6179\n",
      "Epoch 3/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.630 - ETA: 0s - loss: 0.632 - ETA: 0s - loss: 0.629 - ETA: 0s - loss: 0.627 - ETA: 0s - loss: 0.625 - ETA: 0s - loss: 0.623 - ETA: 0s - loss: 0.620 - ETA: 0s - loss: 0.618 - ETA: 0s - loss: 0.616 - ETA: 0s - loss: 0.614 - 1s 1us/step - loss: 0.6139 - val_loss: 0.6254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.587 - ETA: 0s - loss: 0.585 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.582 - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.579 - 1s 1us/step - loss: 0.5795 - val_loss: 0.6150\n",
      "Epoch 5/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.558 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.559 - ETA: 0s - loss: 0.558 - ETA: 0s - loss: 0.557 - ETA: 0s - loss: 0.556 - ETA: 0s - loss: 0.554 - ETA: 0s - loss: 0.552 - 1s 1us/step - loss: 0.5524 - val_loss: 0.5855\n",
      "Epoch 6/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.538 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.537 - ETA: 0s - loss: 0.535 - ETA: 0s - loss: 0.534 - ETA: 0s - loss: 0.532 - ETA: 0s - loss: 0.531 - ETA: 0s - loss: 0.530 - 1s 1us/step - loss: 0.5297 - val_loss: 0.5606\n",
      "Epoch 7/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.526 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.513 - ETA: 0s - loss: 0.512 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.510 - ETA: 0s - loss: 0.509 - ETA: 0s - loss: 0.507 - ETA: 0s - loss: 0.506 - 1s 1us/step - loss: 0.5064 - val_loss: 0.5377\n",
      "Epoch 8/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.487 - ETA: 0s - loss: 0.486 - ETA: 0s - loss: 0.485 - 1s 1us/step - loss: 0.4854 - val_loss: 0.5172\n",
      "Epoch 9/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.474 - ETA: 0s - loss: 0.473 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.471 - ETA: 0s - loss: 0.469 - ETA: 0s - loss: 0.468 - ETA: 0s - loss: 0.467 - ETA: 0s - loss: 0.466 - ETA: 0s - loss: 0.465 - 1s 1us/step - loss: 0.4651 - val_loss: 0.4974\n",
      "Epoch 10/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.454 - ETA: 0s - loss: 0.453 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.451 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.448 - ETA: 0s - loss: 0.448 - ETA: 0s - loss: 0.447 - ETA: 0s - loss: 0.447 - ETA: 0s - loss: 0.446 - 1s 2us/step - loss: 0.4454 - val_loss: 0.4777\n",
      "Epoch 11/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.434 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.429 - ETA: 0s - loss: 0.428 - ETA: 0s - loss: 0.428 - ETA: 0s - loss: 0.427 - ETA: 0s - loss: 0.426 - ETA: 0s - loss: 0.425 - 1s 1us/step - loss: 0.4255 - val_loss: 0.4599\n",
      "Epoch 12/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.420 - ETA: 0s - loss: 0.415 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.413 - ETA: 0s - loss: 0.413 - ETA: 0s - loss: 0.412 - ETA: 0s - loss: 0.411 - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.409 - ETA: 0s - loss: 0.408 - 1s 1us/step - loss: 0.4079 - val_loss: 0.4448\n",
      "Epoch 13/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.393 - ETA: 0s - loss: 0.393 - ETA: 0s - loss: 0.392 - ETA: 0s - loss: 0.391 - ETA: 0s - loss: 0.390 - ETA: 0s - loss: 0.390 - ETA: 0s - loss: 0.388 - 1s 1us/step - loss: 0.3886 - val_loss: 0.4272\n",
      "Epoch 14/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.379 - ETA: 0s - loss: 0.377 - ETA: 0s - loss: 0.376 - ETA: 0s - loss: 0.375 - ETA: 0s - loss: 0.374 - ETA: 0s - loss: 0.373 - ETA: 0s - loss: 0.372 - 1s 1us/step - loss: 0.3717 - val_loss: 0.4051\n",
      "Epoch 15/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.361 - ETA: 0s - loss: 0.360 - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.358 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.356 - 1s 1us/step - loss: 0.3552 - val_loss: 0.3843\n",
      "Epoch 16/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.348 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.343 - ETA: 0s - loss: 0.342 - ETA: 0s - loss: 0.342 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.339 - 1s 1us/step - loss: 0.3391 - val_loss: 0.3645\n",
      "Epoch 17/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.323 - 1s 1us/step - loss: 0.3234 - val_loss: 0.3462\n",
      "Epoch 18/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.309 - 1s 1us/step - loss: 0.3089 - val_loss: 0.3286\n",
      "Epoch 19/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.295 - 1s 1us/step - loss: 0.2950 - val_loss: 0.3125\n",
      "Epoch 20/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.286 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.282 - 1s 1us/step - loss: 0.2822 - val_loss: 0.2976\n",
      "Epoch 21/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.274 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.269 - 1s 2us/step - loss: 0.2693 - val_loss: 0.2833\n",
      "Epoch 22/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.254 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.257 - 1s 1us/step - loss: 0.2577 - val_loss: 0.2697\n",
      "Epoch 23/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.252 - ETA: 0s - loss: 0.253 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.247 - 1s 2us/step - loss: 0.2476 - val_loss: 0.2577\n",
      "Epoch 24/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.243 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.236 - 1s 1us/step - loss: 0.2364 - val_loss: 0.2461\n",
      "Epoch 25/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.232 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.226 - 1s 1us/step - loss: 0.2266 - val_loss: 0.2356\n",
      "Epoch 26/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.217 - 1s 1us/step - loss: 0.2176 - val_loss: 0.2256\n",
      "Epoch 27/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 1s - loss: 0.221 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - 1s 1us/step - loss: 0.2093 - val_loss: 0.2174\n",
      "Epoch 28/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.201 - 1s 1us/step - loss: 0.2011 - val_loss: 0.2086\n",
      "Epoch 29/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.198 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.194 - 1s 1us/step - loss: 0.1939 - val_loss: 0.2011\n",
      "Epoch 30/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - 1s 2us/step - loss: 0.1868 - val_loss: 0.1944\n",
      "Epoch 31/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.181 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - 1s 1us/step - loss: 0.1808 - val_loss: 0.1885\n",
      "Epoch 32/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - 1s 1us/step - loss: 0.1743 - val_loss: 0.1826\n",
      "Epoch 33/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.173 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.171 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - 1s 1us/step - loss: 0.1695 - val_loss: 0.1769\n",
      "Epoch 34/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.168 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.164 - 1s 1us/step - loss: 0.1646 - val_loss: 0.1727\n",
      "Epoch 35/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.160 - 1s 1us/step - loss: 0.1604 - val_loss: 0.1678\n",
      "Epoch 36/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.153 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - 1s 1us/step - loss: 0.1549 - val_loss: 0.1639\n",
      "Epoch 37/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - 1s 1us/step - loss: 0.1510 - val_loss: 0.1591\n",
      "Epoch 38/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - 1s 1us/step - loss: 0.1475 - val_loss: 0.1540\n",
      "Epoch 39/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.144 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - 1s 2us/step - loss: 0.1434 - val_loss: 0.1508\n",
      "Epoch 40/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1401 - val_loss: 0.1480\n",
      "Epoch 41/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - 1s 1us/step - loss: 0.1369 - val_loss: 0.1451\n",
      "Epoch 42/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.141 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - 1s 1us/step - loss: 0.1350 - val_loss: 0.1419\n",
      "Epoch 43/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.135 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - 1s 1us/step - loss: 0.1317 - val_loss: 0.1388\n",
      "Epoch 44/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - 1s 2us/step - loss: 0.1293 - val_loss: 0.1361\n",
      "Epoch 45/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.123 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - 1s 1us/step - loss: 0.1270 - val_loss: 0.1332\n",
      "Epoch 46/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1253 - val_loss: 0.1301\n",
      "Epoch 47/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.129 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - 1s 2us/step - loss: 0.1220 - val_loss: 0.1288\n",
      "Epoch 48/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - 1s 1us/step - loss: 0.1213 - val_loss: 0.1278\n",
      "Epoch 49/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1188 - val_loss: 0.1251\n",
      "Epoch 50/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1169 - val_loss: 0.1228\n",
      "Epoch 51/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - 1s 1us/step - loss: 0.1160 - val_loss: 0.1201\n",
      "Epoch 52/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 1us/step - loss: 0.1145 - val_loss: 0.1175\n",
      "Epoch 53/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1127 - val_loss: 0.1163\n",
      "Epoch 54/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1118 - val_loss: 0.1148\n",
      "Epoch 55/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1100 - val_loss: 0.1125\n",
      "Epoch 56/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 2us/step - loss: 0.1097 - val_loss: 0.1122\n",
      "Epoch 57/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1093 - val_loss: 0.1102\n",
      "Epoch 58/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1076 - val_loss: 0.1093\n",
      "Epoch 59/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1058 - val_loss: 0.1075\n",
      "Epoch 60/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1058 - val_loss: 0.1069\n",
      "Epoch 61/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1046 - val_loss: 0.1062\n",
      "Epoch 62/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1038 - val_loss: 0.1055\n",
      "Epoch 63/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1037 - val_loss: 0.1043\n",
      "Epoch 64/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1030 - val_loss: 0.1035\n",
      "Epoch 65/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1017 - val_loss: 0.1021\n",
      "Epoch 66/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1015 - val_loss: 0.1009\n",
      "Epoch 67/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1006 - val_loss: 0.0999\n",
      "Epoch 68/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.104 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1010 - val_loss: 0.1006\n",
      "Epoch 69/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0994 - val_loss: 0.0994\n",
      "Epoch 70/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0994 - val_loss: 0.0972\n",
      "Epoch 71/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0989 - val_loss: 0.0957\n",
      "Epoch 72/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0988 - val_loss: 0.0943\n",
      "Epoch 73/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0974 - val_loss: 0.0928\n",
      "Epoch 74/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0978 - val_loss: 0.0902\n",
      "Epoch 75/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0972 - val_loss: 0.0884\n",
      "Epoch 76/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0882\n",
      "Epoch 77/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0965 - val_loss: 0.0888\n",
      "Epoch 78/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.092 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0968 - val_loss: 0.0885\n",
      "Epoch 79/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0958 - val_loss: 0.0875\n",
      "Epoch 80/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0960 - val_loss: 0.0869\n",
      "Epoch 81/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0866\n",
      "Epoch 82/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0955 - val_loss: 0.0860\n",
      "Epoch 83/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0858\n",
      "Epoch 84/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0950 - val_loss: 0.0856\n",
      "Epoch 85/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0855\n",
      "Epoch 86/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0939 - val_loss: 0.0854\n",
      "Epoch 87/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0941 - val_loss: 0.0851\n",
      "Epoch 88/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0938 - val_loss: 0.0849\n",
      "Epoch 89/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.098 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0938 - val_loss: 0.0848\n",
      "Epoch 90/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0937 - val_loss: 0.0846\n",
      "Epoch 91/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0931 - val_loss: 0.0846\n",
      "Epoch 92/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0930 - val_loss: 0.0844\n",
      "Epoch 93/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0844\n",
      "Epoch 94/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0932 - val_loss: 0.0844\n",
      "Epoch 95/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0845\n",
      "Epoch 96/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0842\n",
      "Epoch 97/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0841\n",
      "Epoch 98/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0842\n",
      "Epoch 99/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0930 - val_loss: 0.0840\n",
      "Epoch 100/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0838\n",
      "Epoch 101/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0841\n",
      "Epoch 102/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0840\n",
      "Epoch 103/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0841\n",
      "Epoch 104/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0916 - val_loss: 0.0840\n",
      "Epoch 105/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0913 - val_loss: 0.0841\n",
      "Epoch 106/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0914 - val_loss: 0.0840\n",
      "Epoch 107/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 2us/step - loss: 0.0914 - val_loss: 0.0838\n",
      "Epoch 108/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0839\n",
      "Epoch 109/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 2us/step - loss: 0.0917 - val_loss: 0.0837\n",
      "Epoch 110/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0837\n",
      "Epoch 111/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0837\n",
      "Epoch 112/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0838\n",
      "Epoch 113/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0839\n",
      "Epoch 114/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0839\n",
      "Epoch 115/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0906 - val_loss: 0.0837\n",
      "Epoch 116/120\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 2us/step - loss: 0.0912 - val_loss: 0.0836\n",
      "Epoch 117/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0834\n",
      "Epoch 118/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0836\n",
      "Epoch 119/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0835\n",
      "Epoch 120/120\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0913 - val_loss: 0.0834\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 4. auc: 0.9215.\n",
      "CV mean score: 0.9403, std: 0.0117.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=StackModel_maker, \n",
    "                                             X=oof,\n",
    "                                             X_test=prediction,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:45:08.479891Z",
     "start_time": "2019-09-06T20:45:04.844705Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')\n",
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv(f'{model_folder}/stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:45:09.251891Z",
     "start_time": "2019-09-06T20:45:09.079876Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
