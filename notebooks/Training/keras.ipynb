{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:23.919382Z",
     "start_time": "2019-09-28T19:32:19.659028Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "main_dir = r'../../..'\n",
    "data_path = main_dir+'/data'\n",
    "import sys\n",
    "sys.path.append(main_dir)\n",
    "from typing import List, Set, Dict, Optional, Any, Tuple, Type, Union\n",
    "\n",
    "from BayDS.lib.pipeline import *\n",
    "from BayDS.lib.io import *\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:33.245788Z",
     "start_time": "2019-09-28T19:32:23.922384Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('e:/kaggle/09504/train_scaled.pkl')\n",
    "test = pd.read_pickle('e:/kaggle/09504/test_scaled.pkl')\n",
    "y = pd.read_pickle('e:/kaggle/09504/y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:38.821433Z",
     "start_time": "2019-09-28T19:32:33.247789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from BayDS.lib.training import *\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:39.103459Z",
     "start_time": "2019-09-28T19:32:38.823423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4',\n",
       "       'card5', 'card6', 'addr1', 'addr2',\n",
       "       ...\n",
       "       'Transaction_freq_2d_past', 'Transaction_freq_3d_past',\n",
       "       'Transaction_freq_7d_past', 'Transaction_freq_30d_past',\n",
       "       'Transaction_freq_5_past', 'Transaction_freq_5_center',\n",
       "       'Transaction_freq_10_past', 'Transaction_freq_10_center',\n",
       "       'Transaction_freq_100_past', 'Transaction_freq_100_center'],\n",
       "      dtype='object', length=698)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:39.496455Z",
     "start_time": "2019-09-28T19:32:39.106426Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "cat_col = yaml.load(open(r'e:/kaggle/09504/categorical_columns.yaml','r'),Loader=yaml.FullLoader) \n",
    "num_col = yaml.load(open(r'e:/kaggle/09504/numerical_columns.yaml','r'),Loader=yaml.FullLoader) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:39.778432Z",
     "start_time": "2019-09-28T19:32:39.499433Z"
    }
   },
   "outputs": [],
   "source": [
    "undef_cols = []\n",
    "for col in test.columns:\n",
    "    if col not in cat_col and col not in num_col:\n",
    "        print (col)\n",
    "#         undef_cols.append(col)\n",
    "# yaml.dump( undef_cols,open('e:/kaggle/09504/undef_cols.yaml','w') )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:40.049474Z",
     "start_time": "2019-09-28T19:32:39.781435Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# for column in num_col:\n",
    "#     print(column)\n",
    "#     if column not in train.columns:\n",
    "#         print(\"Absent column \", column)\n",
    "#         continue\n",
    "#     col = pd.concat([train[column],test[column]]).astype(np.float32)\n",
    "#     filtered = col[~col.isin([np.inf, -np.inf])].dropna()\n",
    "#     vmax = filtered.max()\n",
    "#     vmin = filtered.min()\n",
    "#     vmean = filtered.mean()\n",
    "#     col = col.replace({\n",
    "#         np.inf:vmax,\n",
    "#         -np.inf:vmin\n",
    "#        }).fillna(vmean)\n",
    "#     if vmax > 100 and vmin >= 0:\n",
    "#         col = np.log1p(col)\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     col.values[...] = scaler.fit_transform(col.values.reshape(-1,1)).flatten()\n",
    "    \n",
    "#     train[column] = col[train.index]\n",
    "#     test[column] = col[test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:40.321449Z",
     "start_time": "2019-09-28T19:32:40.051450Z"
    }
   },
   "outputs": [],
   "source": [
    "# train.to_pickle('e:/kaggle/09504/train_scaled.pkl')\n",
    "# test.to_pickle('e:/kaggle/09504/test_scaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:40.595437Z",
     "start_time": "2019-09-28T19:32:40.323446Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T19:32:40.878449Z",
     "start_time": "2019-09-28T19:32:40.597442Z"
    }
   },
   "outputs": [],
   "source": [
    "def NNModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "#     categorical_inputs = []\n",
    "#     for cat in categorical:\n",
    "#         categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "#     categorical_embeddings = []\n",
    "#     for i, cat in enumerate(categorical):\n",
    "#         categorical_embeddings.append(\n",
    "#             Embedding(category_counts[cat], int(np.log1p(category_counts[cat]) + 1), name = cat + \\\n",
    "#                       \"_embed\")(categorical_inputs[i]))\n",
    "\n",
    "#     categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(.1)(cat_emb)) for cat_emb in categorical_embeddings])\n",
    "# \n",
    "    numerical_inputs = Input(shape=[train.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "    x = Dense(600, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(300, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(100, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 8000,\n",
    "    'epochs': 30,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T20:39:05.592851Z",
     "start_time": "2019-09-28T19:32:40.880434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sat Sep 28 22:32:44 2019\n",
      "Encoding categorical features\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/30\n",
      "472432/472432 [==============================] - 32s 68us/step - loss: 0.1920 - val_loss: 0.1215\n",
      "Epoch 2/30\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.1233 - val_loss: 0.1200\n",
      "Epoch 3/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.1146 - val_loss: 0.1138\n",
      "Epoch 4/30\n",
      "472432/472432 [==============================] - 22s 48us/step - loss: 0.1075 - val_loss: 0.1112\n",
      "Epoch 5/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.1013 - val_loss: 0.1086\n",
      "Epoch 6/30\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0929 - val_loss: 0.1030\n",
      "Epoch 7/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0863 - val_loss: 0.0968\n",
      "Epoch 8/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0816 - val_loss: 0.0919\n",
      "Epoch 9/30\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0779 - val_loss: 0.0941\n",
      "Epoch 10/30\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0763 - val_loss: 0.0937\n",
      "Epoch 11/30\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0738 - val_loss: 0.0871\n",
      "Epoch 12/30\n",
      "472432/472432 [==============================] - 24s 52us/step - loss: 0.0721 - val_loss: 0.0879\n",
      "Epoch 13/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0704 - val_loss: 0.0841\n",
      "Epoch 14/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0699 - val_loss: 0.0871\n",
      "Epoch 15/30\n",
      "472432/472432 [==============================] - 24s 51us/step - loss: 0.0688 - val_loss: 0.0846\n",
      "Epoch 16/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0679 - val_loss: 0.0850\n",
      "Epoch 17/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0672 - val_loss: 0.0801\n",
      "Epoch 18/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0667 - val_loss: 0.0866\n",
      "Epoch 19/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0660 - val_loss: 0.0799\n",
      "Epoch 20/30\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0651 - val_loss: 0.0784\n",
      "Epoch 21/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0649 - val_loss: 0.0842\n",
      "Epoch 22/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0642 - val_loss: 0.0836\n",
      "Epoch 23/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0642 - val_loss: 0.0821\n",
      "Epoch 24/30\n",
      "472432/472432 [==============================] - 23s 49us/step - loss: 0.0639 - val_loss: 0.0835\n",
      "Epoch 25/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0632 - val_loss: 0.0771\n",
      "Epoch 26/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0635 - val_loss: 0.0749\n",
      "Epoch 27/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0624 - val_loss: 0.0779\n",
      "Epoch 28/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0621 - val_loss: 0.0776\n",
      "Epoch 29/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0619 - val_loss: 0.0793\n",
      "Epoch 30/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0622 - val_loss: 0.0783\n",
      "118108/118108 [==============================] - 1s 10us/step\n",
      "Fold 0. auc: 0.8890.\n",
      "Fold 2 started at Sat Sep 28 22:47:10 2019\n",
      "Encoding categorical features\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/30\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.1510 - val_loss: 0.1213\n",
      "Epoch 2/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1126 - val_loss: 0.1146\n",
      "Epoch 3/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1041 - val_loss: 0.1082\n",
      "Epoch 4/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0977 - val_loss: 0.1034\n",
      "Epoch 5/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0903 - val_loss: 0.0959\n",
      "Epoch 6/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0834 - val_loss: 0.0946\n",
      "Epoch 7/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0784 - val_loss: 0.0927\n",
      "Epoch 8/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0746 - val_loss: 0.0924\n",
      "Epoch 9/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0717 - val_loss: 0.0912\n",
      "Epoch 10/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0702 - val_loss: 0.0921\n",
      "Epoch 11/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0677 - val_loss: 0.0897\n",
      "Epoch 12/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0666 - val_loss: 0.0910\n",
      "Epoch 13/30\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 14/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0643 - val_loss: 0.0904\n",
      "Epoch 15/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0644 - val_loss: 0.0884\n",
      "Epoch 16/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0632 - val_loss: 0.0901\n",
      "Epoch 17/30\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0622 - val_loss: 0.0902\n",
      "Epoch 18/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0620 - val_loss: 0.0892\n",
      "Epoch 19/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0612 - val_loss: 0.0888\n",
      "Epoch 20/30\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0605 - val_loss: 0.0895\n",
      "Epoch 21/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0600 - val_loss: 0.0889\n",
      "Epoch 22/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0597 - val_loss: 0.0891\n",
      "Epoch 23/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0589 - val_loss: 0.0885\n",
      "Epoch 24/30\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0588 - val_loss: 0.0891\n",
      "Epoch 25/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0581 - val_loss: 0.0889\n",
      "Epoch 26/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0581 - val_loss: 0.0888\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 21s 46us/step - loss: 0.0577 - val_loss: 0.0876\n",
      "Epoch 28/30\n",
      "472432/472432 [==============================] - 21s 45us/step - loss: 0.0574 - val_loss: 0.0894\n",
      "Epoch 29/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0571 - val_loss: 0.0883\n",
      "Epoch 30/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0574 - val_loss: 0.0890\n",
      "118108/118108 [==============================] - 1s 10us/step\n",
      "Fold 1. auc: 0.9135.\n",
      "Fold 3 started at Sat Sep 28 23:00:04 2019\n",
      "Encoding categorical features\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/30\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.1759 - val_loss: 0.1210\n",
      "Epoch 2/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1158 - val_loss: 0.1138\n",
      "Epoch 3/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1088 - val_loss: 0.1086\n",
      "Epoch 4/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1032 - val_loss: 0.1047\n",
      "Epoch 5/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0968 - val_loss: 0.0996\n",
      "Epoch 6/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0907 - val_loss: 0.0949\n",
      "Epoch 7/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0850 - val_loss: 0.0913\n",
      "Epoch 8/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 9/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0757 - val_loss: 0.0894\n",
      "Epoch 10/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0732 - val_loss: 0.0890\n",
      "Epoch 11/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0707 - val_loss: 0.0888\n",
      "Epoch 12/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0697 - val_loss: 0.0892\n",
      "Epoch 13/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0682 - val_loss: 0.0873\n",
      "Epoch 14/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0670 - val_loss: 0.0864\n",
      "Epoch 15/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0663 - val_loss: 0.0875\n",
      "Epoch 16/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0656 - val_loss: 0.0860\n",
      "Epoch 17/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0648 - val_loss: 0.0858\n",
      "Epoch 18/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0634 - val_loss: 0.0864\n",
      "Epoch 19/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0628 - val_loss: 0.0860\n",
      "Epoch 20/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0628 - val_loss: 0.0853\n",
      "Epoch 21/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0623 - val_loss: 0.0874\n",
      "Epoch 22/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0620 - val_loss: 0.0874\n",
      "Epoch 23/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0619 - val_loss: 0.0855\n",
      "Epoch 24/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0608 - val_loss: 0.0851\n",
      "Epoch 25/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0605 - val_loss: 0.0855\n",
      "Epoch 26/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0600 - val_loss: 0.0868\n",
      "Epoch 27/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0599 - val_loss: 0.0864\n",
      "Epoch 28/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0592 - val_loss: 0.0882\n",
      "Epoch 29/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0588 - val_loss: 0.0850\n",
      "Epoch 30/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0582 - val_loss: 0.0865\n",
      "118108/118108 [==============================] - 1s 10us/step\n",
      "Fold 2. auc: 0.9094.\n",
      "Fold 4 started at Sat Sep 28 23:12:58 2019\n",
      "Encoding categorical features\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.1881 - val_loss: 0.1179\n",
      "Epoch 2/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1176 - val_loss: 0.1118\n",
      "Epoch 3/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1093 - val_loss: 0.1063\n",
      "Epoch 4/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1034 - val_loss: 0.1021\n",
      "Epoch 5/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0974 - val_loss: 0.0980\n",
      "Epoch 6/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0908 - val_loss: 0.0915\n",
      "Epoch 7/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0844 - val_loss: 0.0873\n",
      "Epoch 8/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0789 - val_loss: 0.0859\n",
      "Epoch 9/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0749 - val_loss: 0.0862\n",
      "Epoch 10/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0729 - val_loss: 0.0847\n",
      "Epoch 11/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0706 - val_loss: 0.0839\n",
      "Epoch 12/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0687 - val_loss: 0.0830\n",
      "Epoch 13/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0677 - val_loss: 0.0837\n",
      "Epoch 14/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0665 - val_loss: 0.0825\n",
      "Epoch 15/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0655 - val_loss: 0.0838\n",
      "Epoch 16/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0645 - val_loss: 0.0823\n",
      "Epoch 17/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0645 - val_loss: 0.0821\n",
      "Epoch 18/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0632 - val_loss: 0.0825\n",
      "Epoch 19/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0630 - val_loss: 0.0821\n",
      "Epoch 20/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0626 - val_loss: 0.0821\n",
      "Epoch 21/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0618 - val_loss: 0.0819\n",
      "Epoch 22/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0617 - val_loss: 0.0813\n",
      "Epoch 23/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0606 - val_loss: 0.0811\n",
      "Epoch 24/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0608 - val_loss: 0.0814\n",
      "Epoch 25/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0600 - val_loss: 0.0822\n",
      "Epoch 26/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0595 - val_loss: 0.0813\n",
      "Epoch 27/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0592 - val_loss: 0.0813\n",
      "Epoch 28/30\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0592 - val_loss: 0.0811\n",
      "Epoch 29/30\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0582 - val_loss: 0.0812\n",
      "Epoch 30/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.0579 - val_loss: 0.0823\n",
      "118108/118108 [==============================] - 1s 10us/step\n",
      "Fold 3. auc: 0.9333.\n",
      "Fold 5 started at Sat Sep 28 23:25:59 2019\n",
      "Encoding categorical features\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/30\n",
      "472432/472432 [==============================] - 22s 47us/step - loss: 0.1673 - val_loss: 0.1134\n",
      "Epoch 2/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1162 - val_loss: 0.1082\n",
      "Epoch 3/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.1077 - val_loss: 0.1050\n",
      "Epoch 4/30\n",
      "472432/472432 [==============================] - 21s 46us/step - loss: 0.1003 - val_loss: 0.0996\n",
      "Epoch 5/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0932 - val_loss: 0.0963\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0864 - val_loss: 0.0915\n",
      "Epoch 7/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0804 - val_loss: 0.0895\n",
      "Epoch 8/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0768 - val_loss: 0.0888\n",
      "Epoch 9/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0731 - val_loss: 0.0890\n",
      "Epoch 10/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0720 - val_loss: 0.0891\n",
      "Epoch 11/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0697 - val_loss: 0.0879\n",
      "Epoch 12/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0690 - val_loss: 0.0869\n",
      "Epoch 13/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0673 - val_loss: 0.0873\n",
      "Epoch 14/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0665 - val_loss: 0.0868\n",
      "Epoch 15/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0658 - val_loss: 0.0872\n",
      "Epoch 16/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0646 - val_loss: 0.0869\n",
      "Epoch 17/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0640 - val_loss: 0.0883\n",
      "Epoch 18/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0632 - val_loss: 0.0884\n",
      "Epoch 19/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0632 - val_loss: 0.0856\n",
      "Epoch 20/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0619 - val_loss: 0.0880\n",
      "Epoch 21/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0623 - val_loss: 0.0859\n",
      "Epoch 22/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0605 - val_loss: 0.0868\n",
      "Epoch 23/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0616 - val_loss: 0.0858\n",
      "Epoch 24/30\n",
      "472432/472432 [==============================] - 23s 48us/step - loss: 0.0599 - val_loss: 0.0862\n",
      "Epoch 25/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0602 - val_loss: 0.0857\n",
      "Epoch 26/30\n",
      "472432/472432 [==============================] - 22s 46us/step - loss: 0.0601 - val_loss: 0.0857\n",
      "Epoch 27/30\n",
      "472432/472432 [==============================] - 24s 50us/step - loss: 0.0592 - val_loss: 0.0860\n",
      "Epoch 28/30\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0594 - val_loss: 0.0862\n",
      "Epoch 29/30\n",
      "472432/472432 [==============================] - 25s 52us/step - loss: 0.0581 - val_loss: 0.0863\n",
      "Epoch 30/30\n",
      "472432/472432 [==============================] - 25s 53us/step - loss: 0.0588 - val_loss: 0.0864\n",
      "118108/118108 [==============================] - 1s 11us/step\n",
      "Fold 4. auc: 0.9048.\n",
      "CV mean score: 0.9100, std: 0.0143.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification_vb(model=NNModel_maker, \n",
    "                                             X=train,\n",
    "                                             X_test=test,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             plot_feature_importance=True,\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             categorial_columns=cat_col, categorial_encoder=CatBoostEncoder,\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T21:16:23.922473Z",
     "start_time": "2019-09-28T21:16:23.618443Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'e:/kaggle/09504/result_dict_keras', 'wb') as f:\n",
    "    #     q = json.dumps(result_dict_lgb,indent=2)\n",
    "        pickle.dump(result_dict_keras,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-28T22:04:26.757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# result_timefreq = train_model_classification_vb(model=NNModel_maker,\n",
    "#                                              X=train, X_test=test, y=y, params=params, folds=folds,\n",
    "#                                              model_type=train_options['model_type'],\n",
    "#                                              eval_metric=train_options['eval_metric'],\n",
    "#                                              plot_feature_importance=True,\n",
    "#                                              verbose=500, \n",
    "                                             \n",
    "#                                              averaging=train_options['averaging'],\n",
    "#                                              n_jobs=-1, groups=None,\n",
    "# #                                              train_1_sample_coef=None, train_0_sample_coef=0.2,\n",
    "# #                                              categorial_columns=cat_col, categorial_encoder=CatBoostEncoder\n",
    "#                                                )\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "pd.DataFrame(result_dict_keras['oof'], columns=['isFraud'], index=train.index).to_csv(\n",
    "    'oof_all_data_best_lgb_timefreq.csv')\n",
    "pd.DataFrame(result_dict_keras['prediction'], columns=['isFraud'], index=test.index).to_csv(\n",
    "    'prediction_all_data_best_lgb_timefreq.csv')\n",
    "\n",
    "sample_submission = pd.read_csv(data_path + 'sample_submission.csv').set_index('TransactionID')\n",
    "\n",
    "sub1 = pd.DataFrame(result_dict_keras['prediction'], columns=['isFraud'], index=test.index)\n",
    "\n",
    "sample_submission['isFraud'] = sub1  # *0.5 + sub2*0.25 + sub3*0.25\n",
    "\n",
    "sample_submission.to_csv('lgb_timefreq.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
