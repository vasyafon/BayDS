{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:12:42.415107Z",
     "start_time": "2019-09-29T15:12:42.333109Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:12:47.729363Z",
     "start_time": "2019-09-29T15:12:43.610086Z"
    }
   },
   "outputs": [],
   "source": [
    "main_path = r'../..'\n",
    "data_path = main_path+'/data'\n",
    "import sys\n",
    "sys.path.append(main_path)\n",
    "from BayDS.lib.pipeline import *\n",
    "from BayDS.lib.pipeline.ieee_fraud_nodes import *\n",
    "from typing import List, Set, Dict, Optional, Any, Tuple, Type, Union\n",
    "from BayDS.lib.io import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:12:50.139509Z",
     "start_time": "2019-09-29T15:12:50.011502Z"
    }
   },
   "outputs": [],
   "source": [
    "# main_dir = r'd:\\Documents\\Private\\Kaggle\\Baydin'\n",
    "main_dir = main_path\n",
    "# main_dir = r'f:\\my\\Prog\\kaggle\\Baydin'\n",
    "data_dir = f'{main_dir}/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1: Processing raw, add NanCounts and reduce mem usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:49:57.566201Z",
     "start_time": "2019-09-23T08:36:45.025709Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/01-JoinReduceMem')\n",
    "\n",
    "p.add_node(IEEEFraudTransactionLoaderNode, None, 'transactions',\n",
    "           params={\n",
    "               'input_directory': data_dir\n",
    "           })\n",
    "\n",
    "p.add_node(IEEEFraudIdentityLoaderNode, None, 'identity',\n",
    "           params={\n",
    "               'input_directory': data_dir\n",
    "           })\n",
    "\n",
    "p.add_node(AddNaNCountNode, 'transactions', 'transactions',\n",
    "           params={\n",
    "               'name': 'NanTransactionCount'\n",
    "           })\n",
    "p.add_node(AddNaNCountNode, 'identity', 'identity',\n",
    "           params={\n",
    "               'name': 'NanIdentityCount'\n",
    "           })\n",
    "p.add_node(JoinNode,\n",
    "           ('transactions', 'identity'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "\n",
    "p.add_node(EraserNode, params={\n",
    "    'remove_keys': ['transactions', 'identity']\n",
    "})\n",
    "p.add_node(ReduceMemoryUsageNode,\n",
    "           'data', 'data',\n",
    "           params={\n",
    "               'verbose': True\n",
    "           })\n",
    "p.run(verbose=True)\n",
    "print(p.data['data'].columns)\n",
    "p.save_data('pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2: New!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:27:43.114206Z",
     "start_time": "2019-09-29T14:27:42.983703Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Part 1: before aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:59:38.445821Z",
     "start_time": "2019-09-29T13:52:36.459732Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "0: LoaderNode [2019-09-29 16:52:36]\n",
      "params:\n",
      " {'input_directory': 'e:/kaggle/01-JoinReduceMem', 'file': 'data.pkl'}\n",
      "---------------------------\n",
      "1: TimeTransformNode [2019-09-29 16:52:47]\n",
      "params:\n",
      " None\n",
      "---------------------------\n",
      "2: AddCardIdNode [2019-09-29 16:52:58]\n",
      "params:\n",
      " None\n",
      "---------------------------\n",
      "3: AddNewCardIdNode [2019-09-29 16:53:02]\n",
      "params:\n",
      " None\n",
      "5%\n",
      "10%\n",
      "15%\n",
      "20%\n",
      "25%\n",
      "30%\n",
      "35%\n",
      "40%\n",
      "50%\n",
      "55%\n",
      "60%\n",
      "100%\n",
      "5%\n",
      "10%\n",
      "15%\n",
      "20%\n",
      "25%\n",
      "30%\n",
      "35%\n",
      "40%\n",
      "45%\n",
      "50%\n",
      "55%\n",
      "60%\n",
      "65%\n",
      "70%\n",
      "75%\n",
      "80%\n",
      "85%\n",
      "90%\n",
      "95%\n",
      "---------------------------\n",
      "4: AnyaNewFENode [2019-09-29 16:57:07]\n",
      "params:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:214: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No intersection in Train card2 5012\n",
      "Intersection in Train card2 585528\n",
      "No intersection in Train card3 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:220: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection in Train card3 590493\n",
      "No intersection in Train card4 0\n",
      "Intersection in Train card4 590540\n",
      "No intersection in Train card5 7279\n",
      "Intersection in Train card5 583261\n",
      "No intersection in Train card6 30\n",
      "Intersection in Train card6 590510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:224: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['TransactionAmt_check'] = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:229: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].clip(None, max_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "5: EmailTransformNode [2019-09-29 16:58:39]\n",
      "params:\n",
      " None\n",
      "---------------------------\n",
      "6: AddDeviceOSInfoNode [2019-09-29 16:58:41]\n",
      "params:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:1210: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  idx = data[data.Browser == browser][data.BrowserVersion.isin(browser_map.keys())].index\n",
      "c:\\python37\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving numerical_columns\n",
      "Saving categorical_columns\n",
      "Saving data\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e159c771c6f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Documents\\Private\\Kaggle\\Baydin\\BayDS\\lib\\pipeline\\pipeline.py\u001b[0m in \u001b[0;36msave_data\u001b[1;34m(self, format, dict_format, verbose, only_keys)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pickle'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{self.working_folder}/{k}.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{self.working_folder}/{k}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(self, path, compression, protocol)\u001b[0m\n\u001b[0;32m   2769\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2771\u001b[1;33m         \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(obj, path, compression, protocol)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir =f'e:/kaggle/01-JoinReduceMem'\n",
    "\n",
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/pipeline-1')\n",
    "p.data['numerical_columns'] = []\n",
    "p.data['categorical_columns'] = []\n",
    "\n",
    "p.add_node(LoaderNode, None, 'data',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'data.pkl'\n",
    "           })\n",
    "\n",
    "p.add_node(TimeTransformNode, 'data')\n",
    "p.add_node(AddCardIdNode, ('data', 'numerical_columns', 'categorical_columns'))\n",
    "p.add_node(AddNewCardIdNode, ('data', 'numerical_columns', 'categorical_columns'))\n",
    "p.add_node(AnyaNewFENode, 'data',\n",
    "           'data')\n",
    "p.add_node(EmailTransformNode, 'data')\n",
    "p.add_node(AddDeviceOSInfoNode, ('data', 'numerical_columns', 'categorical_columns'))\n",
    "p.save\n",
    "p.run()\n",
    "p.save_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:27:59.666543Z",
     "start_time": "2019-09-29T14:27:59.539354Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Part 2: Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:21:23.416847Z",
     "start_time": "2019-09-29T14:16:37.482007Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "0: LoaderNode [2019-09-29 17:16:37]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-1', 'file': 'data.pkl'}\n",
      "---------------------------\n",
      "1: LoaderNode [2019-09-29 17:16:45]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-1', 'file': 'numerical_columns.yaml'}\n",
      "---------------------------\n",
      "2: LoaderNode [2019-09-29 17:16:45]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-1', 'file': 'categorical_columns.yaml'}\n",
      "---------------------------\n",
      "3: AddGroupNumericalAggregatesNode [2019-09-29 17:16:45]\n",
      "params:\n",
      " {'features': ['id_02', 'D15', 'TransactionAmt'], 'groupby': ['card1']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:832: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  slice_df['group_col'] = slice_df[gc].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "4: AddGroupNumericalAggregatesNode [2019-09-29 17:16:47]\n",
      "params:\n",
      " {'features': ['id_02', 'D15', 'TransactionAmt'], 'groupby': ['card4']}\n",
      "---------------------------\n",
      "5: AddGlobalFrequencyEncodingNode [2019-09-29 17:16:51]\n",
      "params:\n",
      " {'features': ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'uid', 'uid2', 'uid3', 'uid4', 'uid5', 'new_card_id', 'bank_type', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'product_type', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'DeviceInfo', 'id_01', 'id_36', 'device_name', 'device_version', 'Browser', 'BrowserVersion', 'id_30', 'id_31', 'id_33', 'OS', 'OSVersion', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'ProductCD', 'DeviceType', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_32', 'id_34', 'id_37', 'id_38']}\n",
      "---------------------------\n",
      "6: AddGroupFrequencyEncodingNode [2019-09-29 17:17:03]\n",
      "params:\n",
      " {'features': ['bank_type', 'product_type', 'card1', 'card2', 'card3', 'card5', 'uid', 'uid2', 'uid3'], 'group_by': ['DT_M'], 'freq': True, 'count': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:893: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  slice_df['group_col'] = slice_df[gc].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "7: AddGroupFrequencyEncodingNode [2019-09-29 17:17:13]\n",
      "params:\n",
      " {'features': ['bank_type', 'product_type', 'card1', 'card2', 'card3', 'card5', 'uid', 'uid2', 'uid3'], 'group_by': ['DT_W'], 'freq': True, 'count': False}\n",
      "---------------------------\n",
      "8: AddGroupFrequencyEncodingNode [2019-09-29 17:17:21]\n",
      "params:\n",
      " {'features': ['bank_type', 'product_type', 'card1', 'card2', 'card3', 'card5', 'uid', 'uid2', 'uid3'], 'group_by': ['DT_D'], 'freq': True, 'count': False}\n",
      "---------------------------\n",
      "9: AddGroupNumericalAggregatesNode [2019-09-29 17:17:32]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['uid'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "10: AddGroupNumericalAggregatesNode [2019-09-29 17:17:39]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['uid2'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "11: AddGroupNumericalAggregatesNode [2019-09-29 17:17:48]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['uid3'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "12: AddGroupNumericalAggregatesNode [2019-09-29 17:17:59]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['uid4'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "13: AddGroupNumericalAggregatesNode [2019-09-29 17:18:13]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['uid5'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "14: AddGroupNumericalAggregatesNode [2019-09-29 17:18:26]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['new_card_id'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "15: AddGroupNumericalAggregatesNode [2019-09-29 17:18:40]\n",
      "params:\n",
      " {'features': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15'], 'group_by': ['bank_type'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "16: AddGroupNumericalAggregatesNode [2019-09-29 17:18:49]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card1'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "17: AddGroupNumericalAggregatesNode [2019-09-29 17:18:53]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card2'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "18: AddGroupNumericalAggregatesNode [2019-09-29 17:18:57]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card3'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "19: AddGroupNumericalAggregatesNode [2019-09-29 17:19:01]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card5'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "20: AddGroupNumericalAggregatesNode [2019-09-29 17:19:05]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "21: AddGroupNumericalAggregatesNode [2019-09-29 17:19:09]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid2'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "22: AddGroupNumericalAggregatesNode [2019-09-29 17:19:13]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid3'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "23: AddGroupNumericalAggregatesNode [2019-09-29 17:19:16]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid4'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "24: AddGroupNumericalAggregatesNode [2019-09-29 17:19:20]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid5'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "25: AddGroupNumericalAggregatesNode [2019-09-29 17:19:25]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['new_card_id'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "26: AddGroupNumericalAggregatesNode [2019-09-29 17:19:29]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['bank_type'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "27: AddGroupNumericalAggregatesNode [2019-09-29 17:19:30]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['DT_M'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "28: AddGroupNumericalAggregatesNode [2019-09-29 17:19:34]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['DT_D'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "29: AddGroupNumericalAggregatesNode [2019-09-29 17:19:38]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['DT_W'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "30: AddGroupNumericalAggregatesNode [2019-09-29 17:19:43]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card1', 'DT_W'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\BayDS\\lib\\pipeline\\ieee_fraud_nodes.py:834: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  slice_df['group_col'] += '_' + slice_df[gc].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "31: AddGroupNumericalAggregatesNode [2019-09-29 17:19:48]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card1', 'DT_M'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "32: AddGroupNumericalAggregatesNode [2019-09-29 17:19:53]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['card1', 'DT_D'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "33: AddGroupNumericalAggregatesNode [2019-09-29 17:19:59]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid', 'DT_M'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "34: AddGroupNumericalAggregatesNode [2019-09-29 17:20:04]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid', 'DT_W'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "---------------------------\n",
      "35: AddGroupNumericalAggregatesNode [2019-09-29 17:20:09]\n",
      "params:\n",
      " {'features': ['TransactionAmt'], 'group_by': ['uid', 'DT_D'], 'to_mean': True, 'to_std': True, 'to_minmax': True, 'to_std_score': True}\n",
      "Saving data\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a0bc1aded57c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Documents\\Private\\Kaggle\\Baydin\\BayDS\\lib\\pipeline\\pipeline.py\u001b[0m in \u001b[0;36msave_data\u001b[1;34m(self, format, dict_format, verbose, only_keys)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pickle'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{self.working_folder}/{k}.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{self.working_folder}/{k}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(self, path, compression, protocol)\u001b[0m\n\u001b[0;32m   2769\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2771\u001b[1;33m         \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(obj, path, compression, protocol)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "data_dir =f'{main_dir}/Snapshots/1/pipeline-1'\n",
    "\n",
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/pipeline-2')\n",
    "\n",
    "p.add_node(LoaderNode, None, 'data',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'data.pkl'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'numerical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'numerical_columns.yaml'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'categorical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'categorical_columns.yaml'\n",
    "           })\n",
    "\n",
    "p.add_node(AddGroupNumericalAggregatesNode, \n",
    "          ('data', 'numerical_columns', 'categorical_columns'),\n",
    "          params = {\n",
    "              'features':['id_02','D15','TransactionAmt'],\n",
    "              'groupby':['card1']\n",
    "          })\n",
    "p.add_node(AddGroupNumericalAggregatesNode, \n",
    "          ('data', 'numerical_columns', 'categorical_columns'),\n",
    "          params = {\n",
    "              'features':['id_02','D15','TransactionAmt'],\n",
    "              'groupby':['card4']\n",
    "          })\n",
    "\n",
    "# ВЫЗОВ GLOBAL FREQ ЭНКОДИНГ\n",
    "# \"['device_version', 'version_id_31', 'OS_id_30', 'device_name', 'version_id_30', 'id_31_device', 'browser_id_31']\n",
    "cols_global_freq_enc = ['card1','card2','card3','card4','card5','card6',\n",
    "                        'uid','uid2','uid3','uid4','uid5', 'new_card_id', 'bank_type'] + \\\n",
    "                       ['D' + str(i) for i in range(1, 16)] + ['product_type']  + \\\n",
    "                       ['C' + str(i) for i in range(1, 15)] + \\\n",
    "                       ['DeviceInfo','id_01','id_36', 'device_name', 'device_version', 'Browser', 'BrowserVersion',\n",
    "                         'id_30', 'id_31', 'id_33','OS','OSVersion',\n",
    "                         'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
    "                         'ProductCD', 'DeviceType', 'id_12','id_13', 'id_14', 'id_15', 'id_16', 'id_17', \n",
    "                          'id_18', 'id_19', 'id_20', 'id_21', 'id_22','id_23', 'id_24','id_25', 'id_26', \n",
    "                          'id_27', 'id_28', 'id_29',   'id_32', 'id_34', 'id_37', 'id_38']\n",
    "\n",
    "p.add_node(AddGlobalFrequencyEncodingNode, \n",
    "          ('data', 'numerical_columns', 'categorical_columns'),\n",
    "          params = {\n",
    "              'features':cols_global_freq_enc,\n",
    "          })\n",
    "\n",
    "# ВЫЗОВ TIMEBLOCK FREQ ЭНКОДИНГ\n",
    "\n",
    "groupbys = ['DT_M','DT_W','DT_D']\n",
    "for groupby in groupbys:\n",
    "    p.add_node(AddGroupFrequencyEncodingNode, \n",
    "              ('data', 'numerical_columns', 'categorical_columns'),\n",
    "              params = {\n",
    "                  'features':['bank_type', 'product_type', 'card1', 'card2', 'card3', 'card5', 'uid', 'uid2', 'uid3'],\n",
    "                  'group_by':[groupby],\n",
    "                  'freq':True,\n",
    "                  'count':False\n",
    "              })\n",
    "\n",
    "# ВЫЗОВ ФУНКЦИИ GROUP NUMERICAL AGGREGATE\n",
    "\n",
    "groupbys = ['uid','uid2','uid3','uid4','uid5','new_card_id','bank_type']\n",
    "for groupby in groupbys:\n",
    "    p.add_node(AddGroupNumericalAggregatesNode, \n",
    "              ('data', 'numerical_columns', 'categorical_columns'),\n",
    "              params = {\n",
    "                  'features':['D' + str(i) for i in range(1,16)],\n",
    "                  'group_by':[groupby],\n",
    "                  'to_mean':True,\n",
    "                  'to_std':True,\n",
    "                  'to_minmax':True,\n",
    "                  'to_std_score':True\n",
    "              })\n",
    "    \n",
    "groupbys =['card1','card2','card3','card5','uid','uid2','uid3','uid4','uid5','new_card_id', 'bank_type', \n",
    "        'DT_M', 'DT_D', 'DT_W' , ['card1', 'DT_W'], ['card1', 'DT_M'], ['card1', 'DT_D'],\n",
    "        ['uid', 'DT_M'], ['uid', 'DT_W'], ['uid', 'DT_D']\n",
    "       ]\n",
    "for groupby in groupbys:\n",
    "    if isinstance(groupby, list):\n",
    "        gby=groupby\n",
    "    else:\n",
    "        gby=[groupby]\n",
    "    p.add_node(AddGroupNumericalAggregatesNode, \n",
    "              ('data', 'numerical_columns', 'categorical_columns'),\n",
    "              params = {\n",
    "                  'features':['TransactionAmt'],\n",
    "                  'group_by':gby,\n",
    "                  'to_mean':True,\n",
    "                  'to_std':True,\n",
    "                  'to_minmax':True,\n",
    "                  'to_std_score':True\n",
    "              })\n",
    "p.save()\n",
    "p.run()\n",
    "p.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:28:14.551214Z",
     "start_time": "2019-09-29T14:28:14.427181Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Part 3: After aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:57:12.757163Z",
     "start_time": "2019-09-29T14:51:58.348318Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "0: LoaderNode [2019-09-29 17:51:58]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-2', 'file': 'data.pkl'}\n",
      "---------------------------\n",
      "1: LoaderNode [2019-09-29 17:52:11]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-2', 'file': 'numerical_columns.yaml'}\n",
      "---------------------------\n",
      "2: LoaderNode [2019-09-29 17:52:11]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/pipeline-2', 'file': 'categorical_columns.yaml'}\n",
      "---------------------------\n",
      "3: DropFeaturesNode [2019-09-29 17:52:11]\n",
      "params:\n",
      " {'drop': ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']}\n",
      "---------------------------\n",
      "4: LoaderNode [2019-09-29 17:52:21]\n",
      "params:\n",
      " {'input_directory': 'e:\\\\Kaggle\\\\NewId', 'file': 'TransactionAmt_Agg.pkl'}\n",
      "---------------------------\n",
      "5: LoaderNode [2019-09-29 17:52:21]\n",
      "params:\n",
      " {'input_directory': 'e:\\\\Kaggle\\\\NewId', 'file': 'C5_Agg.pkl'}\n",
      "---------------------------\n",
      "6: LoaderNode [2019-09-29 17:52:22]\n",
      "params:\n",
      " {'input_directory': 'e:\\\\Kaggle\\\\NewId', 'file': 'C8_Agg.pkl'}\n",
      "---------------------------\n",
      "7: JoinNode [2019-09-29 17:52:22]\n",
      "params:\n",
      " {'on': 'TransactionID'}\n",
      "---------------------------\n",
      "8: JoinNode [2019-09-29 17:53:14]\n",
      "params:\n",
      " {'on': 'TransactionID'}\n",
      "---------------------------\n",
      "9: JoinNode [2019-09-29 17:53:20]\n",
      "params:\n",
      " {'on': 'TransactionID'}\n",
      "---------------------------\n",
      "10: EraserNode [2019-09-29 17:53:27]\n",
      "params:\n",
      " {'remove_keys': ['C5_Agg', 'C8_Agg', 'TransactionAmt_Agg']}\n",
      "---------------------------\n",
      "11: AddGlobalFrequencyEncodingNode [2019-09-29 17:53:27]\n",
      "params:\n",
      " {'features': ['ProductCD', 'addr1', 'addr2']}\n",
      "---------------------------\n",
      "12: AnyaFinalFENode [2019-09-29 17:53:36]\n",
      "params:\n",
      " None\n",
      "---------------------------\n",
      "13: EraserNode [2019-09-29 17:54:27]\n",
      "params:\n",
      " {'remove_keys': ['C5_Agg', 'C8_Agg', 'TransactionAmt_Agg']}\n",
      "Warning: C5_Agg is not in data\n",
      "Warning: C8_Agg is not in data\n",
      "Warning: TransactionAmt_Agg is not in data\n",
      "---------------------------\n",
      "14: LoaderNode [2019-09-29 17:54:27]\n",
      "params:\n",
      " {'input_directory': '../../Snapshots/1/VFeatures', 'file': 'v_features_reduced.pkl'}\n",
      "---------------------------\n",
      "15: JoinNode [2019-09-29 17:54:29]\n",
      "params:\n",
      " {'on': 'TransactionID'}\n",
      "---------------------------\n",
      "16: EraserNode [2019-09-29 17:55:40]\n",
      "params:\n",
      " {'remove_keys': ['v_features']}\n",
      "---------------------------\n",
      "17: LoaderNode [2019-09-29 17:55:40]\n",
      "params:\n",
      " {'input_directory': 'e:\\\\Kaggle\\\\TimeAggs24.09', 'file': 'transaction_frequencies.pkl'}\n",
      "---------------------------\n",
      "18: JoinNode [2019-09-29 17:55:41]\n",
      "params:\n",
      " {'on': 'TransactionID'}\n",
      "---------------------------\n",
      "19: EraserNode [2019-09-29 17:55:49]\n",
      "params:\n",
      " {'remove_keys': ['transaction_freq']}\n",
      "Saving data\n",
      "Saving numerical_columns\n",
      "Saving categorical_columns\n"
     ]
    }
   ],
   "source": [
    "data_dir =f'{main_dir}/Snapshots/1/pipeline-2'\n",
    "new_id_data_dir = r'e:\\Kaggle\\NewId'\n",
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/pipeline-3')\n",
    "v_dir = f'{main_dir}/Snapshots/1/VFeatures'\n",
    "\n",
    "p.add_node(LoaderNode, None, 'data',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'data.pkl'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'numerical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'numerical_columns.yaml'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'categorical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'categorical_columns.yaml'\n",
    "           })\n",
    "\n",
    "VFeatures_to_remove = [f'V{i}' for i in range(1,340)]\n",
    "# VFeatures_to_remove = [vf for vf in VFeatures_to_remove if vf in p.data['data'].columns]\n",
    "p.save()\n",
    "\n",
    "p.add_node(DropFeaturesNode,\n",
    "           ('data','numerical_columns','categorical_columns'),\n",
    "           ('data','numerical_columns','categorical_columns'),\n",
    "           params={\n",
    "               'drop': VFeatures_to_remove,\n",
    "           })\n",
    "\n",
    "\n",
    "p.add_node(LoaderNode, None, 'TransactionAmt_Agg',\n",
    "           params={\n",
    "               'input_directory': new_id_data_dir,\n",
    "               'file': 'TransactionAmt_Agg.pkl'\n",
    "           })\n",
    "\n",
    "p.add_node(LoaderNode, None, 'C5_Agg',\n",
    "           params={\n",
    "               'input_directory': new_id_data_dir,\n",
    "               'file': 'C5_Agg.pkl'\n",
    "           })\n",
    "\n",
    "p.add_node(LoaderNode, None, 'C8_Agg',\n",
    "           params={\n",
    "               'input_directory': new_id_data_dir,\n",
    "               'file': 'C8_Agg.pkl'\n",
    "           })\n",
    "p.add_node(JoinNode,\n",
    "           ('data', 'TransactionAmt_Agg'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "\n",
    "p.add_node(JoinNode,\n",
    "           ('data', 'C5_Agg'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "p.add_node(JoinNode,\n",
    "           ('data', 'C8_Agg'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "p.add_node(EraserNode, params={\n",
    "    'remove_keys': ['C5_Agg', 'C8_Agg', 'TransactionAmt_Agg']\n",
    "})\n",
    "\n",
    "p.add_node(AddGlobalFrequencyEncodingNode, \n",
    "          ('data', 'numerical_columns', 'categorical_columns'),\n",
    "          params = {\n",
    "              'features':\"ProductCD,addr1,addr2\".split(\",\"),\n",
    "          })\n",
    "p.add_node(AnyaFinalFENode, 'data')\n",
    "p.add_node(EraserNode, params={\n",
    "    'remove_keys': ['C5_Agg', 'C8_Agg', 'TransactionAmt_Agg']\n",
    "})\n",
    "\n",
    "p.add_node(LoaderNode, None, 'v_features',\n",
    "           params={\n",
    "               'input_directory': v_dir,\n",
    "               'file': 'v_features_reduced.pkl'\n",
    "           })\n",
    "p.add_node(JoinNode,\n",
    "           ('data', 'v_features'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "p.add_node(EraserNode,\n",
    "           params={\n",
    "    'remove_keys': ['v_features']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "p.add_node(LoaderNode, None, 'transaction_freq',\n",
    "           params={\n",
    "               'input_directory': f'e:\\Kaggle\\TimeAggs24.09',\n",
    "               'file': 'transaction_frequencies.pkl'\n",
    "           })\n",
    "p.add_node(JoinNode,\n",
    "           ('data', 'transaction_freq'),\n",
    "           'data',\n",
    "           params={\n",
    "               'on': 'TransactionID'\n",
    "           })\n",
    "p.add_node(EraserNode,\n",
    "           params={\n",
    "    'remove_keys': ['transaction_freq']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "p.run(verbose=True)\n",
    "p.data['numerical_columns'].extend([col for col in p.data['data'].columns if col.startswith('V_PCA')])\n",
    "p.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:07:04.534782Z",
     "start_time": "2019-09-29T14:58:53.200295Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "20: ReduceMemoryUsageNode [2019-09-29 17:58:53]\n",
      "params:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "p.add_node(ReduceMemoryUsageNode, 'data', 'data')\n",
    "p.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:10:09.573070Z",
     "start_time": "2019-09-29T15:09:14.753849Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Saving numerical_columns\n",
      "Saving categorical_columns\n"
     ]
    }
   ],
   "source": [
    "p.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T14:57:48.371919Z",
     "start_time": "2019-09-29T14:57:48.207458Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD', 'card1',\n",
       "       'card2', 'card3', 'card4', 'card5', 'card6',\n",
       "       ...\n",
       "       'Transaction_freq_2d_past', 'Transaction_freq_3d_past',\n",
       "       'Transaction_freq_7d_past', 'Transaction_freq_30d_past',\n",
       "       'Transaction_freq_5_past', 'Transaction_freq_5_center',\n",
       "       'Transaction_freq_10_past', 'Transaction_freq_10_center',\n",
       "       'Transaction_freq_100_past', 'Transaction_freq_100_center'],\n",
       "      dtype='object', length=948)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.data['data'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T09:56:43.145918Z",
     "start_time": "2019-09-23T09:33:25.786634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# todo: check LatestBrowser generation\n",
    "\n",
    "numerical_cols = ['id_%02d' % i for i in range(1,12)] + [\"V%d\"%i for i in range(1,340)] + [\"D%d\"%i for i in range(1,16)] + [\"C%d\"%i for i in range(1,15)]  + ['dist1','TransactionAmt', 'NanIdentityCount', 'NanTransactionCount', '_Weekdays', '_Hours', '_Days', 'Date', 'dist2']\n",
    "label_cols = ['M1', 'M2', 'M3','M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'card4', 'card6', 'ProductCD'] + ['id_%02d'%i for i in (12,15,16,28,29,32,34,35,36,37,38)]\n",
    "label_cols += ['id_13', 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27',\n",
    "            'id_30', 'id_31',  'id_33', 'DeviceType', 'DeviceInfo', 'P_emaildomain',\n",
    "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', \n",
    "            'P_emaildomain_bin', 'P_emaildomain_suffix', 'R_emaildomain_bin', 'R_emaildomain_suffix']\n",
    "\n",
    "#add_from Anya Features\n",
    "numerical_cols+=['TransactionDT', 'Weekdays', 'Hours', 'Days','DT_M', 'DT_W', 'DT_D','id_02_to_mean_card1', 'id_02_to_mean_card4', 'id_02_to_std_card1', 'id_02_to_std_card4', 'D15_to_mean_card1', 'D15_to_mean_card4', 'D15_to_std_card1', 'D15_to_std_card4', 'D15_to_mean_addr1', 'D15_to_std_addr1', 'TransactionAmt_to_mean_card1', 'TransactionAmt_to_mean_card4', 'TransactionAmt_to_std_card1', 'TransactionAmt_to_std_card4', 'TransactionAmt_decimal','nulls1','screen_width', 'screen_height','TransactionAmt_Log', 'card1_count_full',   'Transaction_day_of_week', 'Transaction_hour', 'id_01_count_dist', 'id_31_count_dist', 'id_33_count_dist', 'id_36_count_dist', 'card2_count_full', 'card3_count_full', 'card4_count_full', 'card5_count_full', 'card6_count_full', 'addr1_count_full', 'addr2_count_full', 'id_36_count_full', 'M_sum', 'M_na', 'ProductCD_target_mean', 'M4_target_mean',  'card1_TransactionAmt_mean', 'card1_TransactionAmt_std', 'card2_TransactionAmt_mean', 'card2_TransactionAmt_std', 'card3_TransactionAmt_mean', 'card3_TransactionAmt_std', 'card5_TransactionAmt_mean', 'card5_TransactionAmt_std', 'uid_TransactionAmt_mean', 'uid_TransactionAmt_std', 'uid2_TransactionAmt_mean', 'uid2_TransactionAmt_std', 'uid3_TransactionAmt_mean', 'uid3_TransactionAmt_std', 'card1_fq_enc', 'card2_fq_enc', 'card3_fq_enc', 'card5_fq_enc', 'C1_fq_enc', 'C2_fq_enc', 'C3_fq_enc', 'C4_fq_enc', 'C5_fq_enc', 'C6_fq_enc', 'C7_fq_enc', 'C8_fq_enc', 'C9_fq_enc', 'C10_fq_enc', 'C11_fq_enc', 'C12_fq_enc', 'C13_fq_enc', 'C14_fq_enc', 'D1_fq_enc', 'D2_fq_enc', 'D3_fq_enc', 'D4_fq_enc', 'D5_fq_enc', 'D6_fq_enc', 'D7_fq_enc', 'D8_fq_enc', 'addr1_fq_enc', 'addr2_fq_enc', 'dist1_fq_enc', 'dist2_fq_enc', 'P_emaildomain_fq_enc', 'R_emaildomain_fq_enc', 'DeviceInfo_fq_enc', 'id_30_fq_enc', 'version_id_30_fq_enc', 'version_id_31_fq_enc', 'id_33_fq_enc', 'uid_fq_enc', 'uid2_fq_enc', 'uid3_fq_enc', 'DT_M_total', 'DT_W_total', 'DT_D_total', 'card1_DT_M', 'card2_DT_M', 'card3_DT_M', 'card5_DT_M', 'uid_DT_M', 'uid2_DT_M', 'uid3_DT_M', 'card1_DT_W', 'card2_DT_W', 'card3_DT_W', 'card5_DT_W', 'uid_DT_W', 'uid2_DT_W', 'uid3_DT_W', 'card1_DT_D', 'card2_DT_D', 'card3_DT_D', 'card5_DT_D', 'uid_DT_D', 'uid2_DT_D', 'uid3_DT_D']\n",
    "label_cols+=['isNight','lastest_browser', 'device_name', 'device_version', 'OS_id_30', 'version_id_30', 'browser_id_31', 'version_id_31', 'had_id', 'id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', 'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1','uid', 'uid2', 'uid3']\n",
    "strange_cols = ['Transaction_day_of_week', 'Transaction_hour']\n",
    "\n",
    "p.data['numerical_columns'] = numerical_cols\n",
    "p.data['categorical_columns'] = label_cols\n",
    "p.data['useless_columns'] = strange_cols\n",
    "\n",
    "\n",
    "\n",
    "p.add_node(AddTemporalAggregates, input_key=('data', 'numerical_columns', 'categorical_columns'),\n",
    "           params={\n",
    "               'features':['TransactionAmt', 'C5', 'C8'],\n",
    "               'group_by': 'new_card_id'\n",
    "           })\n",
    "p.save()\n",
    "p.run()\n",
    "p.save_data()\n",
    "# del p\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T18:47:26.926607Z",
     "start_time": "2019-09-19T18:43:32.922628Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir =f'{main_dir}/Snapshots/1/99'\n",
    "\n",
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/04-Temporal')\n",
    "\n",
    "p.add_node(LoaderNode, None, 'data',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'data.pkl'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'numerical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'numerical_columns.yaml'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'categorical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'categorical_columns.yaml'\n",
    "           })\n",
    "\n",
    "p.add_node(AddTemporalAggregates, input_key=('data', 'numerical_columns', 'categorical_columns'),\n",
    "           params={\n",
    "               'features':['TransactionAmt']\n",
    "           }\n",
    "          )\n",
    "p.save()\n",
    "p.run(verbose=True)\n",
    "p.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:24:37.017449Z",
     "start_time": "2019-09-29T15:24:18.010363Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir =f'{main_dir}/Snapshots/1/pipeline-3'\n",
    "\n",
    "p = Pipeline(working_folder=f'{main_dir}/Snapshots/1/05-LabelEncoded-last')\n",
    "\n",
    "p.add_node(LoaderNode, None, 'data',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'data.pkl'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'numerical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'numerical_columns.yaml'\n",
    "           })\n",
    "p.add_node(LoaderNode, None, 'categorical_columns',\n",
    "           params={\n",
    "               'input_directory': data_dir,\n",
    "               'file': 'categorical_columns.yaml'\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:27:20.040441Z",
     "start_time": "2019-09-29T15:24:59.726052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "3: LabelEncoderNode [2019-09-29 18:24:59]\n",
      "params:\n",
      " None\n",
      "---------------------------\n",
      "4: EraserNode [2019-09-29 18:26:57]\n",
      "params:\n",
      " {'remove_keys': ['data']}\n",
      "Saving numerical_columns\n",
      "Saving categorical_columns\n",
      "Saving label_encoded_data\n"
     ]
    }
   ],
   "source": [
    "p.add_node(LabelEncoderNode, input_key=('data', 'numerical_columns', 'categorical_columns'),\n",
    "           output_key=\"label_encoded_data\"\n",
    "          )\n",
    "p.add_node(EraserNode, params={\n",
    "    'remove_keys': ['data']\n",
    "})\n",
    "p.save()\n",
    "p.run(verbose=True)\n",
    "p.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:28:20.829864Z",
     "start_time": "2019-09-29T15:28:20.684496Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b7342956652e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "all_features = list(p.data['data'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:24:41.630842Z",
     "start_time": "2019-09-29T15:24:41.499835Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = [f for f in p.data['numerical_columns'] if f in all_features]\n",
    "categorical_columns =  [f for f in p.data['categorical_columns'] if f in all_features]\n",
    "unrecognized_features = [f for f in all_features if f not in numerical_columns and f not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:24:43.850301Z",
     "start_time": "2019-09-29T15:24:43.730287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isFraud']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrecognized_featuresognized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T15:21:10.856131Z",
     "start_time": "2019-09-29T15:21:10.656061Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml.dump(unrecognized_features,open(p.working_folder+'/unrecognized.yaml','w'))\n",
    "yaml.dump(categorical_columns,open(p.working_folder+'/categorical_columns.yaml','w'))\n",
    "yaml.dump(numerical_columns,open(p.working_folder+'/numerical_columns.yaml','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T17:02:07.361281Z",
     "start_time": "2019-09-21T17:01:22.043791Z"
    }
   },
   "outputs": [],
   "source": [
    "p.save_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "706px",
    "left": "1516px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
