{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T18:48:50.630803Z",
     "start_time": "2019-10-01T18:48:50.440Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import sys\n",
    "main_path = r'../..'\n",
    "sys.path.append(main_path)\n",
    "from BayDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T18:48:51.278808Z",
     "start_time": "2019-10-01T18:48:51.165805Z"
    }
   },
   "outputs": [],
   "source": [
    "main_folder = r'../../Data/sub'\n",
    "model_folder = r'../../Snapshots/Stacking/3009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:02:29.680271Z",
     "start_time": "2019-10-01T19:02:29.558235Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "lb = yaml.load(open(f'{main_folder}/lb.yaml','r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:14:56.796065Z",
     "start_time": "2019-10-01T19:14:51.626021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oofFile': 'oof_all_data_best_lgb_26.csv', 'predictionFile': 'prediction_all_data_best_lgb_26.csv', 'score': 0.9459}\n",
      "Skipping {'oofFile': 'oof_all_data_best_lgb_26.csv', 'predictionFile': 'prediction_all_data_best_lgb_26.csv', 'score': 0.9459}\n",
      "{'oofFile': 'oof_all_data_best_lgb_timefreq.csv', 'predictionFile': 'prediction_all_data_best_lgb_timefreq.csv', 'score': 0.9504}\n",
      "{'oofFile': 'oof_all_data_best_lgb.csv', 'predictionFile': 'prediction_all_data_best_lgb.csv', 'score': 0.9484}\n",
      "{'oofFile': 'oof_lgb_new_card_id_del_mean020_v3.csv', 'predictionFile': 'lgb_new_card_id_del_mean020_v3.csv', 'score': 0.947}\n",
      "Skipping {'oofFile': 'oof_lgb_new_card_id_del_mean020_v3.csv', 'predictionFile': 'lgb_new_card_id_del_mean020_v3.csv', 'score': 0.947}\n",
      "{'oofFile': 'oof_best_submit_09469.csv', 'predictionFile': 'submission_09469.csv', 'score': 0.9469}\n",
      "{'oofFile': 'stacked_oof.csv', 'predictionFile': 'stacked.csv', 'score': 0.939}\n",
      "{'oofFile': 'oof_result_pca.csv', 'predictionFile': 'lgb_pca.csv', 'score': 0.9498}\n",
      "{'oofFile': 'oof_catboost_last.csv', 'predictionFile': 'prediction_catboost_last.csv', 'score': 0.9511}\n",
      "{'oofFile': 'oof_dynamic_cat_final_6folds_20.csv', 'predictionFile': 'submission_dynamic_cat_final_6folds_20.csv', 'score': 0.9514}\n",
      "{'oofFile': 'oof_catboost-work.csv', 'predictionFile': 'prediction-catboost-work.csv', 'score': 0.9512}\n",
      "{'oofFile': 'oof_lightgbm-work-2.csv', 'predictionFile': 'prediction_lightgbm-work-2.csv', 'score': 0.9476}\n",
      "{'oofFile': 'oof_dynamic_cat_work_6folds_20.csv', 'predictionFile': 'submission_dynamic_cat_work_6folds_20.csv', 'score': 0.9512}\n",
      "{'oofFile': 'oof_xgboost-work-1.csv', 'predictionFile': 'prediction_xgboost-work-1.csv', 'score': 0.9464}\n",
      "{'oofFile': 'oof9522.csv', 'predictionFile': 'prediction9522.csv', 'score': 0.9464}\n"
     ]
    }
   ],
   "source": [
    "oofs=None\n",
    "predictions=None\n",
    "for iexp, experiment in enumerate(lb):\n",
    "    print(experiment)\n",
    "    oof = pd.read_csv(f'{main_folder}/{experiment[\"oofFile\"]}')\n",
    "    pred = pd.read_csv(f'{main_folder}/{experiment[\"predictionFile\"]}')\n",
    "    oof.set_index('TransactionID')\n",
    "    pred.set_index('TransactionID')\n",
    "    if len(oof.index) != 590540:\n",
    "        print (f\"Skipping {experiment}\")\n",
    "        continue\n",
    "    if oofs is None:\n",
    "       oofs = pd.DataFrame(index=oof.index)\n",
    "       predictions = pd.DataFrame(index=pred.index)\n",
    "#     print(oof)\n",
    "    oofs[f\"s{iexp}_{experiment['score']}\"] = oof['isFraud']\n",
    "    predictions[f\"s{iexp}_{experiment['score']}\"] = pred['isFraud']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:11:58.309647Z",
     "start_time": "2019-10-01T19:11:57.812631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1_0.9504 0.02265162141866039 0.021841851123379302\n",
      "s2_0.9484 0.02338705009684399 0.02252622090485728\n",
      "s4_0.9469 0.026085073017210213 0.02271503190580545\n",
      "s5_0.939 0.03244336042803625 0.0327943665788628\n",
      "s6_0.9498 0.02274679991623929 0.021454021766264816\n",
      "s7_0.9511 0.029589353552032082 0.027386008221827688\n",
      "s8_0.9514 0.03583654856328075 0.03695540336835534\n",
      "s9_0.9512 0.026460130397639534 0.02405884462802773\n",
      "s10_0.9476 0.022057325574929676 0.020249746314245712\n",
      "s11_0.9512 0.0356167768290346 0.03738436684876621\n",
      "s12_0.9464 0.02029689001643901 0.019229494973673256\n",
      "s13_0.9464 0.03563930771402968 0.034713472379135586\n"
     ]
    }
   ],
   "source": [
    "oofs.columns\n",
    "for col in oofs.columns:\n",
    "    print(col, oofs[col].mean(), predictions[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:15:02.056980Z",
     "start_time": "2019-10-01T19:15:01.797961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oofs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:15:05.872029Z",
     "start_time": "2019-10-01T19:15:05.624127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 12)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:09:35.545166Z",
     "start_time": "2019-10-01T19:09:35.273137Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.read_pickle(r'e:\\Kaggle\\data\\y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:09:36.709124Z",
     "start_time": "2019-10-01T19:09:36.433122Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:09:37.824167Z",
     "start_time": "2019-10-01T19:09:37.586133Z"
    }
   },
   "outputs": [],
   "source": [
    "from BayDS.lib.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:10:12.178714Z",
     "start_time": "2019-10-01T19:10:11.007701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1_0.9504 0.9337790683794884\n",
      "s2_0.9484 0.9310257339819353\n",
      "s4_0.9469 0.9331306395823962\n",
      "s5_0.939 0.9401843734290808\n",
      "s6_0.9498 0.9371002686597802\n",
      "s7_0.9511 0.9492520152989988\n",
      "s8_0.9514 0.9534682076165975\n",
      "s9_0.9512 0.9499705540891189\n",
      "s10_0.9476 0.9384990946131712\n",
      "s11_0.9512 0.9524674067457763\n",
      "s12_0.9464 0.9278023612986986\n",
      "s13_0.9464 0.9359445800665418\n"
     ]
    }
   ],
   "source": [
    "for col in oofs.columns:\n",
    "    print(col,fast_auc(y,oofs[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogRegression stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:15:26.251968Z",
     "start_time": "2019-10-01T19:15:11.424794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Tue Oct  1 22:15:12 2019\n",
      "Fold 0. auc: 0.9472.\n",
      "\n",
      "Fold 2 started at Tue Oct  1 22:15:15 2019\n",
      "Fold 1. auc: 0.9646.\n",
      "\n",
      "Fold 3 started at Tue Oct  1 22:15:18 2019\n",
      "Fold 2. auc: 0.9630.\n",
      "\n",
      "Fold 4 started at Tue Oct  1 22:15:20 2019\n",
      "Fold 3. auc: 0.9698.\n",
      "\n",
      "Fold 5 started at Tue Oct  1 22:15:23 2019\n",
      "Fold 4. auc: 0.9611.\n",
      "\n",
      "CV mean score: 0.9611, std: 0.0075.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "train_options = {\n",
    "    \"model_type\":'sklearn',\n",
    "    'model':model,\n",
    "    'folds': folds,\n",
    "    \"params\": {},\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'splits': n_fold,\n",
    "    'n_jobs': -1,\n",
    "    'groups': None\n",
    "}\n",
    "\n",
    "from sklearn import preprocessing\n",
    "standart_scaler = preprocessing.StandardScaler()\n",
    "X = pd.DataFrame(standart_scaler.fit_transform(oofs), index=oofs.index, columns=oofs.columns)\n",
    "result_dict_logreg = train_model_classification_vb(X=X, X_test=predictions, y=y, **train_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T19:16:24.551118Z",
     "start_time": "2019-10-01T19:16:22.330144Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')\n",
    "sub['isFraud'] = result_dict_logreg['prediction']\n",
    "sub.to_csv(f'{model_folder}/stacked_0110.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:34:50.687848Z",
     "start_time": "2019-09-06T19:34:50.524837Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## LightGBM Stacking (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:34:27.632832Z",
     "start_time": "2019-09-06T19:32:10.594834Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Sep  6 22:32:11 2019\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.109891\ttraining's auc: 0.906504\tvalid_1's binary_logloss: 0.0839437\tvalid_1's auc: 0.899767\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's binary_logloss: 0.139285\ttraining's auc: 0.906217\tvalid_1's binary_logloss: 0.102694\tvalid_1's auc: 0.899856\n",
      "Fold 2 started at Fri Sep  6 22:33:04 2019\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.101532\ttraining's auc: 0.903072\tvalid_1's binary_logloss: 0.1142\tvalid_1's auc: 0.898168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d60985114f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                                          \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                          \u001b[0maveraging\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'averaging'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                                          n_jobs=-1, groups=None)\n\u001b[0m",
      "\u001b[1;32mf:\\my\\Prog\\kaggle\\Baydin\\BayDS\\training\\third_party.py\u001b[0m in \u001b[0;36mtrain_model_classification\u001b[1;34m(X, X_test, y, params, folds, model_type, eval_metric, columns, plot_feature_importance, model, verbose, early_stopping_rounds, n_estimators, splits, averaging, n_jobs, groups)\u001b[0m\n\u001b[0;32m    146\u001b[0m                       \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                       \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lgb_metric_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                       verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0my_pred_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \"\"\"\n\u001b[1;32m-> 1958\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   2373\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2375\u001b[1;33m             \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(preds, dataset)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0margc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margc_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\my\\Prog\\kaggle\\Baydin\\BayDS\\training\\third_party.py\u001b[0m in \u001b[0;36meval_auc\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mFast\u001b[0m \u001b[0mauc\u001b[0m \u001b[0meval\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 1,\n",
    "    'min_child_weight': 10,\n",
    "    'lambda_l1':2,\n",
    "    'lambda_l2':3,\n",
    "    'min_data_in_leaf' :10,\n",
    "    'min_sum_hessian_in_leaf' : 0.0001,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'max_bin': 12,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_freq' : 100,\n",
    "    'min_gain_to_split': 0.1 }\n",
    "\n",
    "train_options = {\n",
    "    \"model_type\":'lgb',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'early_stopping_rounds': 500,\n",
    "    'n_estimators': 5000,\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "}\n",
    "\n",
    "\n",
    "result_dict_lgb = train_model_classification(X=oof, X_test=prediction, y=y, params=params, folds=folds,\n",
    "                                         model_type=train_options['model_type'], \n",
    "                                         eval_metric=train_options['eval_metric'],\n",
    "                                         plot_feature_importance=True,\n",
    "                                         verbose=500, early_stopping_rounds=train_options['early_stopping_rounds'],\n",
    "                                         n_estimators=train_options['n_estimators'], \n",
    "                                         averaging=train_options['averaging'],\n",
    "                                         n_jobs=-1, groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:35:20.278847Z",
     "start_time": "2019-09-06T19:35:20.115833Z"
    }
   },
   "source": [
    "## Keras Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:29:30.933674Z",
     "start_time": "2019-09-12T17:29:30.673661Z"
    }
   },
   "outputs": [],
   "source": [
    "def StackModel_maker():\n",
    "    k.clear_session()\n",
    "    \n",
    "    numerical_inputs = Input(shape=[oof.shape[1]], name = 'all')\n",
    "    numerical_logits = Dropout(.3)(numerical_inputs)\n",
    "  \n",
    "    x = numerical_logits\n",
    "\n",
    "    x = Dense(50, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = Dense(10, activation = 'relu')(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(x)    \n",
    "\n",
    "    model = Model(inputs= [numerical_inputs],outputs=out)\n",
    "    loss = \"binary_crossentropy\"\n",
    "    model.compile(optimizer=Adam(lr = 0.0003), loss = loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "params = {\n",
    "    'batch_size': 16384,\n",
    "    'epochs': 200,\n",
    "    'verbose': True,\n",
    "         }\n",
    "train_options = {\n",
    "    \"model_type\":'keras',\n",
    "    \"params\": params,\n",
    "    \"eval_metric\":'auc',\n",
    "    'averaging': 'usual',\n",
    "    'use_groups': False,\n",
    "    'fold_name': folds.__class__.__name__,\n",
    "    'n_splits': n_fold\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:29:32.787159Z",
     "start_time": "2019-09-12T17:29:32.521108Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/training_params.json', 'w') as f:\n",
    "    q = json.dumps(train_options,indent=2)\n",
    "    f.write(q)\n",
    "# StackModel_maker().save(f'{model_folder}/keras.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:29:33.947330Z",
     "start_time": "2019-09-12T17:29:33.616308Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':4}, log_device_placement=False) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:40:33.967765Z",
     "start_time": "2019-09-12T17:29:34.770166Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Thu Sep 12 20:29:35 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/200\n",
      "472432/472432 [==============================] - ETA: 15s - loss: 0.68 - ETA: 3s - loss: 0.6810 - ETA: 2s - loss: 0.679 - ETA: 1s - loss: 0.676 - ETA: 0s - loss: 0.673 - ETA: 0s - loss: 0.670 - ETA: 0s - loss: 0.669 - ETA: 0s - loss: 0.667 - ETA: 0s - loss: 0.665 - 1s 2us/step - loss: 0.6646 - val_loss: 0.6248\n",
      "Epoch 2/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.647 - ETA: 0s - loss: 0.645 - ETA: 0s - loss: 0.644 - ETA: 0s - loss: 0.641 - ETA: 0s - loss: 0.640 - ETA: 0s - loss: 0.637 - ETA: 0s - loss: 0.636 - ETA: 0s - loss: 0.635 - 1s 1us/step - loss: 0.6335 - val_loss: 0.6260\n",
      "Epoch 3/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.622 - ETA: 0s - loss: 0.619 - ETA: 0s - loss: 0.617 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.612 - ETA: 0s - loss: 0.611 - ETA: 0s - loss: 0.609 - 1s 1us/step - loss: 0.6083 - val_loss: 0.6325\n",
      "Epoch 4/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.596 - ETA: 0s - loss: 0.598 - ETA: 0s - loss: 0.595 - ETA: 0s - loss: 0.593 - ETA: 0s - loss: 0.592 - ETA: 0s - loss: 0.590 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.587 - ETA: 0s - loss: 0.586 - 1s 1us/step - loss: 0.5856 - val_loss: 0.6201\n",
      "Epoch 5/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.572 - ETA: 0s - loss: 0.571 - ETA: 0s - loss: 0.571 - ETA: 0s - loss: 0.567 - ETA: 0s - loss: 0.567 - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.564 - ETA: 0s - loss: 0.563 - 1s 1us/step - loss: 0.5621 - val_loss: 0.6073\n",
      "Epoch 6/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.551 - ETA: 0s - loss: 0.549 - ETA: 0s - loss: 0.547 - ETA: 0s - loss: 0.547 - ETA: 0s - loss: 0.545 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.543 - ETA: 0s - loss: 0.542 - ETA: 0s - loss: 0.541 - 1s 1us/step - loss: 0.5412 - val_loss: 0.5884\n",
      "Epoch 7/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.531 - ETA: 0s - loss: 0.531 - ETA: 0s - loss: 0.529 - ETA: 0s - loss: 0.527 - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.525 - ETA: 0s - loss: 0.525 - ETA: 0s - loss: 0.524 - ETA: 0s - loss: 0.523 - 1s 1us/step - loss: 0.5227 - val_loss: 0.5674\n",
      "Epoch 8/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.512 - ETA: 0s - loss: 0.510 - ETA: 0s - loss: 0.509 - ETA: 0s - loss: 0.508 - ETA: 0s - loss: 0.507 - ETA: 0s - loss: 0.506 - ETA: 0s - loss: 0.505 - 1s 1us/step - loss: 0.5045 - val_loss: 0.5472\n",
      "Epoch 9/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.497 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.492 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.487 - 1s 1us/step - loss: 0.4871 - val_loss: 0.5259\n",
      "Epoch 10/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.482 - ETA: 0s - loss: 0.477 - ETA: 0s - loss: 0.475 - ETA: 0s - loss: 0.473 - ETA: 0s - loss: 0.473 - ETA: 0s - loss: 0.471 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.469 - 1s 1us/step - loss: 0.4685 - val_loss: 0.5091\n",
      "Epoch 11/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.463 - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.460 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.457 - ETA: 0s - loss: 0.455 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.453 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.451 - 1s 1us/step - loss: 0.4512 - val_loss: 0.4932\n",
      "Epoch 12/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.440 - ETA: 0s - loss: 0.439 - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.434 - ETA: 0s - loss: 0.433 - 1s 1us/step - loss: 0.4331 - val_loss: 0.4769\n",
      "Epoch 13/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.419 - ETA: 0s - loss: 0.419 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.417 - ETA: 0s - loss: 0.416 - 1s 1us/step - loss: 0.4156 - val_loss: 0.4570\n",
      "Epoch 14/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.409 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.402 - ETA: 0s - loss: 0.402 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.399 - ETA: 0s - loss: 0.399 - ETA: 0s - loss: 0.398 - 1s 1us/step - loss: 0.3982 - val_loss: 0.4360\n",
      "Epoch 15/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.389 - ETA: 0s - loss: 0.388 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.386 - ETA: 0s - loss: 0.384 - ETA: 0s - loss: 0.384 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.381 - 1s 1us/step - loss: 0.3810 - val_loss: 0.4183\n",
      "Epoch 16/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.370 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.365 - 1s 1us/step - loss: 0.3648 - val_loss: 0.3991\n",
      "Epoch 17/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.354 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.349 - 1s 1us/step - loss: 0.3485 - val_loss: 0.3798\n",
      "Epoch 18/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.335 - ETA: 0s - loss: 0.334 - 1s 1us/step - loss: 0.3335 - val_loss: 0.3606\n",
      "Epoch 19/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.340 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.321 - ETA: 0s - loss: 0.320 - 1s 1us/step - loss: 0.3195 - val_loss: 0.3428\n",
      "Epoch 20/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.312 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.305 - 1s 1us/step - loss: 0.3047 - val_loss: 0.3249\n",
      "Epoch 21/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.293 - 1s 1us/step - loss: 0.2923 - val_loss: 0.3091\n",
      "Epoch 22/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.279 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.279 - ETA: 0s - loss: 0.279 - ETA: 0s - loss: 0.279 - 1s 1us/step - loss: 0.2792 - val_loss: 0.2949\n",
      "Epoch 23/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.267 - 1s 1us/step - loss: 0.2672 - val_loss: 0.2830\n",
      "Epoch 24/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.265 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.255 - 1s 1us/step - loss: 0.2555 - val_loss: 0.2697\n",
      "Epoch 25/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.244 - ETA: 0s - loss: 0.244 - 1s 1us/step - loss: 0.2445 - val_loss: 0.2572\n",
      "Epoch 26/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.233 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - 1s 1us/step - loss: 0.2358 - val_loss: 0.2461\n",
      "Epoch 27/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.231 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.225 - 1s 1us/step - loss: 0.2255 - val_loss: 0.2328\n",
      "Epoch 28/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.217 - 1s 1us/step - loss: 0.2165 - val_loss: 0.2236\n",
      "Epoch 29/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.208 - 1s 1us/step - loss: 0.2083 - val_loss: 0.2145\n",
      "Epoch 30/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.201 - 1s 1us/step - loss: 0.2010 - val_loss: 0.2048\n",
      "Epoch 31/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.193 - ETA: 0s - loss: 0.193 - 1s 1us/step - loss: 0.1931 - val_loss: 0.1946\n",
      "Epoch 32/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - 1s 1us/step - loss: 0.1869 - val_loss: 0.1889\n",
      "Epoch 33/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.193 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - 1s 1us/step - loss: 0.1802 - val_loss: 0.1812\n",
      "Epoch 34/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - 1s 1us/step - loss: 0.1744 - val_loss: 0.1740\n",
      "Epoch 35/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.171 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - 1s 1us/step - loss: 0.1693 - val_loss: 0.1676\n",
      "Epoch 36/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - 1s 1us/step - loss: 0.1640 - val_loss: 0.1623\n",
      "Epoch 37/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - 1s 1us/step - loss: 0.1593 - val_loss: 0.1550\n",
      "Epoch 38/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - 1s 1us/step - loss: 0.1550 - val_loss: 0.1485\n",
      "Epoch 39/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - 1s 1us/step - loss: 0.1501 - val_loss: 0.1448\n",
      "Epoch 40/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - 1s 1us/step - loss: 0.1466 - val_loss: 0.1407\n",
      "Epoch 41/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - 1s 1us/step - loss: 0.1430 - val_loss: 0.1353\n",
      "Epoch 42/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1392 - val_loss: 0.1317\n",
      "Epoch 43/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - 1s 1us/step - loss: 0.1369 - val_loss: 0.1278\n",
      "Epoch 44/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - 1s 1us/step - loss: 0.1337 - val_loss: 0.1255\n",
      "Epoch 45/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - 1s 1us/step - loss: 0.1302 - val_loss: 0.1212\n",
      "Epoch 46/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - 1s 1us/step - loss: 0.1284 - val_loss: 0.1173\n",
      "Epoch 47/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1256 - val_loss: 0.1148\n",
      "Epoch 48/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - 1s 1us/step - loss: 0.1242 - val_loss: 0.1114\n",
      "Epoch 49/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - 1s 1us/step - loss: 0.1220 - val_loss: 0.1097\n",
      "Epoch 50/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1198 - val_loss: 0.1063\n",
      "Epoch 51/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - 1s 1us/step - loss: 0.1186 - val_loss: 0.1045\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1160 - val_loss: 0.1013\n",
      "Epoch 53/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1150 - val_loss: 0.0982\n",
      "Epoch 54/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1134 - val_loss: 0.0969\n",
      "Epoch 55/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1118 - val_loss: 0.0945\n",
      "Epoch 56/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1111 - val_loss: 0.0939\n",
      "Epoch 57/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1096 - val_loss: 0.0915\n",
      "Epoch 58/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1076 - val_loss: 0.0899\n",
      "Epoch 59/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1062 - val_loss: 0.0885\n",
      "Epoch 60/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1053 - val_loss: 0.0883\n",
      "Epoch 61/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1048 - val_loss: 0.0865\n",
      "Epoch 62/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1037 - val_loss: 0.0849\n",
      "Epoch 63/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1027 - val_loss: 0.0838\n",
      "Epoch 64/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1026 - val_loss: 0.0828\n",
      "Epoch 65/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1014 - val_loss: 0.0811\n",
      "Epoch 66/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1006 - val_loss: 0.0797\n",
      "Epoch 67/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.1000 - val_loss: 0.0785\n",
      "Epoch 68/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0991 - val_loss: 0.0778\n",
      "Epoch 69/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.095 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0984 - val_loss: 0.0766\n",
      "Epoch 70/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0976 - val_loss: 0.0762\n",
      "Epoch 71/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0978 - val_loss: 0.0758\n",
      "Epoch 72/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0963 - val_loss: 0.0740\n",
      "Epoch 73/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0962 - val_loss: 0.0732\n",
      "Epoch 74/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0961 - val_loss: 0.0731\n",
      "Epoch 75/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0949 - val_loss: 0.0722\n",
      "Epoch 76/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0944 - val_loss: 0.0713\n",
      "Epoch 77/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0947 - val_loss: 0.0705\n",
      "Epoch 78/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0942 - val_loss: 0.0696\n",
      "Epoch 79/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0690\n",
      "Epoch 80/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0931 - val_loss: 0.0688\n",
      "Epoch 81/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0684\n",
      "Epoch 82/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0678\n",
      "Epoch 83/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0685\n",
      "Epoch 84/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0676\n",
      "Epoch 85/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0914 - val_loss: 0.0670\n",
      "Epoch 86/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0663\n",
      "Epoch 87/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0904 - val_loss: 0.0662\n",
      "Epoch 88/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.086 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0659\n",
      "Epoch 89/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0650\n",
      "Epoch 90/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0656\n",
      "Epoch 91/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0901 - val_loss: 0.0651\n",
      "Epoch 92/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0888 - val_loss: 0.0650\n",
      "Epoch 93/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0649\n",
      "Epoch 94/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0895 - val_loss: 0.0646\n",
      "Epoch 95/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0637\n",
      "Epoch 96/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0635\n",
      "Epoch 97/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0890 - val_loss: 0.0635\n",
      "Epoch 98/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0890 - val_loss: 0.0625\n",
      "Epoch 99/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0630\n",
      "Epoch 100/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0626\n",
      "Epoch 101/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0885 - val_loss: 0.0622\n",
      "Epoch 102/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0882 - val_loss: 0.0626\n",
      "Epoch 103/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0883 - val_loss: 0.0622\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0882 - val_loss: 0.0620\n",
      "Epoch 105/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0620\n",
      "Epoch 106/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0623\n",
      "Epoch 107/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0616\n",
      "Epoch 108/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0618\n",
      "Epoch 109/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0875 - val_loss: 0.0618\n",
      "Epoch 110/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0614\n",
      "Epoch 111/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0877 - val_loss: 0.0614\n",
      "Epoch 112/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0614\n",
      "Epoch 113/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0868 - val_loss: 0.0610\n",
      "Epoch 114/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0873 - val_loss: 0.0615\n",
      "Epoch 115/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0874 - val_loss: 0.0618\n",
      "Epoch 116/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0869 - val_loss: 0.0605\n",
      "Epoch 117/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0867 - val_loss: 0.0609\n",
      "Epoch 118/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0864 - val_loss: 0.0607\n",
      "Epoch 119/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0867 - val_loss: 0.0609\n",
      "Epoch 120/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0862 - val_loss: 0.0609\n",
      "Epoch 121/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0607\n",
      "Epoch 122/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0606\n",
      "Epoch 123/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0607\n",
      "Epoch 124/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0858 - val_loss: 0.0610\n",
      "Epoch 125/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0864 - val_loss: 0.0608\n",
      "Epoch 126/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0606\n",
      "Epoch 127/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0604\n",
      "Epoch 128/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0857 - val_loss: 0.0603\n",
      "Epoch 129/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0604\n",
      "Epoch 130/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0607\n",
      "Epoch 131/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0862 - val_loss: 0.0606\n",
      "Epoch 132/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0605\n",
      "Epoch 133/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0858 - val_loss: 0.0602\n",
      "Epoch 134/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0603\n",
      "Epoch 135/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0852 - val_loss: 0.0605\n",
      "Epoch 136/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0853 - val_loss: 0.0604\n",
      "Epoch 137/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0606\n",
      "Epoch 138/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0607\n",
      "Epoch 139/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0606\n",
      "Epoch 140/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0851 - val_loss: 0.0605\n",
      "Epoch 141/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0605\n",
      "Epoch 142/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0850 - val_loss: 0.0604\n",
      "Epoch 143/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0601\n",
      "Epoch 144/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0600\n",
      "Epoch 145/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0600\n",
      "Epoch 146/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0597\n",
      "Epoch 147/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0595\n",
      "Epoch 148/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0597\n",
      "Epoch 149/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0595\n",
      "Epoch 150/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0596\n",
      "Epoch 151/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0598\n",
      "Epoch 152/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0597\n",
      "Epoch 153/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0594\n",
      "Epoch 154/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0594\n",
      "Epoch 155/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0594\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0594\n",
      "Epoch 157/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0594\n",
      "Epoch 158/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0593\n",
      "Epoch 159/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0592\n",
      "Epoch 160/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0592\n",
      "Epoch 161/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0591\n",
      "Epoch 162/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0591\n",
      "Epoch 163/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0593\n",
      "Epoch 164/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0592\n",
      "Epoch 165/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0591\n",
      "Epoch 166/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0591\n",
      "Epoch 167/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0591\n",
      "Epoch 168/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0589\n",
      "Epoch 169/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0590\n",
      "Epoch 170/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0591\n",
      "Epoch 171/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0590\n",
      "Epoch 172/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0586\n",
      "Epoch 173/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.086 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0593\n",
      "Epoch 174/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0592\n",
      "Epoch 175/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0588\n",
      "Epoch 176/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0591\n",
      "Epoch 177/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0592\n",
      "Epoch 178/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0827 - val_loss: 0.0591\n",
      "Epoch 179/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0586\n",
      "Epoch 180/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0590\n",
      "Epoch 181/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0594\n",
      "Epoch 182/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0586\n",
      "Epoch 183/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0587\n",
      "Epoch 184/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0587\n",
      "Epoch 185/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0588\n",
      "Epoch 186/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0589\n",
      "Epoch 187/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0589\n",
      "Epoch 188/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0586\n",
      "Epoch 189/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0588\n",
      "Epoch 190/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0588\n",
      "Epoch 191/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0585\n",
      "Epoch 192/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0587\n",
      "Epoch 193/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0586\n",
      "Epoch 194/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0585\n",
      "Epoch 195/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0585\n",
      "Epoch 196/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0587\n",
      "Epoch 197/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0590\n",
      "Epoch 198/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0589\n",
      "Epoch 199/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0585\n",
      "Epoch 200/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0585\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 0. auc: 0.9389.\n",
      "Fold 2 started at Thu Sep 12 20:31:45 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/200\n",
      "472432/472432 [==============================] - ETA: 15s - loss: 0.70 - ETA: 3s - loss: 0.7075 - ETA: 2s - loss: 0.704 - ETA: 1s - loss: 0.700 - ETA: 0s - loss: 0.696 - ETA: 0s - loss: 0.693 - ETA: 0s - loss: 0.689 - ETA: 0s - loss: 0.685 - ETA: 0s - loss: 0.682 - 1s 2us/step - loss: 0.6803 - val_loss: 0.6257\n",
      "Epoch 2/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.653 - ETA: 0s - loss: 0.649 - ETA: 0s - loss: 0.645 - ETA: 0s - loss: 0.642 - ETA: 0s - loss: 0.639 - ETA: 0s - loss: 0.636 - ETA: 0s - loss: 0.634 - ETA: 0s - loss: 0.630 - ETA: 0s - loss: 0.628 - 1s 1us/step - loss: 0.6268 - val_loss: 0.5926\n",
      "Epoch 3/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.601 - ETA: 0s - loss: 0.600 - ETA: 0s - loss: 0.599 - ETA: 0s - loss: 0.597 - ETA: 0s - loss: 0.596 - ETA: 0s - loss: 0.593 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.589 - 1s 1us/step - loss: 0.5888 - val_loss: 0.5618\n",
      "Epoch 4/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.572 - ETA: 0s - loss: 0.572 - ETA: 0s - loss: 0.569 - ETA: 0s - loss: 0.569 - ETA: 0s - loss: 0.567 - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.560 - 1s 1us/step - loss: 0.5582 - val_loss: 0.5328\n",
      "Epoch 5/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.538 - ETA: 0s - loss: 0.536 - ETA: 0s - loss: 0.535 - ETA: 0s - loss: 0.534 - ETA: 0s - loss: 0.533 - 1s 1us/step - loss: 0.5328 - val_loss: 0.5069\n",
      "Epoch 6/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.521 - ETA: 0s - loss: 0.519 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.514 - ETA: 0s - loss: 0.513 - ETA: 0s - loss: 0.512 - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.509 - ETA: 0s - loss: 0.508 - 1s 1us/step - loss: 0.5087 - val_loss: 0.4819\n",
      "Epoch 7/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.496 - ETA: 0s - loss: 0.494 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.492 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.487 - 1s 1us/step - loss: 0.4856 - val_loss: 0.4577\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.469 - ETA: 0s - loss: 0.466 - ETA: 0s - loss: 0.467 - ETA: 0s - loss: 0.467 - ETA: 0s - loss: 0.465 - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.463 - ETA: 0s - loss: 0.462 - 1s 1us/step - loss: 0.4623 - val_loss: 0.4341\n",
      "Epoch 9/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.453 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.448 - ETA: 0s - loss: 0.446 - ETA: 0s - loss: 0.444 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.442 - ETA: 0s - loss: 0.440 - 1s 1us/step - loss: 0.4404 - val_loss: 0.4129\n",
      "Epoch 10/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.420 - ETA: 0s - loss: 0.419 - 1s 1us/step - loss: 0.4192 - val_loss: 0.3928\n",
      "Epoch 11/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.398 - 1s 1us/step - loss: 0.3987 - val_loss: 0.3727\n",
      "Epoch 12/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.393 - ETA: 0s - loss: 0.391 - ETA: 0s - loss: 0.389 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.380 - 1s 1us/step - loss: 0.3797 - val_loss: 0.3542\n",
      "Epoch 13/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.373 - ETA: 0s - loss: 0.373 - ETA: 0s - loss: 0.369 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.362 - 1s 1us/step - loss: 0.3623 - val_loss: 0.3362\n",
      "Epoch 14/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.353 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.348 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.346 - 1s 1us/step - loss: 0.3458 - val_loss: 0.3194\n",
      "Epoch 15/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.329 - 1s 1us/step - loss: 0.3291 - val_loss: 0.3036\n",
      "Epoch 16/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.320 - ETA: 0s - loss: 0.319 - ETA: 0s - loss: 0.318 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.314 - 1s 1us/step - loss: 0.3139 - val_loss: 0.2885\n",
      "Epoch 17/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.306 - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.302 - ETA: 0s - loss: 0.302 - ETA: 0s - loss: 0.301 - 1s 1us/step - loss: 0.3007 - val_loss: 0.2745\n",
      "Epoch 18/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.289 - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.286 - ETA: 0s - loss: 0.285 - 1s 1us/step - loss: 0.2852 - val_loss: 0.2616\n",
      "Epoch 19/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.275 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.275 - ETA: 0s - loss: 0.274 - 1s 1us/step - loss: 0.2734 - val_loss: 0.2494\n",
      "Epoch 20/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.266 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.261 - 1s 1us/step - loss: 0.2613 - val_loss: 0.2381\n",
      "Epoch 21/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.255 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.255 - ETA: 0s - loss: 0.254 - ETA: 0s - loss: 0.253 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.250 - 1s 1us/step - loss: 0.2504 - val_loss: 0.2275\n",
      "Epoch 22/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.242 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - 1s 1us/step - loss: 0.2395 - val_loss: 0.2179\n",
      "Epoch 23/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.229 - 1s 1us/step - loss: 0.2296 - val_loss: 0.2089\n",
      "Epoch 24/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.222 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.221 - 1s 1us/step - loss: 0.2207 - val_loss: 0.2004\n",
      "Epoch 25/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.223 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.215 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.214 - ETA: 0s - loss: 0.213 - 1s 1us/step - loss: 0.2129 - val_loss: 0.1925\n",
      "Epoch 26/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.206 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.205 - ETA: 0s - loss: 0.205 - 1s 1us/step - loss: 0.2045 - val_loss: 0.1853\n",
      "Epoch 27/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - 1s 1us/step - loss: 0.1965 - val_loss: 0.1786\n",
      "Epoch 28/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.193 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.191 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.190 - 1s 1us/step - loss: 0.1901 - val_loss: 0.1722\n",
      "Epoch 29/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.185 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.183 - 1s 1us/step - loss: 0.1835 - val_loss: 0.1666\n",
      "Epoch 30/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.178 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.178 - 1s 1us/step - loss: 0.1776 - val_loss: 0.1613\n",
      "Epoch 31/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.172 - 1s 1us/step - loss: 0.1717 - val_loss: 0.1564\n",
      "Epoch 32/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.172 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.166 - 1s 1us/step - loss: 0.1668 - val_loss: 0.1519\n",
      "Epoch 33/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.161 - 1s 1us/step - loss: 0.1615 - val_loss: 0.1477\n",
      "Epoch 34/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.156 - 1s 1us/step - loss: 0.1565 - val_loss: 0.1439\n",
      "Epoch 35/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - 1s 1us/step - loss: 0.1531 - val_loss: 0.1403\n",
      "Epoch 36/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - 1s 1us/step - loss: 0.1496 - val_loss: 0.1370\n",
      "Epoch 37/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - 1s 1us/step - loss: 0.1465 - val_loss: 0.1338\n",
      "Epoch 38/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - 1s 1us/step - loss: 0.1428 - val_loss: 0.1310\n",
      "Epoch 39/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.140 - 1s 1us/step - loss: 0.1406 - val_loss: 0.1284\n",
      "Epoch 40/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.136 - 1s 1us/step - loss: 0.1363 - val_loss: 0.1261\n",
      "Epoch 41/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.133 - 1s 1us/step - loss: 0.1340 - val_loss: 0.1240\n",
      "Epoch 42/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - 1s 1us/step - loss: 0.1319 - val_loss: 0.1219\n",
      "Epoch 43/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1291 - val_loss: 0.1199\n",
      "Epoch 44/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - 1s 1us/step - loss: 0.1267 - val_loss: 0.1181\n",
      "Epoch 45/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1255 - val_loss: 0.1164\n",
      "Epoch 46/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - 1s 1us/step - loss: 0.1243 - val_loss: 0.1149\n",
      "Epoch 47/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - 1s 1us/step - loss: 0.1209 - val_loss: 0.1134\n",
      "Epoch 48/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - 1s 1us/step - loss: 0.1198 - val_loss: 0.1119\n",
      "Epoch 49/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1187 - val_loss: 0.1108\n",
      "Epoch 50/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - 1s 1us/step - loss: 0.1180 - val_loss: 0.1100\n",
      "Epoch 51/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1166 - val_loss: 0.1086\n",
      "Epoch 52/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1152 - val_loss: 0.1077\n",
      "Epoch 53/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1138 - val_loss: 0.1068\n",
      "Epoch 54/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1127 - val_loss: 0.1059\n",
      "Epoch 55/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1119 - val_loss: 0.1052\n",
      "Epoch 56/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1110 - val_loss: 0.1047\n",
      "Epoch 57/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1098 - val_loss: 0.1045\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1093 - val_loss: 0.1039\n",
      "Epoch 59/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1086 - val_loss: 0.1033\n",
      "Epoch 60/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1080 - val_loss: 0.1025\n",
      "Epoch 61/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1068 - val_loss: 0.1018\n",
      "Epoch 62/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1065 - val_loss: 0.1012\n",
      "Epoch 63/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1058 - val_loss: 0.1007\n",
      "Epoch 64/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1051 - val_loss: 0.1005\n",
      "Epoch 65/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1042 - val_loss: 0.1001\n",
      "Epoch 66/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1037 - val_loss: 0.0997\n",
      "Epoch 67/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1038 - val_loss: 0.0988\n",
      "Epoch 68/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1025 - val_loss: 0.0986\n",
      "Epoch 69/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1019 - val_loss: 0.0980\n",
      "Epoch 70/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1025 - val_loss: 0.0968\n",
      "Epoch 71/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1011 - val_loss: 0.0961\n",
      "Epoch 72/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1011 - val_loss: 0.0965\n",
      "Epoch 73/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0997 - val_loss: 0.0967\n",
      "Epoch 74/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0995 - val_loss: 0.0963\n",
      "Epoch 75/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.1002 - val_loss: 0.0959\n",
      "Epoch 76/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0988 - val_loss: 0.0959\n",
      "Epoch 77/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0991 - val_loss: 0.0955\n",
      "Epoch 78/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0946\n",
      "Epoch 79/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0940\n",
      "Epoch 80/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0979 - val_loss: 0.0937\n",
      "Epoch 81/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0975 - val_loss: 0.0932\n",
      "Epoch 82/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0975 - val_loss: 0.0932\n",
      "Epoch 83/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0963 - val_loss: 0.0926\n",
      "Epoch 84/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0972 - val_loss: 0.0926\n",
      "Epoch 85/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0928\n",
      "Epoch 86/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0930\n",
      "Epoch 87/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0962 - val_loss: 0.0921\n",
      "Epoch 88/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0956 - val_loss: 0.0920\n",
      "Epoch 89/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0959 - val_loss: 0.0919\n",
      "Epoch 90/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0961 - val_loss: 0.0920\n",
      "Epoch 91/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.102 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0957 - val_loss: 0.0923\n",
      "Epoch 92/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 2us/step - loss: 0.0957 - val_loss: 0.0928\n",
      "Epoch 93/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0950 - val_loss: 0.0929\n",
      "Epoch 94/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0960 - val_loss: 0.0927\n",
      "Epoch 95/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0955 - val_loss: 0.0927\n",
      "Epoch 96/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0958 - val_loss: 0.0924\n",
      "Epoch 97/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0950 - val_loss: 0.0927\n",
      "Epoch 98/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - 1s 2us/step - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 99/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.101 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 100/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0949 - val_loss: 0.0923\n",
      "Epoch 101/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 102/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.100 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0948 - val_loss: 0.0937\n",
      "Epoch 103/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0942 - val_loss: 0.0937\n",
      "Epoch 104/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0945 - val_loss: 0.0936\n",
      "Epoch 105/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0937 - val_loss: 0.0931\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 1s - loss: 0.101 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0946 - val_loss: 0.0935\n",
      "Epoch 107/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0944 - val_loss: 0.0925\n",
      "Epoch 108/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0936 - val_loss: 0.0927\n",
      "Epoch 109/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0931 - val_loss: 0.0929\n",
      "Epoch 110/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0941 - val_loss: 0.0950\n",
      "Epoch 111/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.102 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0948\n",
      "Epoch 112/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0936 - val_loss: 0.0943\n",
      "Epoch 113/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0940 - val_loss: 0.0948\n",
      "Epoch 114/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0940 - val_loss: 0.0945\n",
      "Epoch 115/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0934 - val_loss: 0.0945\n",
      "Epoch 116/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 2us/step - loss: 0.0941 - val_loss: 0.0948\n",
      "Epoch 117/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0936 - val_loss: 0.0945\n",
      "Epoch 118/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0935 - val_loss: 0.0928\n",
      "Epoch 119/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0932 - val_loss: 0.0931\n",
      "Epoch 120/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.100 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0937 - val_loss: 0.0932\n",
      "Epoch 121/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0937 - val_loss: 0.0934\n",
      "Epoch 122/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0940 - val_loss: 0.0942\n",
      "Epoch 123/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0936 - val_loss: 0.0932\n",
      "Epoch 124/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 2us/step - loss: 0.0935 - val_loss: 0.0944\n",
      "Epoch 125/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.085 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0936 - val_loss: 0.0948\n",
      "Epoch 126/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0953\n",
      "Epoch 127/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0936 - val_loss: 0.0954\n",
      "Epoch 128/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.097 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0932 - val_loss: 0.0947\n",
      "Epoch 129/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0930 - val_loss: 0.0936\n",
      "Epoch 130/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0937\n",
      "Epoch 131/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.099 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0932 - val_loss: 0.0946\n",
      "Epoch 132/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0955\n",
      "Epoch 133/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0922 - val_loss: 0.0945\n",
      "Epoch 134/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0940\n",
      "Epoch 135/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0927 - val_loss: 0.0945\n",
      "Epoch 136/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0927 - val_loss: 0.0938\n",
      "Epoch 137/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0936\n",
      "Epoch 138/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0934\n",
      "Epoch 139/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0929 - val_loss: 0.0934\n",
      "Epoch 140/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.102 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0942\n",
      "Epoch 141/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0923 - val_loss: 0.0942\n",
      "Epoch 142/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0927 - val_loss: 0.0930\n",
      "Epoch 143/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.085 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0931 - val_loss: 0.0938\n",
      "Epoch 144/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0936\n",
      "Epoch 145/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0933\n",
      "Epoch 146/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0927 - val_loss: 0.0941\n",
      "Epoch 147/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0927 - val_loss: 0.0942\n",
      "Epoch 148/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0924 - val_loss: 0.0944\n",
      "Epoch 149/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0940\n",
      "Epoch 150/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0943\n",
      "Epoch 151/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0923 - val_loss: 0.0949\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0920 - val_loss: 0.0939\n",
      "Epoch 153/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.080 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0938\n",
      "Epoch 154/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.094 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 2us/step - loss: 0.0914 - val_loss: 0.0934\n",
      "Epoch 155/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0924 - val_loss: 0.0934\n",
      "Epoch 156/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0941\n",
      "Epoch 157/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0946\n",
      "Epoch 158/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0922 - val_loss: 0.0947\n",
      "Epoch 159/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0948\n",
      "Epoch 160/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0949\n",
      "Epoch 161/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0947\n",
      "Epoch 162/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0946\n",
      "Epoch 163/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0921 - val_loss: 0.0948\n",
      "Epoch 164/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 2us/step - loss: 0.0921 - val_loss: 0.0946\n",
      "Epoch 165/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0942\n",
      "Epoch 166/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0943\n",
      "Epoch 167/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.101 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0951\n",
      "Epoch 168/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0954\n",
      "Epoch 169/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0941\n",
      "Epoch 170/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0947\n",
      "Epoch 171/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0916 - val_loss: 0.0935\n",
      "Epoch 172/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0939\n",
      "Epoch 173/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0914 - val_loss: 0.0944\n",
      "Epoch 174/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0944\n",
      "Epoch 175/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0941\n",
      "Epoch 176/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0945\n",
      "Epoch 177/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0928\n",
      "Epoch 178/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0928\n",
      "Epoch 179/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0922 - val_loss: 0.0936\n",
      "Epoch 180/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0903 - val_loss: 0.0944\n",
      "Epoch 181/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0922 - val_loss: 0.0945\n",
      "Epoch 182/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0911 - val_loss: 0.0948\n",
      "Epoch 183/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0956\n",
      "Epoch 184/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0921 - val_loss: 0.0963\n",
      "Epoch 185/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0954\n",
      "Epoch 186/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0960\n",
      "Epoch 187/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0949\n",
      "Epoch 188/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0908 - val_loss: 0.0945\n",
      "Epoch 189/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0948\n",
      "Epoch 190/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0937\n",
      "Epoch 191/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0933\n",
      "Epoch 192/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0942\n",
      "Epoch 193/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0906 - val_loss: 0.0959\n",
      "Epoch 194/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0963\n",
      "Epoch 195/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0917 - val_loss: 0.0969\n",
      "Epoch 196/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0915 - val_loss: 0.0965\n",
      "Epoch 197/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0916 - val_loss: 0.0969\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0910 - val_loss: 0.0969\n",
      "Epoch 199/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0911 - val_loss: 0.0967\n",
      "Epoch 200/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0951\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 1. auc: 0.9541.\n",
      "Fold 3 started at Thu Sep 12 20:34:11 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/200\n",
      "472432/472432 [==============================] - ETA: 15s - loss: 0.73 - ETA: 2s - loss: 0.7279 - ETA: 1s - loss: 0.723 - ETA: 0s - loss: 0.719 - ETA: 0s - loss: 0.716 - ETA: 0s - loss: 0.712 - ETA: 0s - loss: 0.709 - ETA: 0s - loss: 0.707 - 1s 2us/step - loss: 0.7065 - val_loss: 0.6420\n",
      "Epoch 2/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.683 - ETA: 0s - loss: 0.681 - ETA: 0s - loss: 0.679 - ETA: 0s - loss: 0.677 - ETA: 0s - loss: 0.675 - ETA: 0s - loss: 0.673 - ETA: 0s - loss: 0.671 - ETA: 0s - loss: 0.669 - 1s 1us/step - loss: 0.6687 - val_loss: 0.6040\n",
      "Epoch 3/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.658 - ETA: 0s - loss: 0.652 - ETA: 0s - loss: 0.651 - ETA: 0s - loss: 0.650 - ETA: 0s - loss: 0.649 - ETA: 0s - loss: 0.648 - ETA: 0s - loss: 0.647 - ETA: 0s - loss: 0.645 - ETA: 0s - loss: 0.644 - ETA: 0s - loss: 0.643 - 1s 1us/step - loss: 0.6435 - val_loss: 0.5920\n",
      "Epoch 4/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.630 - ETA: 0s - loss: 0.631 - ETA: 0s - loss: 0.630 - ETA: 0s - loss: 0.629 - ETA: 0s - loss: 0.628 - ETA: 0s - loss: 0.626 - ETA: 0s - loss: 0.625 - ETA: 0s - loss: 0.624 - ETA: 0s - loss: 0.623 - ETA: 0s - loss: 0.622 - 1s 1us/step - loss: 0.6223 - val_loss: 0.5924\n",
      "Epoch 5/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.611 - ETA: 0s - loss: 0.609 - ETA: 0s - loss: 0.609 - ETA: 0s - loss: 0.608 - ETA: 0s - loss: 0.607 - ETA: 0s - loss: 0.606 - ETA: 0s - loss: 0.605 - ETA: 0s - loss: 0.604 - ETA: 0s - loss: 0.603 - ETA: 0s - loss: 0.601 - 1s 1us/step - loss: 0.6015 - val_loss: 0.5994\n",
      "Epoch 6/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.597 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.588 - ETA: 0s - loss: 0.587 - ETA: 0s - loss: 0.585 - ETA: 0s - loss: 0.585 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.582 - ETA: 0s - loss: 0.581 - 1s 1us/step - loss: 0.5814 - val_loss: 0.6041\n",
      "Epoch 7/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.571 - ETA: 0s - loss: 0.569 - ETA: 0s - loss: 0.567 - ETA: 0s - loss: 0.566 - ETA: 0s - loss: 0.564 - ETA: 0s - loss: 0.563 - ETA: 0s - loss: 0.563 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.561 - 1s 1us/step - loss: 0.5603 - val_loss: 0.5966\n",
      "Epoch 8/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.550 - ETA: 0s - loss: 0.549 - ETA: 0s - loss: 0.547 - ETA: 0s - loss: 0.546 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.543 - ETA: 0s - loss: 0.542 - ETA: 0s - loss: 0.541 - 1s 1us/step - loss: 0.5403 - val_loss: 0.5769\n",
      "Epoch 9/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.531 - ETA: 0s - loss: 0.528 - ETA: 0s - loss: 0.528 - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.525 - ETA: 0s - loss: 0.525 - ETA: 0s - loss: 0.524 - ETA: 0s - loss: 0.523 - ETA: 0s - loss: 0.521 - 1s 1us/step - loss: 0.5207 - val_loss: 0.5495\n",
      "Epoch 10/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.509 - ETA: 0s - loss: 0.507 - ETA: 0s - loss: 0.507 - ETA: 0s - loss: 0.506 - ETA: 0s - loss: 0.505 - ETA: 0s - loss: 0.505 - ETA: 0s - loss: 0.504 - ETA: 0s - loss: 0.503 - ETA: 0s - loss: 0.502 - ETA: 0s - loss: 0.501 - 1s 1us/step - loss: 0.5015 - val_loss: 0.5218\n",
      "Epoch 11/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.494 - ETA: 0s - loss: 0.492 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.488 - ETA: 0s - loss: 0.488 - ETA: 0s - loss: 0.486 - ETA: 0s - loss: 0.485 - ETA: 0s - loss: 0.484 - 1s 1us/step - loss: 0.4832 - val_loss: 0.4918\n",
      "Epoch 12/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.473 - ETA: 0s - loss: 0.472 - ETA: 0s - loss: 0.470 - ETA: 0s - loss: 0.469 - ETA: 0s - loss: 0.468 - ETA: 0s - loss: 0.468 - ETA: 0s - loss: 0.466 - ETA: 0s - loss: 0.465 - 1s 1us/step - loss: 0.4643 - val_loss: 0.4669\n",
      "Epoch 13/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.455 - ETA: 0s - loss: 0.455 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.452 - ETA: 0s - loss: 0.451 - ETA: 0s - loss: 0.450 - ETA: 0s - loss: 0.449 - ETA: 0s - loss: 0.448 - ETA: 0s - loss: 0.447 - 1s 1us/step - loss: 0.4470 - val_loss: 0.4453\n",
      "Epoch 14/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.433 - ETA: 0s - loss: 0.433 - ETA: 0s - loss: 0.431 - ETA: 0s - loss: 0.431 - ETA: 0s - loss: 0.429 - 1s 1us/step - loss: 0.4292 - val_loss: 0.4212\n",
      "Epoch 15/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.412 - ETA: 0s - loss: 0.417 - ETA: 0s - loss: 0.416 - ETA: 0s - loss: 0.415 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.413 - ETA: 0s - loss: 0.412 - ETA: 0s - loss: 0.411 - 1s 1us/step - loss: 0.4111 - val_loss: 0.4012\n",
      "Epoch 16/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.399 - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.397 - ETA: 0s - loss: 0.396 - 1s 1us/step - loss: 0.3950 - val_loss: 0.3791\n",
      "Epoch 17/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.382 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.379 - ETA: 0s - loss: 0.378 - 1s 1us/step - loss: 0.3786 - val_loss: 0.3601\n",
      "Epoch 18/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.369 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.361 - 1s 1us/step - loss: 0.3612 - val_loss: 0.3427\n",
      "Epoch 19/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.349 - ETA: 0s - loss: 0.348 - ETA: 0s - loss: 0.346 - 1s 1us/step - loss: 0.3466 - val_loss: 0.3259\n",
      "Epoch 20/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.335 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.332 - 1s 1us/step - loss: 0.3320 - val_loss: 0.3090\n",
      "Epoch 21/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.318 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.321 - ETA: 0s - loss: 0.320 - ETA: 0s - loss: 0.319 - ETA: 0s - loss: 0.319 - ETA: 0s - loss: 0.317 - 1s 1us/step - loss: 0.3174 - val_loss: 0.2949\n",
      "Epoch 22/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.306 - ETA: 0s - loss: 0.305 - ETA: 0s - loss: 0.305 - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.303 - 1s 1us/step - loss: 0.3032 - val_loss: 0.2795\n",
      "Epoch 23/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.291 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.292 - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.291 - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.289 - ETA: 0s - loss: 0.289 - 1s 1us/step - loss: 0.2892 - val_loss: 0.2692\n",
      "Epoch 24/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.279 - ETA: 0s - loss: 0.278 - ETA: 0s - loss: 0.277 - 1s 1us/step - loss: 0.2777 - val_loss: 0.2550\n",
      "Epoch 25/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.267 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.267 - ETA: 0s - loss: 0.267 - ETA: 0s - loss: 0.265 - 1s 1us/step - loss: 0.2658 - val_loss: 0.2441\n",
      "Epoch 26/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.255 - ETA: 0s - loss: 0.254 - 1s 1us/step - loss: 0.2542 - val_loss: 0.2333\n",
      "Epoch 27/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.244 - 1s 1us/step - loss: 0.2435 - val_loss: 0.2216\n",
      "Epoch 28/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.243 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.235 - ETA: 0s - loss: 0.234 - ETA: 0s - loss: 0.233 - 1s 1us/step - loss: 0.2334 - val_loss: 0.2123\n",
      "Epoch 29/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.225 - ETA: 0s - loss: 0.225 - ETA: 0s - loss: 0.225 - ETA: 0s - loss: 0.224 - 1s 1us/step - loss: 0.2248 - val_loss: 0.2023\n",
      "Epoch 30/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.216 - ETA: 0s - loss: 0.216 - 1s 1us/step - loss: 0.2162 - val_loss: 0.1953\n",
      "Epoch 31/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.208 - ETA: 0s - loss: 0.208 - 1s 1us/step - loss: 0.2077 - val_loss: 0.1872\n",
      "Epoch 32/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.198 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.200 - ETA: 0s - loss: 0.199 - 1s 1us/step - loss: 0.1999 - val_loss: 0.1803\n",
      "Epoch 33/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.193 - ETA: 0s - loss: 0.193 - 1s 1us/step - loss: 0.1931 - val_loss: 0.1740\n",
      "Epoch 34/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.189 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - 1s 1us/step - loss: 0.1861 - val_loss: 0.1668\n",
      "Epoch 35/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - 1s 1us/step - loss: 0.1800 - val_loss: 0.1604\n",
      "Epoch 36/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - 1s 1us/step - loss: 0.1741 - val_loss: 0.1544\n",
      "Epoch 37/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - 1s 1us/step - loss: 0.1682 - val_loss: 0.1487\n",
      "Epoch 38/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.163 - 1s 1us/step - loss: 0.1637 - val_loss: 0.1455\n",
      "Epoch 39/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.160 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - 1s 1us/step - loss: 0.1585 - val_loss: 0.1399\n",
      "Epoch 40/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - 1s 1us/step - loss: 0.1540 - val_loss: 0.1367\n",
      "Epoch 41/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - 1s 1us/step - loss: 0.1494 - val_loss: 0.1330\n",
      "Epoch 42/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.147 - 1s 1us/step - loss: 0.1465 - val_loss: 0.1293\n",
      "Epoch 43/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.144 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - 1s 1us/step - loss: 0.1420 - val_loss: 0.1269\n",
      "Epoch 44/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.140 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1388 - val_loss: 0.1240\n",
      "Epoch 45/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.135 - 1s 1us/step - loss: 0.1354 - val_loss: 0.1200\n",
      "Epoch 46/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - 1s 1us/step - loss: 0.1331 - val_loss: 0.1183\n",
      "Epoch 47/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1294 - val_loss: 0.1153\n",
      "Epoch 48/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - 1s 1us/step - loss: 0.1283 - val_loss: 0.1130\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1250 - val_loss: 0.1106\n",
      "Epoch 50/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - 1s 1us/step - loss: 0.1232 - val_loss: 0.1084\n",
      "Epoch 51/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - 1s 1us/step - loss: 0.1204 - val_loss: 0.1075\n",
      "Epoch 52/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1177 - val_loss: 0.1055\n",
      "Epoch 53/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1169 - val_loss: 0.1040\n",
      "Epoch 54/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1154 - val_loss: 0.1015\n",
      "Epoch 55/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1131 - val_loss: 0.1009\n",
      "Epoch 56/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1119 - val_loss: 0.0992\n",
      "Epoch 57/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1107 - val_loss: 0.0989\n",
      "Epoch 58/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1084 - val_loss: 0.0971\n",
      "Epoch 59/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1077 - val_loss: 0.0963\n",
      "Epoch 60/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1072 - val_loss: 0.0955\n",
      "Epoch 61/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1060 - val_loss: 0.0934\n",
      "Epoch 62/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1049 - val_loss: 0.0940\n",
      "Epoch 63/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1042 - val_loss: 0.0924\n",
      "Epoch 64/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1027 - val_loss: 0.0918\n",
      "Epoch 65/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1017 - val_loss: 0.0913\n",
      "Epoch 66/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1010 - val_loss: 0.0900\n",
      "Epoch 67/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1010 - val_loss: 0.0894\n",
      "Epoch 68/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0996 - val_loss: 0.0881\n",
      "Epoch 69/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0988 - val_loss: 0.0886\n",
      "Epoch 70/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0985 - val_loss: 0.0888\n",
      "Epoch 71/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - 1s 1us/step - loss: 0.0980 - val_loss: 0.0875\n",
      "Epoch 72/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0979 - val_loss: 0.0875\n",
      "Epoch 73/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0877\n",
      "Epoch 74/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0970 - val_loss: 0.0873\n",
      "Epoch 75/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0954 - val_loss: 0.0861\n",
      "Epoch 76/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0948 - val_loss: 0.0857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0948 - val_loss: 0.0854\n",
      "Epoch 78/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0945 - val_loss: 0.0846\n",
      "Epoch 79/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0940 - val_loss: 0.0835\n",
      "Epoch 80/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0933 - val_loss: 0.0835\n",
      "Epoch 81/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0926 - val_loss: 0.0836\n",
      "Epoch 82/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0925 - val_loss: 0.0831\n",
      "Epoch 83/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 0s 1us/step - loss: 0.0920 - val_loss: 0.0827\n",
      "Epoch 84/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0823\n",
      "Epoch 85/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0918 - val_loss: 0.0821\n",
      "Epoch 86/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0822\n",
      "Epoch 87/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0911 - val_loss: 0.0825\n",
      "Epoch 88/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0906 - val_loss: 0.0819\n",
      "Epoch 89/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0823\n",
      "Epoch 90/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0904 - val_loss: 0.0818\n",
      "Epoch 91/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0903 - val_loss: 0.0824\n",
      "Epoch 92/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0895 - val_loss: 0.0826\n",
      "Epoch 93/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0894 - val_loss: 0.0824\n",
      "Epoch 94/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0824\n",
      "Epoch 95/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0820\n",
      "Epoch 96/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0818\n",
      "Epoch 97/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0815\n",
      "Epoch 98/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0888 - val_loss: 0.0821\n",
      "Epoch 99/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0816\n",
      "Epoch 100/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0878 - val_loss: 0.0814\n",
      "Epoch 101/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0885 - val_loss: 0.0813\n",
      "Epoch 102/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0877 - val_loss: 0.0807\n",
      "Epoch 103/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0875 - val_loss: 0.0808\n",
      "Epoch 104/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0877 - val_loss: 0.0813\n",
      "Epoch 105/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0873 - val_loss: 0.0809\n",
      "Epoch 106/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0871 - val_loss: 0.0813\n",
      "Epoch 107/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0869 - val_loss: 0.0813\n",
      "Epoch 108/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0868 - val_loss: 0.0812\n",
      "Epoch 109/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0867 - val_loss: 0.0810\n",
      "Epoch 110/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0807\n",
      "Epoch 111/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0807\n",
      "Epoch 112/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0865 - val_loss: 0.0806\n",
      "Epoch 113/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0808\n",
      "Epoch 114/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - 0s 1us/step - loss: 0.0865 - val_loss: 0.0806\n",
      "Epoch 115/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0806\n",
      "Epoch 116/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0809\n",
      "Epoch 117/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0804\n",
      "Epoch 118/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0856 - val_loss: 0.0809\n",
      "Epoch 119/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0861 - val_loss: 0.0802\n",
      "Epoch 120/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0858 - val_loss: 0.0802\n",
      "Epoch 121/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0798\n",
      "Epoch 122/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0803\n",
      "Epoch 123/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0810\n",
      "Epoch 124/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0807\n",
      "Epoch 125/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0853 - val_loss: 0.0808\n",
      "Epoch 126/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0852 - val_loss: 0.0807\n",
      "Epoch 127/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0805\n",
      "Epoch 128/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0809\n",
      "Epoch 129/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0850 - val_loss: 0.0807\n",
      "Epoch 130/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 0s 1us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 131/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0853 - val_loss: 0.0803\n",
      "Epoch 132/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0803\n",
      "Epoch 134/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0851 - val_loss: 0.0801\n",
      "Epoch 135/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0852 - val_loss: 0.0801\n",
      "Epoch 136/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 0s 1us/step - loss: 0.0846 - val_loss: 0.0804\n",
      "Epoch 137/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 0s 1us/step - loss: 0.0847 - val_loss: 0.0802\n",
      "Epoch 138/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0852 - val_loss: 0.0799\n",
      "Epoch 139/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0802\n",
      "Epoch 140/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 0s 1us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 141/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 0s 1us/step - loss: 0.0851 - val_loss: 0.0802\n",
      "Epoch 142/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0800\n",
      "Epoch 143/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0800\n",
      "Epoch 144/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0800\n",
      "Epoch 145/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0844 - val_loss: 0.0801\n",
      "Epoch 146/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0800\n",
      "Epoch 147/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0796\n",
      "Epoch 148/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0797\n",
      "Epoch 149/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0800\n",
      "Epoch 150/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0805\n",
      "Epoch 151/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0844 - val_loss: 0.0810\n",
      "Epoch 152/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0812\n",
      "Epoch 153/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0805\n",
      "Epoch 154/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0803\n",
      "Epoch 155/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0799\n",
      "Epoch 156/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0806\n",
      "Epoch 157/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0809\n",
      "Epoch 158/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0809\n",
      "Epoch 159/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0807\n",
      "Epoch 160/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0807\n",
      "Epoch 161/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0800\n",
      "Epoch 162/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0801\n",
      "Epoch 163/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0844 - val_loss: 0.0804\n",
      "Epoch 164/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0807\n",
      "Epoch 165/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0809\n",
      "Epoch 166/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0808\n",
      "Epoch 167/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0810\n",
      "Epoch 168/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0808\n",
      "Epoch 169/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0810\n",
      "Epoch 170/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0813\n",
      "Epoch 171/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0816\n",
      "Epoch 172/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0807\n",
      "Epoch 173/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0812\n",
      "Epoch 174/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0817\n",
      "Epoch 175/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0814\n",
      "Epoch 176/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0800\n",
      "Epoch 177/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0790\n",
      "Epoch 178/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0793\n",
      "Epoch 179/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0798\n",
      "Epoch 180/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0794\n",
      "Epoch 181/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0802\n",
      "Epoch 182/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0796\n",
      "Epoch 183/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0791\n",
      "Epoch 184/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0793\n",
      "Epoch 185/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0795\n",
      "Epoch 186/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0786\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0785\n",
      "Epoch 188/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0786\n",
      "Epoch 189/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0827 - val_loss: 0.0782\n",
      "Epoch 190/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0829 - val_loss: 0.0784\n",
      "Epoch 191/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0824 - val_loss: 0.0776\n",
      "Epoch 192/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0767\n",
      "Epoch 193/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 0s 1us/step - loss: 0.0823 - val_loss: 0.0763\n",
      "Epoch 194/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 0s 1us/step - loss: 0.0821 - val_loss: 0.0762\n",
      "Epoch 195/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 0s 1us/step - loss: 0.0819 - val_loss: 0.0767\n",
      "Epoch 196/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0769\n",
      "Epoch 197/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 0s 1us/step - loss: 0.0822 - val_loss: 0.0771\n",
      "Epoch 198/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0773\n",
      "Epoch 199/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 0s 1us/step - loss: 0.0821 - val_loss: 0.0770\n",
      "Epoch 200/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0770\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 2. auc: 0.9483.\n",
      "Fold 4 started at Thu Sep 12 20:36:15 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/200\n",
      "472432/472432 [==============================] - ETA: 14s - loss: 0.78 - ETA: 3s - loss: 0.7810 - ETA: 1s - loss: 0.778 - ETA: 0s - loss: 0.773 - ETA: 0s - loss: 0.770 - ETA: 0s - loss: 0.767 - ETA: 0s - loss: 0.764 - ETA: 0s - loss: 0.761 - 1s 2us/step - loss: 0.7579 - val_loss: 0.6612\n",
      "Epoch 2/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.733 - ETA: 0s - loss: 0.729 - ETA: 0s - loss: 0.724 - ETA: 0s - loss: 0.721 - ETA: 0s - loss: 0.717 - ETA: 0s - loss: 0.714 - ETA: 0s - loss: 0.710 - ETA: 0s - loss: 0.707 - 1s 1us/step - loss: 0.7068 - val_loss: 0.7044\n",
      "Epoch 3/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.682 - ETA: 0s - loss: 0.678 - ETA: 0s - loss: 0.676 - ETA: 0s - loss: 0.673 - ETA: 0s - loss: 0.671 - ETA: 0s - loss: 0.668 - ETA: 0s - loss: 0.666 - ETA: 0s - loss: 0.663 - 1s 1us/step - loss: 0.6607 - val_loss: 0.6866\n",
      "Epoch 4/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.638 - ETA: 0s - loss: 0.635 - ETA: 0s - loss: 0.634 - ETA: 0s - loss: 0.633 - ETA: 0s - loss: 0.631 - ETA: 0s - loss: 0.629 - ETA: 0s - loss: 0.627 - ETA: 0s - loss: 0.626 - 1s 1us/step - loss: 0.6257 - val_loss: 0.6473\n",
      "Epoch 5/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.610 - ETA: 0s - loss: 0.611 - ETA: 0s - loss: 0.610 - ETA: 0s - loss: 0.608 - ETA: 0s - loss: 0.607 - ETA: 0s - loss: 0.605 - ETA: 0s - loss: 0.604 - ETA: 0s - loss: 0.602 - 1s 1us/step - loss: 0.6016 - val_loss: 0.6150\n",
      "Epoch 6/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.594 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.587 - ETA: 0s - loss: 0.586 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.583 - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.580 - 1s 1us/step - loss: 0.5802 - val_loss: 0.5872\n",
      "Epoch 7/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.568 - ETA: 0s - loss: 0.566 - ETA: 0s - loss: 0.566 - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.564 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.560 - 1s 1us/step - loss: 0.5589 - val_loss: 0.5588\n",
      "Epoch 8/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.545 - ETA: 0s - loss: 0.547 - ETA: 0s - loss: 0.545 - ETA: 0s - loss: 0.543 - ETA: 0s - loss: 0.542 - ETA: 0s - loss: 0.540 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.538 - 1s 1us/step - loss: 0.5377 - val_loss: 0.5347\n",
      "Epoch 9/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.530 - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.524 - ETA: 0s - loss: 0.524 - ETA: 0s - loss: 0.522 - ETA: 0s - loss: 0.521 - ETA: 0s - loss: 0.519 - ETA: 0s - loss: 0.518 - 1s 1us/step - loss: 0.5176 - val_loss: 0.5134\n",
      "Epoch 10/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.508 - ETA: 0s - loss: 0.506 - ETA: 0s - loss: 0.504 - ETA: 0s - loss: 0.502 - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.500 - ETA: 0s - loss: 0.499 - ETA: 0s - loss: 0.497 - 1s 1us/step - loss: 0.4973 - val_loss: 0.4980\n",
      "Epoch 11/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.484 - ETA: 0s - loss: 0.486 - ETA: 0s - loss: 0.484 - ETA: 0s - loss: 0.482 - ETA: 0s - loss: 0.482 - ETA: 0s - loss: 0.481 - ETA: 0s - loss: 0.479 - ETA: 0s - loss: 0.478 - 1s 1us/step - loss: 0.4773 - val_loss: 0.4864\n",
      "Epoch 12/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.465 - ETA: 0s - loss: 0.464 - ETA: 0s - loss: 0.463 - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.460 - ETA: 0s - loss: 0.459 - ETA: 0s - loss: 0.458 - 1s 1us/step - loss: 0.4577 - val_loss: 0.4688\n",
      "Epoch 13/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.445 - ETA: 0s - loss: 0.446 - ETA: 0s - loss: 0.445 - ETA: 0s - loss: 0.445 - ETA: 0s - loss: 0.444 - ETA: 0s - loss: 0.443 - ETA: 0s - loss: 0.441 - ETA: 0s - loss: 0.440 - 1s 1us/step - loss: 0.4389 - val_loss: 0.4436\n",
      "Epoch 14/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.428 - ETA: 0s - loss: 0.426 - ETA: 0s - loss: 0.425 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.421 - 1s 1us/step - loss: 0.4204 - val_loss: 0.4257\n",
      "Epoch 15/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.408 - ETA: 0s - loss: 0.407 - ETA: 0s - loss: 0.406 - ETA: 0s - loss: 0.405 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.402 - 1s 1us/step - loss: 0.4021 - val_loss: 0.4018\n",
      "Epoch 16/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.390 - ETA: 0s - loss: 0.391 - ETA: 0s - loss: 0.389 - ETA: 0s - loss: 0.388 - ETA: 0s - loss: 0.387 - ETA: 0s - loss: 0.386 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.384 - 1s 1us/step - loss: 0.3839 - val_loss: 0.3806\n",
      "Epoch 17/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.375 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.371 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.371 - ETA: 0s - loss: 0.370 - ETA: 0s - loss: 0.368 - ETA: 0s - loss: 0.367 - 1s 1us/step - loss: 0.3670 - val_loss: 0.3596\n",
      "Epoch 18/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.358 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.355 - ETA: 0s - loss: 0.354 - ETA: 0s - loss: 0.353 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.350 - 1s 1us/step - loss: 0.3500 - val_loss: 0.3437\n",
      "Epoch 19/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.344 - ETA: 0s - loss: 0.341 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.338 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.335 - 1s 1us/step - loss: 0.3353 - val_loss: 0.3207\n",
      "Epoch 20/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.321 - ETA: 0s - loss: 0.320 - ETA: 0s - loss: 0.320 - 1s 1us/step - loss: 0.3194 - val_loss: 0.3023\n",
      "Epoch 21/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.307 - ETA: 0s - loss: 0.306 - 1s 1us/step - loss: 0.3059 - val_loss: 0.2901\n",
      "Epoch 22/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.300 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.292 - 1s 1us/step - loss: 0.2921 - val_loss: 0.2762\n",
      "Epoch 23/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.284 - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.282 - ETA: 0s - loss: 0.281 - ETA: 0s - loss: 0.280 - ETA: 0s - loss: 0.279 - 1s 1us/step - loss: 0.2785 - val_loss: 0.2635\n",
      "Epoch 24/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.267 - 1s 1us/step - loss: 0.2666 - val_loss: 0.2511\n",
      "Epoch 25/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.258 - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.256 - ETA: 0s - loss: 0.256 - 1s 1us/step - loss: 0.2558 - val_loss: 0.2383\n",
      "Epoch 26/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.247 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.246 - ETA: 0s - loss: 0.245 - 1s 1us/step - loss: 0.2448 - val_loss: 0.2295\n",
      "Epoch 27/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.235 - 1s 1us/step - loss: 0.2346 - val_loss: 0.2218\n",
      "Epoch 28/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.225 - 1s 1us/step - loss: 0.2253 - val_loss: 0.2086\n",
      "Epoch 29/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.216 - 1s 1us/step - loss: 0.2163 - val_loss: 0.1985\n",
      "Epoch 30/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.208 - ETA: 0s - loss: 0.208 - ETA: 0s - loss: 0.208 - 1s 1us/step - loss: 0.2079 - val_loss: 0.1921\n",
      "Epoch 31/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.201 - ETA: 0s - loss: 0.201 - 1s 1us/step - loss: 0.2008 - val_loss: 0.1859\n",
      "Epoch 32/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.193 - ETA: 0s - loss: 0.192 - ETA: 0s - loss: 0.192 - 1s 1us/step - loss: 0.1928 - val_loss: 0.1776\n",
      "Epoch 33/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - 1s 1us/step - loss: 0.1860 - val_loss: 0.1721\n",
      "Epoch 34/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.178 - 1s 1us/step - loss: 0.1788 - val_loss: 0.1632\n",
      "Epoch 35/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.179 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.176 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - 1s 1us/step - loss: 0.1737 - val_loss: 0.1598\n",
      "Epoch 36/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.168 - ETA: 0s - loss: 0.167 - 1s 1us/step - loss: 0.1679 - val_loss: 0.1532\n",
      "Epoch 37/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.165 - ETA: 0s - loss: 0.167 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - 1s 1us/step - loss: 0.1628 - val_loss: 0.1502\n",
      "Epoch 38/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - 1s 1us/step - loss: 0.1583 - val_loss: 0.1451\n",
      "Epoch 39/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.153 - 1s 1us/step - loss: 0.1535 - val_loss: 0.1396\n",
      "Epoch 40/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.161 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.149 - 1s 1us/step - loss: 0.1497 - val_loss: 0.1359\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - ETA: 0s - loss: 0.146 - 1s 1us/step - loss: 0.1462 - val_loss: 0.1329\n",
      "Epoch 42/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - 1s 1us/step - loss: 0.1420 - val_loss: 0.1290\n",
      "Epoch 43/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.139 - 1s 1us/step - loss: 0.1391 - val_loss: 0.1243\n",
      "Epoch 44/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.135 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - ETA: 0s - loss: 0.134 - 1s 1us/step - loss: 0.1349 - val_loss: 0.1230\n",
      "Epoch 45/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - 1s 1us/step - loss: 0.1325 - val_loss: 0.1216\n",
      "Epoch 46/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1296 - val_loss: 0.1189\n",
      "Epoch 47/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - 1s 1us/step - loss: 0.1268 - val_loss: 0.1158\n",
      "Epoch 48/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - 1s 1us/step - loss: 0.1252 - val_loss: 0.1139\n",
      "Epoch 49/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.122 - 1s 1us/step - loss: 0.1220 - val_loss: 0.1130\n",
      "Epoch 50/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - 1s 1us/step - loss: 0.1201 - val_loss: 0.1107\n",
      "Epoch 51/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.118 - 1s 1us/step - loss: 0.1181 - val_loss: 0.1081\n",
      "Epoch 52/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - 1s 1us/step - loss: 0.1165 - val_loss: 0.1057\n",
      "Epoch 53/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - 1s 1us/step - loss: 0.1147 - val_loss: 0.1045\n",
      "Epoch 54/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1125 - val_loss: 0.1039\n",
      "Epoch 55/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - 1s 1us/step - loss: 0.1112 - val_loss: 0.1031\n",
      "Epoch 56/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1096 - val_loss: 0.1001\n",
      "Epoch 57/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - 1s 1us/step - loss: 0.1080 - val_loss: 0.0983\n",
      "Epoch 58/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1072 - val_loss: 0.0970\n",
      "Epoch 59/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1062 - val_loss: 0.0969\n",
      "Epoch 60/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1051 - val_loss: 0.0967\n",
      "Epoch 61/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - 1s 1us/step - loss: 0.1034 - val_loss: 0.0951\n",
      "Epoch 62/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1026 - val_loss: 0.0936\n",
      "Epoch 63/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1017 - val_loss: 0.0929\n",
      "Epoch 64/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1005 - val_loss: 0.0914\n",
      "Epoch 65/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0997 - val_loss: 0.0916\n",
      "Epoch 66/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0993 - val_loss: 0.0904\n",
      "Epoch 67/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0979 - val_loss: 0.0902\n",
      "Epoch 68/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0976 - val_loss: 0.0900\n",
      "Epoch 69/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0967 - val_loss: 0.0895\n",
      "Epoch 70/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0957 - val_loss: 0.0887\n",
      "Epoch 71/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0955 - val_loss: 0.0880\n",
      "Epoch 72/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0946 - val_loss: 0.0870\n",
      "Epoch 73/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0868\n",
      "Epoch 74/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0937 - val_loss: 0.0868\n",
      "Epoch 75/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0859\n",
      "Epoch 76/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0928 - val_loss: 0.0867\n",
      "Epoch 77/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0924 - val_loss: 0.0858\n",
      "Epoch 78/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0913 - val_loss: 0.0843\n",
      "Epoch 79/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0913 - val_loss: 0.0845\n",
      "Epoch 80/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0909 - val_loss: 0.0850\n",
      "Epoch 81/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0908 - val_loss: 0.0844\n",
      "Epoch 82/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0907 - val_loss: 0.0847\n",
      "Epoch 83/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0905 - val_loss: 0.0843\n",
      "Epoch 84/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0837\n",
      "Epoch 85/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0891 - val_loss: 0.0836\n",
      "Epoch 86/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0892 - val_loss: 0.0836\n",
      "Epoch 87/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0839\n",
      "Epoch 88/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0884 - val_loss: 0.0832\n",
      "Epoch 89/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0890 - val_loss: 0.0827\n",
      "Epoch 90/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0830\n",
      "Epoch 91/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0825\n",
      "Epoch 92/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0873 - val_loss: 0.0826\n",
      "Epoch 93/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0831\n",
      "Epoch 94/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0868 - val_loss: 0.0832\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0870 - val_loss: 0.0834\n",
      "Epoch 96/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0869 - val_loss: 0.0831\n",
      "Epoch 97/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0833\n",
      "Epoch 98/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0865 - val_loss: 0.0830\n",
      "Epoch 99/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0866 - val_loss: 0.0832\n",
      "Epoch 100/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0829\n",
      "Epoch 101/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0824\n",
      "Epoch 102/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0857 - val_loss: 0.0824\n",
      "Epoch 103/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0824\n",
      "Epoch 104/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0826\n",
      "Epoch 105/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0852 - val_loss: 0.0827\n",
      "Epoch 106/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0856 - val_loss: 0.0828\n",
      "Epoch 107/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0851 - val_loss: 0.0826\n",
      "Epoch 108/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0816\n",
      "Epoch 109/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0817\n",
      "Epoch 110/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0849 - val_loss: 0.0820\n",
      "Epoch 111/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0854 - val_loss: 0.0824\n",
      "Epoch 112/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0822\n",
      "Epoch 113/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0844 - val_loss: 0.0817\n",
      "Epoch 114/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0817\n",
      "Epoch 115/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0814\n",
      "Epoch 116/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0809\n",
      "Epoch 117/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0808\n",
      "Epoch 118/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0807\n",
      "Epoch 119/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0806\n",
      "Epoch 120/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0808\n",
      "Epoch 121/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0804\n",
      "Epoch 122/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0807\n",
      "Epoch 123/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0799\n",
      "Epoch 124/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0795\n",
      "Epoch 125/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0795\n",
      "Epoch 126/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0793\n",
      "Epoch 127/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0796\n",
      "Epoch 128/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0792\n",
      "Epoch 129/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0789\n",
      "Epoch 130/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0793\n",
      "Epoch 131/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0827 - val_loss: 0.0786\n",
      "Epoch 132/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0785\n",
      "Epoch 133/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0824 - val_loss: 0.0781\n",
      "Epoch 134/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0785\n",
      "Epoch 135/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0783\n",
      "Epoch 136/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0824 - val_loss: 0.0786\n",
      "Epoch 137/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0827 - val_loss: 0.0788\n",
      "Epoch 138/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0784\n",
      "Epoch 139/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0782\n",
      "Epoch 140/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0825 - val_loss: 0.0784\n",
      "Epoch 141/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0825 - val_loss: 0.0780\n",
      "Epoch 142/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0822 - val_loss: 0.0777\n",
      "Epoch 143/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0825 - val_loss: 0.0778\n",
      "Epoch 144/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0777\n",
      "Epoch 145/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0780\n",
      "Epoch 146/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0826 - val_loss: 0.0781\n",
      "Epoch 147/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0820 - val_loss: 0.0784\n",
      "Epoch 148/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0825 - val_loss: 0.0783\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0823 - val_loss: 0.0780\n",
      "Epoch 150/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0781\n",
      "Epoch 151/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0816 - val_loss: 0.0780\n",
      "Epoch 152/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0780\n",
      "Epoch 153/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0776\n",
      "Epoch 154/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0777\n",
      "Epoch 155/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0778\n",
      "Epoch 156/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0777\n",
      "Epoch 157/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0777\n",
      "Epoch 158/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0777\n",
      "Epoch 159/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0777\n",
      "Epoch 160/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0773\n",
      "Epoch 161/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0779\n",
      "Epoch 162/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0779\n",
      "Epoch 163/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0781\n",
      "Epoch 164/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0816 - val_loss: 0.0782\n",
      "Epoch 165/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0777\n",
      "Epoch 166/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0780\n",
      "Epoch 167/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0780\n",
      "Epoch 168/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0780\n",
      "Epoch 169/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0779\n",
      "Epoch 170/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0820 - val_loss: 0.0780\n",
      "Epoch 171/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0782\n",
      "Epoch 172/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0778\n",
      "Epoch 173/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0777\n",
      "Epoch 174/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0777\n",
      "Epoch 175/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0777\n",
      "Epoch 176/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0780\n",
      "Epoch 177/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0821 - val_loss: 0.0781\n",
      "Epoch 178/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0780\n",
      "Epoch 179/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0815 - val_loss: 0.0778\n",
      "Epoch 180/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0815 - val_loss: 0.0779\n",
      "Epoch 181/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0818 - val_loss: 0.0779\n",
      "Epoch 182/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0778\n",
      "Epoch 183/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0812 - val_loss: 0.0779\n",
      "Epoch 184/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0817 - val_loss: 0.0781\n",
      "Epoch 185/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0812 - val_loss: 0.0781\n",
      "Epoch 186/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - 1s 1us/step - loss: 0.0810 - val_loss: 0.0782\n",
      "Epoch 187/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0779\n",
      "Epoch 188/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0813 - val_loss: 0.0782\n",
      "Epoch 189/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0816 - val_loss: 0.0782\n",
      "Epoch 190/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0815 - val_loss: 0.0781\n",
      "Epoch 191/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0816 - val_loss: 0.0778\n",
      "Epoch 192/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0785\n",
      "Epoch 193/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0815 - val_loss: 0.0787\n",
      "Epoch 194/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0790\n",
      "Epoch 195/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0787\n",
      "Epoch 196/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0811 - val_loss: 0.0785\n",
      "Epoch 197/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0814 - val_loss: 0.0782\n",
      "Epoch 198/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0811 - val_loss: 0.0777\n",
      "Epoch 199/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0819 - val_loss: 0.0778\n",
      "Epoch 200/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - 1s 1us/step - loss: 0.0816 - val_loss: 0.0783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 3. auc: 0.9598.\n",
      "Fold 5 started at Thu Sep 12 20:38:22 2019\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/200\n",
      "472432/472432 [==============================] - ETA: 16s - loss: 0.72 - ETA: 3s - loss: 0.7238 - ETA: 1s - loss: 0.719 - ETA: 1s - loss: 0.714 - ETA: 0s - loss: 0.709 - ETA: 0s - loss: 0.705 - ETA: 0s - loss: 0.702 - ETA: 0s - loss: 0.697 - 1s 3us/step - loss: 0.6930 - val_loss: 0.6585\n",
      "Epoch 2/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.656 - ETA: 0s - loss: 0.656 - ETA: 0s - loss: 0.656 - ETA: 0s - loss: 0.653 - ETA: 0s - loss: 0.650 - ETA: 0s - loss: 0.647 - ETA: 0s - loss: 0.645 - ETA: 0s - loss: 0.643 - ETA: 0s - loss: 0.641 - ETA: 0s - loss: 0.639 - 1s 1us/step - loss: 0.6390 - val_loss: 0.6216\n",
      "Epoch 3/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.619 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.615 - ETA: 0s - loss: 0.614 - ETA: 0s - loss: 0.612 - ETA: 0s - loss: 0.610 - ETA: 0s - loss: 0.609 - ETA: 0s - loss: 0.607 - ETA: 0s - loss: 0.605 - 1s 1us/step - loss: 0.6044 - val_loss: 0.5908\n",
      "Epoch 4/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.590 - ETA: 0s - loss: 0.591 - ETA: 0s - loss: 0.589 - ETA: 0s - loss: 0.586 - ETA: 0s - loss: 0.584 - ETA: 0s - loss: 0.583 - ETA: 0s - loss: 0.582 - ETA: 0s - loss: 0.581 - ETA: 0s - loss: 0.579 - 1s 1us/step - loss: 0.5782 - val_loss: 0.5646\n",
      "Epoch 5/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.565 - ETA: 0s - loss: 0.562 - ETA: 0s - loss: 0.561 - ETA: 0s - loss: 0.559 - ETA: 0s - loss: 0.558 - ETA: 0s - loss: 0.556 - ETA: 0s - loss: 0.555 - 1s 1us/step - loss: 0.5551 - val_loss: 0.5433\n",
      "Epoch 6/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.537 - ETA: 0s - loss: 0.541 - ETA: 0s - loss: 0.541 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.539 - ETA: 0s - loss: 0.538 - ETA: 0s - loss: 0.536 - ETA: 0s - loss: 0.536 - ETA: 0s - loss: 0.534 - 1s 1us/step - loss: 0.5341 - val_loss: 0.5233\n",
      "Epoch 7/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.526 - ETA: 0s - loss: 0.519 - ETA: 0s - loss: 0.519 - ETA: 0s - loss: 0.518 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.516 - ETA: 0s - loss: 0.515 - ETA: 0s - loss: 0.514 - ETA: 0s - loss: 0.513 - 1s 1us/step - loss: 0.5126 - val_loss: 0.5043\n",
      "Epoch 8/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.503 - ETA: 0s - loss: 0.506 - ETA: 0s - loss: 0.502 - ETA: 0s - loss: 0.500 - ETA: 0s - loss: 0.499 - ETA: 0s - loss: 0.498 - ETA: 0s - loss: 0.497 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.494 - 1s 1us/step - loss: 0.4932 - val_loss: 0.4873\n",
      "Epoch 9/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.480 - ETA: 0s - loss: 0.479 - ETA: 0s - loss: 0.478 - ETA: 0s - loss: 0.477 - ETA: 0s - loss: 0.475 - ETA: 0s - loss: 0.475 - ETA: 0s - loss: 0.474 - ETA: 0s - loss: 0.474 - ETA: 0s - loss: 0.473 - 1s 1us/step - loss: 0.4724 - val_loss: 0.4706\n",
      "Epoch 10/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.462 - ETA: 0s - loss: 0.461 - ETA: 0s - loss: 0.458 - ETA: 0s - loss: 0.457 - ETA: 0s - loss: 0.456 - ETA: 0s - loss: 0.456 - ETA: 0s - loss: 0.454 - ETA: 0s - loss: 0.453 - 1s 1us/step - loss: 0.4525 - val_loss: 0.4533\n",
      "Epoch 11/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.438 - ETA: 0s - loss: 0.439 - ETA: 0s - loss: 0.439 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.435 - ETA: 0s - loss: 0.434 - ETA: 0s - loss: 0.433 - 1s 1us/step - loss: 0.4328 - val_loss: 0.4352\n",
      "Epoch 12/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.425 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.420 - ETA: 0s - loss: 0.419 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.416 - ETA: 0s - loss: 0.415 - 1s 1us/step - loss: 0.4137 - val_loss: 0.4171\n",
      "Epoch 13/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.401 - ETA: 0s - loss: 0.400 - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.397 - ETA: 0s - loss: 0.396 - 1s 1us/step - loss: 0.3951 - val_loss: 0.3966\n",
      "Epoch 14/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.390 - ETA: 0s - loss: 0.385 - ETA: 0s - loss: 0.383 - ETA: 0s - loss: 0.381 - ETA: 0s - loss: 0.380 - ETA: 0s - loss: 0.379 - ETA: 0s - loss: 0.378 - ETA: 0s - loss: 0.377 - 1s 1us/step - loss: 0.3769 - val_loss: 0.3776\n",
      "Epoch 15/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.375 - ETA: 0s - loss: 0.369 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.366 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.361 - ETA: 0s - loss: 0.361 - 1s 1us/step - loss: 0.3606 - val_loss: 0.3582\n",
      "Epoch 16/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.346 - ETA: 0s - loss: 0.346 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.346 - ETA: 0s - loss: 0.345 - ETA: 0s - loss: 0.345 - ETA: 0s - loss: 0.344 - 1s 1us/step - loss: 0.3431 - val_loss: 0.3415\n",
      "Epoch 17/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.332 - ETA: 0s - loss: 0.332 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.329 - ETA: 0s - loss: 0.328 - 1s 1us/step - loss: 0.3277 - val_loss: 0.3239\n",
      "Epoch 18/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.312 - 1s 1us/step - loss: 0.3119 - val_loss: 0.3089\n",
      "Epoch 19/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.302 - ETA: 0s - loss: 0.306 - ETA: 0s - loss: 0.303 - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.298 - 1s 1us/step - loss: 0.2981 - val_loss: 0.2951\n",
      "Epoch 20/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.291 - ETA: 0s - loss: 0.289 - ETA: 0s - loss: 0.289 - ETA: 0s - loss: 0.288 - ETA: 0s - loss: 0.287 - ETA: 0s - loss: 0.286 - ETA: 0s - loss: 0.285 - ETA: 0s - loss: 0.284 - 1s 1us/step - loss: 0.2846 - val_loss: 0.2798\n",
      "Epoch 21/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.283 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.275 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.271 - 1s 1us/step - loss: 0.2716 - val_loss: 0.2653\n",
      "Epoch 22/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.266 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.262 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.260 - ETA: 0s - loss: 0.259 - 1s 1us/step - loss: 0.2588 - val_loss: 0.2530\n",
      "Epoch 23/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.251 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.249 - ETA: 0s - loss: 0.248 - 1s 1us/step - loss: 0.2480 - val_loss: 0.2422\n",
      "Epoch 24/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.243 - ETA: 0s - loss: 0.242 - ETA: 0s - loss: 0.242 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.240 - ETA: 0s - loss: 0.239 - ETA: 0s - loss: 0.238 - ETA: 0s - loss: 0.237 - 1s 1us/step - loss: 0.2378 - val_loss: 0.2304\n",
      "Epoch 25/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.231 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.230 - ETA: 0s - loss: 0.229 - ETA: 0s - loss: 0.228 - 1s 1us/step - loss: 0.2283 - val_loss: 0.2204\n",
      "Epoch 26/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.218 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.221 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.220 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.219 - ETA: 0s - loss: 0.218 - 1s 1us/step - loss: 0.2187 - val_loss: 0.2114\n",
      "Epoch 27/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.217 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.212 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.211 - ETA: 0s - loss: 0.210 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.209 - ETA: 0s - loss: 0.208 - 1s 1us/step - loss: 0.2086 - val_loss: 0.2027\n",
      "Epoch 28/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.207 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.204 - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.202 - ETA: 0s - loss: 0.201 - 1s 1us/step - loss: 0.2016 - val_loss: 0.1945\n",
      "Epoch 29/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.190 - ETA: 0s - loss: 0.194 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.197 - ETA: 0s - loss: 0.196 - ETA: 0s - loss: 0.195 - ETA: 0s - loss: 0.194 - 1s 1us/step - loss: 0.1939 - val_loss: 0.1863\n",
      "Epoch 30/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.188 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.187 - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.186 - 1s 1us/step - loss: 0.1862 - val_loss: 0.1801\n",
      "Epoch 31/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.186 - ETA: 0s - loss: 0.183 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.182 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.181 - ETA: 0s - loss: 0.180 - ETA: 0s - loss: 0.180 - 1s 1us/step - loss: 0.1803 - val_loss: 0.1741\n",
      "Epoch 32/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.175 - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.174 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - ETA: 0s - loss: 0.173 - 1s 1us/step - loss: 0.1734 - val_loss: 0.1680\n",
      "Epoch 33/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.170 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - ETA: 0s - loss: 0.169 - 1s 1us/step - loss: 0.1689 - val_loss: 0.1623\n",
      "Epoch 34/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.164 - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.163 - 1s 1us/step - loss: 0.1630 - val_loss: 0.1558\n",
      "Epoch 35/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - ETA: 0s - loss: 0.158 - 1s 1us/step - loss: 0.1581 - val_loss: 0.1528\n",
      "Epoch 36/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.163 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.155 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.154 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.153 - 1s 1us/step - loss: 0.1535 - val_loss: 0.1479\n",
      "Epoch 37/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.153 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.151 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.149 - 1s 1us/step - loss: 0.1493 - val_loss: 0.1430\n",
      "Epoch 38/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.152 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.145 - ETA: 0s - loss: 0.144 - 1s 1us/step - loss: 0.1446 - val_loss: 0.1388\n",
      "Epoch 39/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.142 - ETA: 0s - loss: 0.141 - ETA: 0s - loss: 0.141 - 1s 1us/step - loss: 0.1411 - val_loss: 0.1359\n",
      "Epoch 40/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.139 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - ETA: 0s - loss: 0.138 - 1s 1us/step - loss: 0.1384 - val_loss: 0.1333\n",
      "Epoch 41/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.128 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.137 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.136 - ETA: 0s - loss: 0.135 - 1s 1us/step - loss: 0.1355 - val_loss: 0.1284\n",
      "Epoch 42/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.133 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.132 - ETA: 0s - loss: 0.132 - 1s 1us/step - loss: 0.1318 - val_loss: 0.1267\n",
      "Epoch 43/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.131 - ETA: 0s - loss: 0.130 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.128 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - ETA: 0s - loss: 0.129 - 1s 1us/step - loss: 0.1292 - val_loss: 0.1233\n",
      "Epoch 44/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.127 - ETA: 0s - loss: 0.126 - 1s 1us/step - loss: 0.1266 - val_loss: 0.1201\n",
      "Epoch 45/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - 1s 1us/step - loss: 0.1239 - val_loss: 0.1183\n",
      "Epoch 46/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.122 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.121 - ETA: 0s - loss: 0.120 - 1s 1us/step - loss: 0.1209 - val_loss: 0.1156\n",
      "Epoch 47/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.123 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.120 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - ETA: 0s - loss: 0.119 - 1s 1us/step - loss: 0.1192 - val_loss: 0.1134\n",
      "Epoch 48/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - 1s 1us/step - loss: 0.1171 - val_loss: 0.1107\n",
      "Epoch 49/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.117 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.115 - 1s 1us/step - loss: 0.1157 - val_loss: 0.1095\n",
      "Epoch 50/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - 1s 1us/step - loss: 0.1131 - val_loss: 0.1074\n",
      "Epoch 51/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.114 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - ETA: 0s - loss: 0.112 - 1s 1us/step - loss: 0.1124 - val_loss: 0.1061\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.110 - 1s 1us/step - loss: 0.1105 - val_loss: 0.1043\n",
      "Epoch 53/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - 1s 1us/step - loss: 0.1089 - val_loss: 0.1036\n",
      "Epoch 54/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.107 - 1s 1us/step - loss: 0.1075 - val_loss: 0.1016\n",
      "Epoch 55/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - 1s 1us/step - loss: 0.1066 - val_loss: 0.1000\n",
      "Epoch 56/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - 1s 1us/step - loss: 0.1056 - val_loss: 0.0992\n",
      "Epoch 57/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.104 - ETA: 0s - loss: 0.104 - 1s 1us/step - loss: 0.1045 - val_loss: 0.0978\n",
      "Epoch 58/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1029 - val_loss: 0.0971\n",
      "Epoch 59/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - 1s 1us/step - loss: 0.1024 - val_loss: 0.0961\n",
      "Epoch 60/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.103 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.102 - ETA: 0s - loss: 0.101 - 1s 1us/step - loss: 0.1019 - val_loss: 0.0953\n",
      "Epoch 61/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - 1s 1us/step - loss: 0.1009 - val_loss: 0.0933\n",
      "Epoch 62/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0999 - val_loss: 0.0923\n",
      "Epoch 63/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - 1s 1us/step - loss: 0.0994 - val_loss: 0.0917\n",
      "Epoch 64/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0977 - val_loss: 0.0908\n",
      "Epoch 65/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.098 - ETA: 0s - loss: 0.097 - 1s 1us/step - loss: 0.0977 - val_loss: 0.0901\n",
      "Epoch 66/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0969 - val_loss: 0.0897\n",
      "Epoch 67/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0957 - val_loss: 0.0887\n",
      "Epoch 68/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.096 - 1s 1us/step - loss: 0.0965 - val_loss: 0.0884\n",
      "Epoch 69/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.095 - 1s 1us/step - loss: 0.0955 - val_loss: 0.0873\n",
      "Epoch 70/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - 1s 1us/step - loss: 0.0943 - val_loss: 0.0871\n",
      "Epoch 71/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0936 - val_loss: 0.0864\n",
      "Epoch 72/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0934 - val_loss: 0.0857\n",
      "Epoch 73/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - 1s 1us/step - loss: 0.0935 - val_loss: 0.0853\n",
      "Epoch 74/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.097 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - 1s 1us/step - loss: 0.0929 - val_loss: 0.0854\n",
      "Epoch 75/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0919 - val_loss: 0.0847\n",
      "Epoch 76/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0914 - val_loss: 0.0844\n",
      "Epoch 77/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0842\n",
      "Epoch 78/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0912 - val_loss: 0.0839\n",
      "Epoch 79/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - 1s 1us/step - loss: 0.0909 - val_loss: 0.0836\n",
      "Epoch 80/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.096 - ETA: 0s - loss: 0.092 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0902 - val_loss: 0.0831\n",
      "Epoch 81/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0900 - val_loss: 0.0829\n",
      "Epoch 82/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - 1s 1us/step - loss: 0.0902 - val_loss: 0.0830\n",
      "Epoch 83/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.095 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - 1s 1us/step - loss: 0.0896 - val_loss: 0.0826\n",
      "Epoch 84/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0888 - val_loss: 0.0823\n",
      "Epoch 85/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0820\n",
      "Epoch 86/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0889 - val_loss: 0.0820\n",
      "Epoch 87/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0886 - val_loss: 0.0814\n",
      "Epoch 88/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0883 - val_loss: 0.0813\n",
      "Epoch 89/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0887 - val_loss: 0.0814\n",
      "Epoch 90/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0812\n",
      "Epoch 91/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0880 - val_loss: 0.0811\n",
      "Epoch 92/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.093 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0881 - val_loss: 0.0813\n",
      "Epoch 93/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0876 - val_loss: 0.0806\n",
      "Epoch 94/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - 1s 1us/step - loss: 0.0879 - val_loss: 0.0807\n",
      "Epoch 95/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0870 - val_loss: 0.0806\n",
      "Epoch 96/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0807\n",
      "Epoch 97/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0805\n",
      "Epoch 98/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0867 - val_loss: 0.0803\n",
      "Epoch 99/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0872 - val_loss: 0.0802\n",
      "Epoch 100/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0861 - val_loss: 0.0802\n",
      "Epoch 101/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0867 - val_loss: 0.0800\n",
      "Epoch 102/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0798\n",
      "Epoch 103/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - 1s 1us/step - loss: 0.0870 - val_loss: 0.0797\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0859 - val_loss: 0.0797\n",
      "Epoch 105/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0857 - val_loss: 0.0794\n",
      "Epoch 106/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0861 - val_loss: 0.0795\n",
      "Epoch 107/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - 1s 1us/step - loss: 0.0860 - val_loss: 0.0795\n",
      "Epoch 108/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0863 - val_loss: 0.0795\n",
      "Epoch 109/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0795\n",
      "Epoch 110/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0853 - val_loss: 0.0793\n",
      "Epoch 111/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0855 - val_loss: 0.0794\n",
      "Epoch 112/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0793\n",
      "Epoch 113/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0848 - val_loss: 0.0791\n",
      "Epoch 114/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0849 - val_loss: 0.0788\n",
      "Epoch 115/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0849 - val_loss: 0.0789\n",
      "Epoch 116/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0850 - val_loss: 0.0789\n",
      "Epoch 117/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0788\n",
      "Epoch 118/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0788\n",
      "Epoch 119/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0787\n",
      "Epoch 120/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0787\n",
      "Epoch 121/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.091 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0846 - val_loss: 0.0784\n",
      "Epoch 122/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0784\n",
      "Epoch 123/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0785\n",
      "Epoch 124/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0845 - val_loss: 0.0783\n",
      "Epoch 125/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0842 - val_loss: 0.0784\n",
      "Epoch 126/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0783\n",
      "Epoch 127/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0785\n",
      "Epoch 128/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0783\n",
      "Epoch 129/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0786\n",
      "Epoch 130/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0847 - val_loss: 0.0784\n",
      "Epoch 131/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0844 - val_loss: 0.0784\n",
      "Epoch 132/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0843 - val_loss: 0.0783\n",
      "Epoch 133/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0781\n",
      "Epoch 134/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0782\n",
      "Epoch 135/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0778\n",
      "Epoch 136/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0841 - val_loss: 0.0780\n",
      "Epoch 137/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0777\n",
      "Epoch 138/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0779\n",
      "Epoch 139/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0777\n",
      "Epoch 140/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0778\n",
      "Epoch 141/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0776\n",
      "Epoch 142/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0778\n",
      "Epoch 143/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0777\n",
      "Epoch 144/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0777\n",
      "Epoch 145/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0779\n",
      "Epoch 146/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0776\n",
      "Epoch 147/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0778\n",
      "Epoch 148/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0774\n",
      "Epoch 149/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0840 - val_loss: 0.0773\n",
      "Epoch 150/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0773\n",
      "Epoch 151/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0775\n",
      "Epoch 152/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0774\n",
      "Epoch 153/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0774\n",
      "Epoch 154/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0774\n",
      "Epoch 155/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0771\n",
      "Epoch 156/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0771\n",
      "Epoch 158/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0769\n",
      "Epoch 159/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0839 - val_loss: 0.0772\n",
      "Epoch 160/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0773\n",
      "Epoch 161/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0768\n",
      "Epoch 162/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0769\n",
      "Epoch 163/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - 1s 1us/step - loss: 0.0838 - val_loss: 0.0770\n",
      "Epoch 164/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0771\n",
      "Epoch 165/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0768\n",
      "Epoch 166/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0770\n",
      "Epoch 167/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0771\n",
      "Epoch 168/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0771\n",
      "Epoch 169/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0771\n",
      "Epoch 170/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0771\n",
      "Epoch 171/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0771\n",
      "Epoch 172/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0770\n",
      "Epoch 173/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0773\n",
      "Epoch 174/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0775\n",
      "Epoch 175/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0773\n",
      "Epoch 176/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0775\n",
      "Epoch 177/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0772\n",
      "Epoch 178/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.090 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0836 - val_loss: 0.0773\n",
      "Epoch 179/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0770\n",
      "Epoch 180/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0773\n",
      "Epoch 181/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0768\n",
      "Epoch 182/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0770\n",
      "Epoch 183/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0837 - val_loss: 0.0770\n",
      "Epoch 184/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0769\n",
      "Epoch 185/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.078 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0769\n",
      "Epoch 186/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0770\n",
      "Epoch 187/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0769\n",
      "Epoch 188/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0769\n",
      "Epoch 189/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0768\n",
      "Epoch 190/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0767\n",
      "Epoch 191/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0764\n",
      "Epoch 192/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.089 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0766\n",
      "Epoch 193/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0834 - val_loss: 0.0767\n",
      "Epoch 194/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0770\n",
      "Epoch 195/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0835 - val_loss: 0.0769\n",
      "Epoch 196/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.086 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0831 - val_loss: 0.0769\n",
      "Epoch 197/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.082 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0767\n",
      "Epoch 198/200\n",
      "472432/472432 [==============================] - ETA: 1s - loss: 0.081 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0833 - val_loss: 0.0765\n",
      "Epoch 199/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0832 - val_loss: 0.0765\n",
      "Epoch 200/200\n",
      "472432/472432 [==============================] - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.083 - 1s 1us/step - loss: 0.0830 - val_loss: 0.0763\n",
      "118108/118108 [==============================] - ETA:  - 0s 1us/step\n",
      "Fold 4. auc: 0.9435.\n",
      "CV mean score: 0.9489, std: 0.0074.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "result_dict_keras = train_model_classification(model=StackModel_maker, \n",
    "                                             X=oof,\n",
    "                                             X_test=prediction,\n",
    "                                             y=y, params=params, folds=folds,\n",
    "                                             model_type=train_options['model_type'], \n",
    "                                             eval_metric=train_options['eval_metric'],\n",
    "                                             averaging=train_options['averaging'],\n",
    "                                             groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:41:33.110128Z",
     "start_time": "2019-09-12T17:41:30.728072Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'../../data/sample_submission.csv')\n",
    "sub['isFraud'] = result_dict_keras['prediction']\n",
    "sub.to_csv(f'{model_folder}/stacked_keras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T17:41:42.279769Z",
     "start_time": "2019-09-12T17:41:42.005688Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{model_folder}/results_dict_stacked_keras.pkl', 'wb') as f:\n",
    "#     q = json.dumps(result_dict_lgb,indent=2)\n",
    "    pickle.dump(result_dict_keras,f)\n",
    "#     f.write(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
